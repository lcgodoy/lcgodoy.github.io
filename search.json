[
  {
    "objectID": "talks/2025-ucsf/index.html",
    "href": "talks/2025-ucsf/index.html",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "",
    "text": "Details\n\nDate: Mar 12, 2025\nLocation: San Francisco, CA - USA\nSlides\n\n\n\nAbstract\nAccurate modeling of spatial dependence is crucial for analyzing spatial data and influencing parameter estimation and predictions. Existing models for areal data often struggle to differentiate between different polygon shapes, while data fusion models face computational challenges with larger datasets. To address these limitations, we propose the Hausdorff-Gaussian process (HGP), a versatile model using the Hausdorff distance to capture spatial dependence in point and areal data. We introduce a valid correlation function, accommodating various modeling techniques, including geostatistical and areal models, and integrate it into generalized linear mixed-effects models for data fusion. We demonstrate the HGP’s competitive performance regarding goodness-of-fit and prediction through simulations and real-world applications involving both areal data and data fusion. The HGP offers a flexible and robust solution for modeling diverse spatial data with potential public health and climate science applications.\n\n\nSlides"
  },
  {
    "objectID": "talks/2025-git/index.html",
    "href": "talks/2025-git/index.html",
    "title": "Git & Friends",
    "section": "",
    "text": "Details\n\nDate: Nov 02, 2025\nLocation: Santa Cruz, CA - Brazil\nSlides\n\n\n\nAbstract\nA brief presentation about version control focused on git with a lightning introduction to the terminal.\n\n\nSlides"
  },
  {
    "objectID": "talks/2024-ucsc/index.html",
    "href": "talks/2024-ucsc/index.html",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "",
    "text": "Details\n\nDate: Oct 21, 2024\nLocation: Santa Cruz, CA\nSlides\n\n\n\nAbstract\nAccurate modeling of spatial dependence is pivotal in analyzing spatial data, influencing parameter estimation and predictions. The spatial structure of the data significantly impacts valid statistical inference. Existing models for areal data often rely on adjacency matrices, struggling to differentiate between polygons of varying sizes and shapes. Conversely, data fusion models rely on computationally intensive numerical integrals, presenting challenges for moderately large datasets. In response to these issues, we propose the Hausdorff-Gaussian process (HGP), a versatile model utilizing the Hausdorff distance to capture spatial dependence in both point and areal data. We introduce a valid correlation function for this model, accommodating diverse modeling techniques, including geostatistical and areal models. Integration into generalized linear mixed-effects models enhances its applicability, particularly in addressing data fusion challenges. We validate our approach through a comprehensive simulation study and application to two real-world scenarios involve areal data, and another demonstrates its effectiveness in data fusion. The results suggest that the HGP is competitive with specialized models regarding goodness-of-fit and prediction performances. In summary, the HGP offers a flexible and robust solution for modeling spatial data of various types and shapes, with potential applications spanning fields such as public health and climate science.\n\n\nSlides"
  },
  {
    "objectID": "talks/2024-jsm/index.html",
    "href": "talks/2024-jsm/index.html",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "",
    "text": "Details\n\nDate: Aug 4, 2024\nLocation: Portlant, OR\nSlides\n\n\n\nAbstract\nAccurate modeling of spatial dependence is pivotal in analyzing spatial data, influencing parameter estimation and out-of-sample predictions. The spatial structure and geometry of the data significantly impact valid statistical inference. Existing models for areal data often rely on adjacency matrices, struggling to differentiate between polygons of varying sizes and shapes. Conversely, data fusion models, while effective, rely on computationally intensive numerical integrals, presenting challenges for moderately large datasets. In response to these issues, we propose the Hausdorff-Gaussian process (HGP), a versatile model class utilizing the Hausdorff distance to capture spatial dependence in both point and areal data. We introduce a valid correlation function within the HGP framework, accommodating diverse modeling techniques, including geostatistical and areal models. Integration into generalized linear mixed-effects models enhances its applicability, particularly in addressing change of support and data fusion challenges. We validate our approach through a comprehensive simulation study and application to two real-world scenarios: one involving areal data and another demonstrating its effectiveness in data fusion. The results suggest that the HGP is competitive with specialized models regarding goodness-of-fit and prediction performances. In summary, the HGP offers a flexible and robust solution for modeling spatial data of various types and shapes, with potential applications spanning fields such as public health and climate science.\n\n\nSlides"
  },
  {
    "objectID": "talks/2024-cobal/index.html",
    "href": "talks/2024-cobal/index.html",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "",
    "text": "Details\n\nDate: Dec 05, 2024\nLocation: Belo Horizonte, MG - Brazil\nSlides\n\n\n\nAbstract\nTuberculosis (TB) remains a significant global health challenge, and Brazil exemplifies the complexities of controlling this infectious disease. Reliable estimates and forecasts of TB incidence rates are crucial to guide public health policies. This study focuses on the high-burden municipalities of Eastern Rio Grande do Sul, Brazil. We propose a novel spatiotemporal model based on the Hausdorff-Gaussian process to analyze TB incidence data. This model incorporates spatial dependence dictated by the Hausdorff distance, allowing it to “borrow strength” from municipalities and generate more reliable estimates, particularly for smaller areas. Our analysis has two primary goals. First, we aim to generate accurate TB incidence estimates by incorporating municipality-specific characteristics through covariates and a spatiotemporal random effect. The model delivers trustworthy expected incidence rates, consequently allowing for calculating standardized incidence ratios (SIRs). Second, our model offers predictive capabilities, forecasting TB incidence ratesone year ahead to support proactive public health planning. We demonstrate our model’s effectiveness and competitive performance against other specialized areal data models. The insights gained from this study can guide policymakers in developing effective TB control strategies.\n\n\nSlides"
  },
  {
    "objectID": "talks/2018-rbras/index.html",
    "href": "talks/2018-rbras/index.html",
    "title": "Visualizing intramunicipality votes distribution",
    "section": "",
    "text": "Details\n\nDate: May 24, 2018\nLocation: Curitiba, Brazil\nSlides\n\n\n\nAbstract\nIn Brazil, socioeconomic data are available at census tracts (polygons), while election data are available at voting locations (point-referenced). The misaligned data make it challenging to study the association between election outcomes and socioeconomic variables. Given that the voters are assigned to the nearest electoral sections, we use Voronoi tessellation to associate each voting station with a Voronoi polygon. Areal interpolation is used to change the spatial support of the socioeconomic data.\n\n\nSlides"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Past\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n\n\n\n\n\ndrmr: A Bayesian approach to Dynamic Range Models in R\n\n\n\nSpecies distribution models\n\nPopulation dynamics\n\n\n\nTalk given at GCRG Spring lab meeting.\n\n\n\n\n\nApr 21, 2025\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nSTATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES\n\n\n\nSpatial statistics\n\nGaussian process\n\n\n\nTalk given at the Department of Epidemiology & Biostatistics at University of California San Francisco\n\n\n\n\n\nMar 12, 2025\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nGit & Friends\n\n\n\ncode\n\ngit\n\nVersion control\n\n\n\nTalk given at the EEB Department at UCSC\n\n\n\n\n\nFeb 3, 2025\n\n\nLucas da Cunha Godoy, Maya Zeff\n\n\n\n\n\n\n\nSpatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes\n\n\n\nSpatiotemporal statistics\n\nGaussian process\n\n\n\nTalk given at the XVII Encontro Brasileiro de Estatística Bayesiana and VII Congresso Bayesiano da América Latina\n\n\n\n\n\nDec 5, 2024\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nSTATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES\n\n\n\nSpatial statistics\n\nGaussian process\n\n\n\nTalk given at the Department of Statistics at Universidade Federal do Rio Grande do Sul\n\n\n\n\n\nNov 21, 2024\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nSTATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES\n\n\n\nSpatial statistics\n\nGaussian process\n\n\n\nTalk given at the Department of Statistics at UCSC\n\n\n\n\n\nOct 21, 2024\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nFROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE\n\n\n\nSpatial statistics\n\nGaussian process\n\n\n\nTalk given at the 2024 JSM\n\n\n\n\n\nAug 4, 2024\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nHAUSDORFF–GAUSSIAN PROCESS WITH A SPATIOTEMPORAL APPLICATION\n\n\n\nSpatial statistics\n\nGaussian process\n\nDisease mapping\n\nTuberculosis\n\nBrasil\n\n\n\nTalk given at the 37th NESS\n\n\n\n\n\nMay 23, 2024\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nHausdorff–Gaussian Process with Spatial and Spatiotemporal Applications\n\n\n\nSpatial statistics\n\nGaussian processes\n\nAir pollution\n\nDisease mapping\n\n\n\nPhD defense\n\n\n\n\n\nApr 10, 2024\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nSpatially misaligned data: An application to the 2018 Brazilian Presidential Election\n\n\n\nSpatial statistics\n\nElections\n\nVoronoi tesselation\n\nBrasil\n\n\n\nTalk given at the 34th NESS\n\n\n\n\n\nOct 1, 2021\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nVoronoi Data Linkage: Extracting Information from Polygons to Points\n\n\n\nSpatial statistics\n\nAreal interpolation\n\nElections\n\nBrasil\n\n\n\nTalk given in the 1st Conference on Statistics and Data Science\n\n\n\n\n\nOct 16, 2018\n\n\nLucas da Cunha Godoy\n\n\n\n\n\n\n\nVisualizing intramunicipality votes distribution\n\n\n\nSpatial statistics\n\nAreal interpolation\n\nElections\n\nBrasil\n\n\n\nTalk given at the 63rd RBRAS\n\n\n\n\n\nMay 24, 2018\n\n\nLucas da Cunha Godoy\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#the-challenge-limits-of-sdms",
    "href": "slides/2025-slmdrmr/index.html#the-challenge-limits-of-sdms",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "The Challenge & Limits of SDMs",
    "text": "The Challenge & Limits of SDMs\n\nCritical Challenge: Predicting species’ responses to global environmental change is vital for conservation and management.\nUsual Tool: Species Distribution Models (SDMs) have been the workhorse, correlating occurrences with environmental variables.\nLimitations of SDMs:\n\nCorrelative: Struggle to predict responses under novel future conditions (Pagel and Schurr 2012).\nEquilibrium Assumption: Often violated (Guisan and Thuiller 2005).\nLack Mechanism: Don’t explicitly model the underlying biological processes."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#dynamic-range-models-drms-a-mechanistic-approach",
    "href": "slides/2025-slmdrmr/index.html#dynamic-range-models-drms-a-mechanistic-approach",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Dynamic Range Models (DRMs): A Mechanistic Approach",
    "text": "Dynamic Range Models (DRMs): A Mechanistic Approach\n\nDRMs explicitly incorporate demographic processes that drive range dynamics (Pagel and Schurr 2012).\nAllows linking environmental drivers directly to specific processes\nPotential for more robust forecasting under novel conditions.\nWhy are they rarely in practice? Despite conceptual appeal, DRMs have been underutilized due to their complexity and computational fitting challenges."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#introducing-drmr-making-drms-accessible",
    "href": "slides/2025-slmdrmr/index.html#introducing-drmr-making-drms-accessible",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Introducing drmr: Making DRMs Accessible",
    "text": "Introducing drmr: Making DRMs Accessible\n\nGoal: Bridge the gap between DRM potential and practical application.\nKey Features:\n\nDevelops and applies age-structured DRMs in a Bayesian framework.\nUser-friendly interface.\nLeverages Stan via cmdstanr for efficient fitting (Gabry et al. 2024).\nEasily relate environmental drivers to specific recruitment and survival."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#zero-augmented-probability-distributions",
    "href": "slides/2025-slmdrmr/index.html#zero-augmented-probability-distributions",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Zero-augmented probability distributions",
    "text": "Zero-augmented probability distributions\n\nSpecies’ densities are non-negative continuous variables.\nZero-augmented vs. Zero-inflated Distributions:\n\nZero-inflated models apply to discrete distributions (e.g., Poisson counts). They increase (inflate) the probability of observing zeros, which is already a possible outcome (\\(P(Y = 0) &gt; 0\\)) in the base distribution.\nZero-augmented models apply to continuous distributions (e.g., densities). Since \\(P(Y = 0)\\) is theoretically \\(0\\) for continuous variables, these models add a discrete probability mass specifically at zero, augmenting the possibilities to include exact zeros."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#zero-augmented-probability-density-function-pdf",
    "href": "slides/2025-slmdrmr/index.html#zero-augmented-probability-density-function-pdf",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Zero-augmented probability density function (PDF)",
    "text": "Zero-augmented probability density function (PDF)\n\\[ f(y_{t, i} \\mid \\mu_{t, i}, \\phi, \\rho_{t, i}) = \\begin{cases} \\rho_{t, i}, &\n  \\text{ if } y_{t, i} = 0, \\\\ (1 - \\rho_{t, i}) g(y_{t, i} \\mid \\mu_{t, i},\n  \\phi), & \\text{ if } y_{t, i} &gt; 0, \\end{cases} \\]\n\n\\(\\rho_{t, i} = \\mathrm{Pr}(Y_{t, i} = 0)\\) is the probability of absence.\n\\(g(\\cdot \\mid \\mu_{t, i}, \\phi)\\) is the pdf of a continuous probability distribution.\n\\(\\mu_{t, i}\\) is the expected value (theoretical mean) of \\(Y_{t,\ni}\\) provided the species is present at time \\(t\\) and site \\(i\\)."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#setup",
    "href": "slides/2025-slmdrmr/index.html#setup",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Setup",
    "text": "Setup\n\n\\(Y_{a, t, i}\\): Unobserved density of individuals of age \\(a\\), time \\(t\\) and site \\(i\\).\n\\(\\lambda_{a, t, i}\\): Expected age-specific density.\n\\(Y_{t, i} = \\sum_{a} Y_{a, t, i}\\): Observed density of individuals of all ages at time \\(t\\) and site \\(i\\).\n\\(\\mu_{t, i} = \\sum_{a} \\lambda_{a, t, i}\\): Expected “overall” density.\nBiological processes are encoded through \\(\\lambda_{a, t, i}\\).\nKey processes: recruitment, survival, and movement"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#recruitment",
    "href": "slides/2025-slmdrmr/index.html#recruitment",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Recruitment",
    "text": "Recruitment\n\nExpected density for recruits: \\[ \\lambda_{1, t, i} = \\exp \\{ \\psi_{t, i} \\} \\]\nWhere \\(\\psi_{t, i}\\) is the expected log-transformed recruitment at time \\(t\\) and site \\(i\\).\nWe assume the expected log-transformed recruitment relates to the environmental drivers as follows: \\[ \\psi_{t, i} =\n\\boldsymbol{\\beta}^{\\top}_r \\mathbf{x}^{(r)}_{t, i} \\]\nIt is also possible to incorporate temporal dependence to recruitment through an AR(1) process."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#survival",
    "href": "slides/2025-slmdrmr/index.html#survival",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Survival",
    "text": "Survival\n\nExpected density at age \\(a\\), time \\(t\\), and patch \\(i\\): \\[\n\\lambda_{a, t, i} = \\lambda_{a - 1, t - 1, i} \\cdot s_{a - 1, t - 1, i} \\]\n\\(s_{a, t, i}\\) represents survival rates.\nWe assume the log-transformed survival rates relate to the environmental drivers as follows: \\[ \\log(s_{a, t, i}) =\n\\boldsymbol{\\beta}^{\\top}_s \\mathbf{x}^{(s)}_{t, i} - f_{a, t} \\]\nExternal information: additional mortality sources can be incorporated to the survival rates as well. Above, \\(f_{a, t}\\) is the instantaneous mortality rate for individuals of age \\(a\\) at time \\(t\\). Examples: fishing mortality, hunting, etc."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#movement",
    "href": "slides/2025-slmdrmr/index.html#movement",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Movement",
    "text": "Movement\n\nMovement is an important process affecting species’ densities.\nDue to a high computational cost, we offer only a simple way to account for movement.\nWe estimate the probability of individuals remaining in the same site (\\(\\zeta\\)) between two time points, and divide the probability of moving (\\(1 - \\zeta\\)) evenly across neighboring sites."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#main-functions",
    "href": "slides/2025-slmdrmr/index.html#main-functions",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Main Functions",
    "text": "Main Functions\n\nFitting: fit_drm, fit_sdm\nForecasting: predict_drm, predict_sdm\nVisualization: marg_rec, marg_surv, marg_pabs\nSimulation: pop_dyn, model_sim, pp_sim"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#summer-flounder-dataset",
    "href": "slides/2025-slmdrmr/index.html#summer-flounder-dataset",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Summer Flounder Dataset",
    "text": "Summer Flounder Dataset\n\nAn example analysis uses Summer flounder (Paralichthys dentatus) data from 1982-2016 NOAA bottom trawl surveys (Fredston et al. 2025) to illustrate the package’s features.\nThe data spans the US Atlantic coast (Cape Hatteras, NC to the Canada/Maine border) and was aggregated from individual hauls into 10 latitudinal patches with varying areas.\nResponse variable: Density (count per unit area).\nEnvironmental drivers: SST and SBT."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#patchessites",
    "href": "slides/2025-slmdrmr/index.html#patchessites",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Patches/sites",
    "text": "Patches/sites"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#fitting-a-simple-model",
    "href": "slides/2025-slmdrmr/index.html#fitting-a-simple-model",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Fitting a simple model",
    "text": "Fitting a simple model\n\nDefault model: two age groups with constant density and recruitment across time/space, and sets a fixed survival rate of \\(0.70\\) between age classes.\nOutput: is a list containing a stanfit object, equivalent to cmdstanr::sample() output, allowing full access to cmdstanr’s features for diagnostics, plotting, and assessment.\n\n\nlibrary(drmr) ## load package\ndata(sum_fl)  ## load data\nbaseline &lt;-\n  fit_drm(.data = dat_train,  ## dataset\n          y_col = \"dens\",     ## response variable\n          time_col = \"year\",  ## variable storing time\n          site_col = \"patch\", ## variable storing \"patch/site\" id\n          seed = 202505)      ## seed"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#parameter-estimates-diagnostics",
    "href": "slides/2025-slmdrmr/index.html#parameter-estimates-diagnostics",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Parameter estimates & diagnostics",
    "text": "Parameter estimates & diagnostics\n\nThe $summary method allows for checking the parameter estimates easily\n\n\nbaseline$stanfit$summary(variables = c(\"phi\", \"beta_r\"))\n\n# A tibble: 2 × 10\n  variable     mean  median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 phi[1]     1.08    1.08   0.0960 0.0945  0.925 1.24    1.00    4099.    3003.\n2 beta_r[1] -0.0792 -0.0818 0.0735 0.0734 -0.197 0.0411  1.00    4011.    3083."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#toggles-and-increased-model-complexity",
    "href": "slides/2025-slmdrmr/index.html#toggles-and-increased-model-complexity",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Toggles and increased model complexity",
    "text": "Toggles and increased model complexity\n\n\n\n\n\n\n\n\nToggle\nDescription\nDefault State\n\n\n\n\ncloglog\nUse the complementary log-log (cloglog) link function for absence probability. If off, the logistic link function is used.\nOff\n\n\nmovement\nEnable the movement routine as described.\nOff\n\n\nest_surv\nEstimate survival probabilities within the model.\nOn\n\n\nest_init\nEstimate \\(\\lambda\\) initial values.\nOff (this one has many options)\n\n\ntime_ar\nInclude an AR(1) term for recruitment.\nOff"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#models-fitted-to-this-example",
    "href": "slides/2025-slmdrmr/index.html#models-fitted-to-this-example",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Models fitted to this example",
    "text": "Models fitted to this example\n\n\n\n\n\n\n\nModel\nDescription\n\n\n\n\nbaseline\nBaseline model\n\n\ndrm_1\nRecruitment as a quadratic function of SST, and probability of absence depending on number of hauls, SST and SBT\n\n\ndrm_2\nSame as drm_1 + estimating constant survival rates\n\n\ndrm_3\nSame as drm_2 + AR(1) for recruitment\n\n\ndrm_4\nSame as drm_3 + movement and increasing number of age-classes to 6\n\n\ndrm_5\nSame as drm_3 and increasing number of age-classes to 6\n\n\ndrm_6\nSame as drm_3 + fishing mortality for specific age-classes at each time point (16 age-classes)\n\n\ndrm_7\nprobability of absence as drm_3; AR(1) for recruitment (but constant across patches) and survival depending on SBT\n\n\nsdm\nA zero-augmented Gamma SDM with the absence probability as in drm_3 and conditional density as a quadratic function of SST."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#code-for-fitting-a-complex-model",
    "href": "slides/2025-slmdrmr/index.html#code-for-fitting-a-complex-model",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Code for fitting a complex model",
    "text": "Code for fitting a complex model\n\ndrm_4 &lt;-\n  fit_drm(.data = dat_train,\n          y_col = \"dens\",\n          time_col = \"year\",\n          site_col = \"patch\",\n          family = \"gamma\",\n          seed = 202505,\n          formula_zero = ~ 1 + c_hauls + c_btemp + c_stemp,\n          formula_rec = ~ 1 + c_stemp + I(c_stemp * c_stemp),\n          formula_surv = ~ 1,\n          n_ages = 6,\n          adj_mat = adj_mat, ## A matrix for movement routine\n          ages_movement = c(0, 0, 1, 1, 1, 0), ## ages allowed to move\n          .toggles = list(est_surv = 1,\n                          time_ar = 1,\n                          movement = 1),\n          init = \"pathfinder\")"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#estimating-relationship-between-processes-and-environmental-variables",
    "href": "slides/2025-slmdrmr/index.html#estimating-relationship-between-processes-and-environmental-variables",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Estimating relationship between processes and environmental variables",
    "text": "Estimating relationship between processes and environmental variables\n\nRecruitment and SST:\n\n\nnewdata_rec &lt;- data.frame(c_stemp =\n                            seq(from = quantile(dat_train$c_stemp, .05),\n                                to = quantile(dat_train$c_stemp, .95),\n                                length.out = 200))\n\nrec_samples_3 &lt;- marg_rec(drm_3, newdata_rec)\n\n\nSurvival and SBT:\n\n\nnewdata_surv &lt;- data.frame(c_btemp =\n                             seq(from = quantile(dat_train$c_btemp, .05),\n                                 to = quantile(dat_train$c_btemp, .95),\n                                 length.out = 200))\n\nsurv_samples &lt;- marg_surv(drm_7, newdata_surv)"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#estimated-relationship-between-processes-and-environmental-variables",
    "href": "slides/2025-slmdrmr/index.html#estimated-relationship-between-processes-and-environmental-variables",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Estimated relationship between processes and environmental variables",
    "text": "Estimated relationship between processes and environmental variables"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#forecasting",
    "href": "slides/2025-slmdrmr/index.html#forecasting",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Forecasting",
    "text": "Forecasting\n\nThe code for obtaining out-of-sample predictions is quite intuitive.\nWe only need to provide the output for a model fit, a new dataset (where we want the predictions), and a seed:\n\n\nforecast_3 &lt;- predict_drm(drm = drm_3,\n                          new_data = dat_test,\n                          past_data = filter(dat_train,\n                                             year == max(year)),\n                          seed = 125,\n                          cores = 4)"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#comparing-models",
    "href": "slides/2025-slmdrmr/index.html#comparing-models",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Comparing models",
    "text": "Comparing models\n\n\n\n\n\n\n\n\n\n\n\nModel\n\\(\\Delta\\)-LOOIC\nRMSE\nIS\nPIC\nTime\n\n\n\n\ndrm_3\n0.00\n8.98\n8.60\n78.0\n13.34\n\n\nsdm\n-6.07\n12.04\n12.72\n60.0\n3.88\n\n\ndrm_4\n-7.35\n8.30\n8.87\n84.0\n28.7\n\n\ndrm_5\n-7.74\n8.23\n8.96\n86.0\n19.24\n\n\ndrm_7\n-10.41\n8.75\n8.97\n78.0\n22.73\n\n\ndrm_6\n-18.04\n10.22\n10.49\n86.0\n33.73\n\n\ndrm_1\n-22.49\n11.17\n10.68\n68.0\n4.67\n\n\ndrm_2\n-32.32\n10.73\n10.29\n68.0\n4.44\n\n\nbaseline\n-163.85\n14.44\n12.98\n74.0\n1.35"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#highlights",
    "href": "slides/2025-slmdrmr/index.html#highlights",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Highlights",
    "text": "Highlights\n\nThe drmr substantially lowers the barrier for ecologists to use the DRM in their applications.\nThe code is easy to use and takes advantage of what has been developed for Stan: visualization, diagnostic tools, and estimation.\ndrmr allows for empirically testing which processes are more important to predict the distribution of a species.\nThe more complex a model is, the more (and better) data we need to be able to estimate those relationships."
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#future-work",
    "href": "slides/2025-slmdrmr/index.html#future-work",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "Future work",
    "text": "Future work\n\nApplication to NE Mackerel\nMore options for spatial and temporal random effects for specific processes\nOther population dynamic models (e.g., Ricker, Belverton-Holt)\nGAM-like non-parametric relationships between processes and the environment\nSupport for length-composition data\nMore realistic movement routines"
  },
  {
    "objectID": "slides/2025-slmdrmr/index.html#references",
    "href": "slides/2025-slmdrmr/index.html#references",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "",
    "text": "References\n\n\nFredston, A., Ovando, D., Cunha Godoy, L. da, Kong, J., Muffley, B., Thorson, J. T., and Pinsky, M. (2025), “Dynamic range models improve the near-term forecast for a marine species on the move,” Ecology Letters, 00, (under review). https://doi.org/10.32942/X24D00.\n\n\nGabry, J., Češnovar, R., Johnson, A., and Bronder, S. (2024), cmdstanr: R interface to CmdStan.\n\n\nGuisan, A., and Thuiller, W. (2005), “Predicting species distribution: Offering more than simple habitat models,” Ecology letters, Wiley Online Library, 8, 993–1009. https://doi.org/https://doi.org/10.1111/j.1461-0248.2005.00792.x.\n\n\nPagel, J., and Schurr, F. M. (2012), “Forecasting species ranges by statistical estimation of ecological niches and spatial population dynamics,” Global Ecology and Biogeography, 21, 293–304. https://doi.org/https://doi.org/10.1111/j.1466-8238.2011.00663.x."
  },
  {
    "objectID": "slides/2025-frjune/index.html#overview",
    "href": "slides/2025-frjune/index.html#overview",
    "title": "FinRisk – June 2025 Update",
    "section": "Overview",
    "text": "Overview\n\ndrmr package: got authors approval to submit the current version of the paper. Package documentation available here.\nIn the last meeting, we briefly talked about data availability and key environmental drivers to study Mackerel’s distribution.\nA lot of time spent looking for the data and processing it.\nThe data from the survey we identified as the most approprate is “sparsely available”.\n\n\n\n\n\n\n\n\n\n\nSurvey\nDistribution\nStart\nAge structure\n\n\n\n\nIESSNS\nSummer feeding\n2010\nAge and size composition (Age 3+)\n\n\nBTS\nOverwinter\n1965\nAge-0 abundance index\n\n\nEgg Survey\nSpawning\n1992\nNo age structure"
  },
  {
    "objectID": "slides/2025-frjune/index.html#iessns-data",
    "href": "slides/2025-frjune/index.html#iessns-data",
    "title": "FinRisk – June 2025 Update",
    "section": "IESSNS data",
    "text": "IESSNS data\n\nPrevious papers using IESSNS data [e.g.; Ono et al. (2024)] mention the data is available from the Planning Group on Northeast Atlantic Pelagic Ecosystem Surveys (PGNAPES)\nI could not find that data on the ICES portal.\nI connectect with Anna Heiða Ólafsdóttir, she pointed that the PGNAPES data is not publicly available. Some of it is available through a hard to find ICES portal."
  },
  {
    "objectID": "slides/2025-frjune/index.html#data-processing",
    "href": "slides/2025-frjune/index.html#data-processing",
    "title": "FinRisk – June 2025 Update",
    "section": "Data processing",
    "text": "Data processing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\nV11\nV12\nV13\nV14\nV15\nV16\nV17\nV18\nV19\nV20\nV21\nV22\nV23\nV24\nV25\nV26\nV27\nV28\nV29\nV30\nV31\nV32\nV33\nV34\nV35\nV36\nV37\nV38\nV39\nV40\nV41\nV42\nV43\nV44\nV45\n\n\n\n\nCruise\nHeader\nCruiseSurvey\nCruiseCountry\nCruisePlatform\nCruiseStartDate\nCruiseEndDate\nCruiseOrganisation\nCruiseLocalID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCruise\nRecord\nIESSNS\nDK\n26AS\n2018-07-02\n2018-07-13\n2195\nIESSNS_DK_2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHaul\nHeader\nCruiseLocalID\nHaulGear\nHaulNumber\nHaulStationName\nHaulStartTime\nHaulDuration\nHaulValidity\nHaulStartLatitude\nHaulStartLongitude\nHaulStopLatitude\nHaulStopLongitude\nHaulStatisticalRectangle\nHaulMinTrawlDepth\nHaulMaxTrawlDepth\nHaulBottomDepth\nHaulDistance\nHaulNetopening\nHaulCodendMesh\nHaulSweepLength\nHaulGearExceptions\nHaulDoorType\nHaulWarpLength\nHaulWarpDiameter\nHaulWarpDensity\nHaulDoorSurface\nHaulDoorWeight\nHaulDoorSpread\nHaulWingSpread\nHaulBuoyancy\nHaulKiteArea\nHaulGroundRopeWeight\nHaulRigging\nHaulTickler\nHaulHydrographicStationID\nHaulTowDirection\nHaulSpeedGround\nHaulSpeedWater\nHaulWindDirection\nHaulWindSpeed\nHaulSwellDirection\nHaulSwellHeight\nHaulLogDistance\nHaulStratum\n\n\nHaul\nRecord\nIESSNS_DK_2018\nPEL\n1\n1\n2018-07-02T20:20\n30\nV\n57.882168\n9.613833\n57.905666\n9.561\n44F9\n0\n\n102\n4471\n28\n20\n\n\n\n\n\n\n\n\n122\n\n\n\n\n\n\n\n\n4.8\n\n\n\n\n\n\n\n\n\nHaul\nRecord\nIESSNS_DK_2018\nPEL\n2\n2\n2018-07-03T04:25\n30\nV\n57.835\n8.143167\n57.846\n8.072333\n44F8\n0\n\n525\n4683\n32\n20\n\n\n\n\n\n\n\n\n121\n\n\n\n\n\n\n\n\n5.1\n\n\n\n\n\n\n\n\n\nHaul\nRecord\nIESSNS_DK_2018\nPEL\n3\n3\n2018-07-03T09:26\n30\nV\n57.896\n6.6373334\n57.936333\n6.6435\n44F6\n0\n\n368\n4709\n35\n20\n\n\n\n\n\n\n\n\n121\n\n\n\n\n\n\n\n\n5.1"
  },
  {
    "objectID": "slides/2025-frjune/index.html#hauls",
    "href": "slides/2025-frjune/index.html#hauls",
    "title": "FinRisk – June 2025 Update",
    "section": "Hauls",
    "text": "Hauls"
  },
  {
    "objectID": "slides/2025-frjune/index.html#hauls-2024",
    "href": "slides/2025-frjune/index.html#hauls-2024",
    "title": "FinRisk – June 2025 Update",
    "section": "Hauls 2024",
    "text": "Hauls 2024"
  },
  {
    "objectID": "slides/2025-frjune/index.html#incorporating-bt",
    "href": "slides/2025-frjune/index.html#incorporating-bt",
    "title": "FinRisk – June 2025 Update",
    "section": "Incorporating BT",
    "text": "Incorporating BT"
  },
  {
    "objectID": "slides/2025-frjune/index.html#ices-rectangles",
    "href": "slides/2025-frjune/index.html#ices-rectangles",
    "title": "FinRisk – June 2025 Update",
    "section": "ICES “rectangles”",
    "text": "ICES “rectangles”"
  },
  {
    "objectID": "slides/2025-frjune/index.html#cpue-across-all-surveys-over-time",
    "href": "slides/2025-frjune/index.html#cpue-across-all-surveys-over-time",
    "title": "FinRisk – June 2025 Update",
    "section": "CPUE (across all surveys) over time",
    "text": "CPUE (across all surveys) over time"
  },
  {
    "objectID": "slides/2025-frjune/index.html#next-steps-questions",
    "href": "slides/2025-frjune/index.html#next-steps-questions",
    "title": "FinRisk – June 2025 Update",
    "section": "Next Steps & Questions",
    "text": "Next Steps & Questions\n\nMore data processing :(\nAlthough the spatiotemporal coverage we have is challenging, these are the circumstanes where model-based approaches (e.g., DRM) “shine”\nFor the models, I need to be careful and think about how to incorporate the information from the different surveys (suggestions welcome)\nWhat spatial resolution would be best for the translational tools and economical risk part of the project?\nIs the main goal to quantify range shifts or are we aiming at forecasting abundance / Biomass?"
  },
  {
    "objectID": "slides/2025-frjune/index.html#references",
    "href": "slides/2025-frjune/index.html#references",
    "title": "FinRisk – June 2025 Update",
    "section": "",
    "text": "References\n\n\nOno, K., Katara, I., Eliasen, S. K., Broms, C., Campbell, A., Santos Schmidt, T. C. dos, Egan, A., Hølleland, S. N., Jacobsen, J. A., Jansen, T., Mackinson, S., Mousing, E. A., Nash, R. D. M., Nikolioudakis, N., Nnanatu, C., Nøttestad, L., Singh, W., Slotte, A., Wieland, K., and Olafsdottir, A. H. (2024), “Effect of environmental drivers on the spatiotemporal distribution of mackerel at age in the Nordic Seas during 2010-20,” ICES Journal of Marine Science, 81, 1282–1294. https://doi.org/10.1093/icesjms/fsae087."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#spatial-statistics",
    "href": "slides/2024-ufrgs/index.html#spatial-statistics",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Spatial Statistics",
    "text": "Spatial Statistics\n\nTaking into account spatial dependence possibly present in data is a foremost aspect of spatial statistics.\nGeneral spatial model (Cressie 1993): \\(\\{\nZ(\\mathbf{s}) \\; : \\; \\mathbf{s} \\in D \\}\\), where \\(D\\) is an index set.\nStatistical inference depends heavily on the spatial structure/geometry of the observed spatial data.\n\n\n\n\nGeometry\nBranch\nIndex set\n\n\n\n\nAreas/polygons\nAreal models\nCountable\n\n\nPoints\nGeostatistics\nContinuum\n\n\nMixed\nSpatial Data Fusion\n\n\n\n\n\n\nChallenges arise when working with data from different sources:\n\nChange of support\nSpatial misalignment\nData fusion itself.\n\n\nLoosely speaking, this means the GP has stationary mean, variance, and a correlation function such that the correlation between two data points depends solely on their distance.\n\nCommon assumptions are stationarity and isotropy.\nImportance in spatial statistics: predominant foundation of geostatistical modeling.\nCompletely specified by mean and covariance functions.\n\nThe main reasons these models are not applied to areal data are:\n\nCalculating distance between areal spatial units is non-trivial;\nThe commonly used areal models are computationally efficient."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#classic-models-for-spatial-data",
    "href": "slides/2024-ufrgs/index.html#classic-models-for-spatial-data",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Classic Models for Spatial Data",
    "text": "Classic Models for Spatial Data\n\nAreal data\n\nCAR (Besag 1974), ICAR, BYM (Besag et al. 1991), DAGAR (Datta et al. 2019).\n\nPoint-referenced data\n\nGaussian processes (GP), Nearest-neighbor mixture processes (Zheng et al. 2023)\n\nMixed/fused data\n\n“Aggregated” GP (AGP) (Moraga et al. 2017): \\[\nZ(\\mathbf{s}_i)\n= \\begin{cases}\nZ(\\mathbf{s}_i), & \\text{if } \\mathcal{A}(\\mathbf{s}_i) = 0 \\\\\n{\\mathcal{A}(\\mathbf{s}_i)}^{-1}\n\\int_{\\mathcal{A}(\\mathbf{s}_i)} Z(\\mathbf{s}) \\mathrm{d}\\mathbf{s}, & \\text{if }\n\\mathcal{A}(\\mathbf{s}_i) &gt; 0\n\\end{cases}\n\\]\n\n\n\n\nAreal models are usually heteroscedastic; The marginal variances decrease with the number of neighbors;\nData fusion models are also heteroscedastic (unless all the polygons are of the same size); computationally prohibitive for moderately large datasets; arbitrary choice of grid resolution."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#research-questions",
    "href": "slides/2024-ufrgs/index.html#research-questions",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Research Questions",
    "text": "Research Questions\n\nThe main research questions we are interested in are:\n\nCan we propose a model for spatial data that accomodates areal, point-referrenced, and fused data?\nIf so, is this model competitive when compared to specialized models?\n\nProposal: An isotropic GP defined on a flexible index set.\nMain challenge: Defining a valid correlation function."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#preliminaries",
    "href": "slides/2024-ufrgs/index.html#preliminaries",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nPoint-referenced and areal spatial units are (closed and bounded) sets.\nWe need to generalize distance between points to distance between sets.\nIdeally, this distance should:\n\nTake into account the shape, size, and orientation of spatial sample units.\nBe “spatially interpretable”."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#distances-between-sets",
    "href": "slides/2024-ufrgs/index.html#distances-between-sets",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Distances between sets",
    "text": "Distances between sets\n\nMetric space: \\((D, d)\\), where \\(D\\) is a spatial region of interest.\nDistance between a point and a set: \\(d(x, A) = \\inf_{a \\in A}\nd(x, a)\\), where \\(d(x, y)\\) is the distance between any two elements \\(x, y \\in\nD\\)\nDirected Hausdorff distance: \\[{\\vec h}(A, B) = \\sup_{a \\in A}\nd(a, B)\\]\nHausdorff distance: \\[h(A, B) = \\max \\left \\{ \\vec{h}(A, B),\n\\vec{h}(B, A) \\right \\}\\]\n\n\n\nSymmetric Hausdorff distance: the greater of the two directed Hausdorff distances.\nNote that if \\(A\\) and \\(B\\) are both singletons, then \\(h(A, B) = d(A, B)\\).\n\nMeric Properties: (1) Symmetry: \\(d(x, y) = d(y, x)\\); (2) Nonnegativeness: \\(d(x,\ny) \\geq 0\\) and \\(d(x, x) = 0\\); (3)Positiveness: \\(d(x, y) = 0 \\implies x = y\\); (4) Triangle inequality: \\(d(x, y) \\leq d(x, z) + d(z, y)\\)"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#hausdorff-distance-for-spatial-data-analysis",
    "href": "slides/2024-ufrgs/index.html#hausdorff-distance-for-spatial-data-analysis",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Hausdorff Distance for Spatial Data Analysis",
    "text": "Hausdorff Distance for Spatial Data Analysis\n\nStudy region: In spatial statistics, \\(D\\) is tipically a closed and bounded subset of \\(\\mathbb{R}^2\\).\nIn this context, the Hausdorff distance is a metric (Sendov 2004).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetric on \\(D \\setminus \\varnothing\\)\nThe Hausdorff distance ability to account for spatial units’ shapes, sizes and orientation(Min et al. 2007) renders it an interesting tool to achieve our goals.\nMoreover, it can distinguish between overlapping, nested, and disjointed regions.\nIn the figure: (1) The dashed lines denote the Hausdorff distances; (2) The infimum distance between to sets is zero for the three cases; (3) Distance between centroids is the same for the first two figures."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#the-hgp",
    "href": "slides/2024-ufrgs/index.html#the-hgp",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "The HGP",
    "text": "The HGP\n\nIndex set: \\(\\mathcal{B}(D)\\) represents the closed and bounded subsets of \\(D \\subset \\mathbb{R}^2\\).\n\\(Z(\\mathbf{s}) \\sim \\mathrm{HGP}\\{m(\\mathbf{s}), v(\\mathbf{s}), r(h)\\}\\), where \\(\\mathbf{s} \\in \\mathcal{B}(D)\\).\nMean function: \\(m(\\mathbf{s}) = \\mathbb{E}[Z(\\mathbf{s})]\\)\nCovariance function: \\(\\mathrm{Cov}(Z(\\mathbf{s}_1),\nZ(\\mathbf{s}_2)) = v(\\mathbf{s}_1) v(\\mathbf{s}_2) r(h(\\mathbf{s}_1,\n\\mathbf{s}_2))\\)\nSD function: \\(v(\\mathbf{s}) =\n\\sqrt{\\mathrm{Var}(Z(\\mathbf{s}))}\\)\nCorrelation function: \\(r(h) =\n\\mathrm{Cor}(Z(\\mathbf{s}_1), Z(\\mathbf{s}_2)),\\) where \\(h\\) denotes the Hausdorff distance between \\(\\mathbf{s}_1, \\mathbf{s}_2 \\in\n\\mathcal{B}(D)\\).\n\n\n\nIdeally, we want bounded, compact, and non-empty sets for the Hausdorff distance to be a metric..\nIn \\(\\mathbb{R}^2\\), a compact subset is bounded.\nempty is a subset of any set -&gt; it is bounded bc a subset of a bounded set is bounded itself.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nThe SD function allows the HGP to accommodate both homoscedastic and heteroscedastic scenarios."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#the-vmathbfs-function",
    "href": "slides/2024-ufrgs/index.html#the-vmathbfs-function",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "The \\(v(\\mathbf{s})\\) function",
    "text": "The \\(v(\\mathbf{s})\\) function\nWe may defined: \\[v(\\mathbf{s}) = \\exp \\{ \\alpha_0 + \\alpha_1 w(\\mathbf{s})\n\\},\\] where \\(w(\\mathbf{s})\\) is a covariate available for any \\(\\mathbf{s} \\in\n\\mathcal{B}(D)\\).\n\nUseful special cases:\n\nHomoscedastic: \\(w(\\mathbf{s}) = 0\\) (consequence, \\(\\sigma =\n\\exp \\{ \\alpha_0 \\}\\))\nData Fusion: \\(w(\\mathbf{s}) =\n\\mathbb{1}(\\mathcal{A}(\\mathbf{s}) &gt; 0)\\).\nArea dependent: \\(w(\\mathbf{s}) = \\mathcal{A}(\\mathbf{s})\\)\n\nAlthough flexible, one has to be careful when choosing this function to ensure the process validity (Palacios and Steel 2006).\n\n\n\nfor data fusion: \\(\\sigma_a = \\exp \\{ \\alpha_0 + \\alpha_1 \\}\\)."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#ensuring-the-process-validity",
    "href": "slides/2024-ufrgs/index.html#ensuring-the-process-validity",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Ensuring the process’ validity",
    "text": "Ensuring the process’ validity\nFor a valid process, its correlation function must satisfy the following properties:\n\nDiminish with increasing distance: \\(\\lim_{h \\to \\infty}r(h) = 0\\).\nBounded from above by 1: \\(r(0) = 1\\).\nPositive-definiteness: yields positive-definite correlation matrices for all its finite-dimensional marginal distributions.\nUnfortunately, functions that are guaranteed to be positive-definite on \\((\\mathbb{R}^2, \\lVert \\cdot\n\\rVert_2)\\) are not necessarily positive definite on other metric spaces (Li et al. 2023)."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#the-powered-exponential-correlation-pec-function",
    "href": "slides/2024-ufrgs/index.html#the-powered-exponential-correlation-pec-function",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "The Powered Exponential Correlation (PEC) Function",
    "text": "The Powered Exponential Correlation (PEC) Function\n\nPEC function: \\[r(h; \\phi, \\nu) = \\exp\\left \\{ -\n\\frac{h^{\\nu}}{\\phi^{\\nu}}\\right \\},\\] where \\(\\nu\\) is a smoothness parameter and \\(\\phi\\) governs the range of the spatial dependence.\n\n\nParametrization: We reparametrize this function with \\(\\rho =\n{\\log(10)}^{1 / \\nu} \\phi\\).\nInterpretation: \\(\\rho\\) is the distance at which the spatial correlation reduces to \\(0.10\\).\n\n\n\nexplain \\(\\rho\\)."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#visualizing-the-pec-function",
    "href": "slides/2024-ufrgs/index.html#visualizing-the-pec-function",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Visualizing the PEC function",
    "text": "Visualizing the PEC function"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#theoretical-foundation-positive-definiteness-of-the-pec",
    "href": "slides/2024-ufrgs/index.html#theoretical-foundation-positive-definiteness-of-the-pec",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Theoretical Foundation: Positive Definiteness of the PEC",
    "text": "Theoretical Foundation: Positive Definiteness of the PEC\n\n\n\nProposition\n\n\nLet \\(h = h(\\mathbf{s}, \\mathbf{s}')\\) be the Hausdorff distance between two spatial units, denoted \\(\\mathbf{s}, \\mathbf{s}' \\in \\mathcal{B}(D)\\), where \\(D\n\\subset \\mathbb{R}^2\\). The powered exponential correlation function \\(\\exp \\{ -\nh^{\\nu} / \\phi^{\\nu} \\}\\) is positive definite for \\(\\nu \\in (1/2, 1)\\).\n\n\n\n\nThe theorem above guarantees the validity of the HGP equipped with a PEC function with \\(\\nu \\in\n(1/2, 1)\\).\nThe proof is based on embedding the Hausdorff distance into a high-dimensional \\(L_1\\) normed Euclidean space, and using the fact that the exponential correlation function is positive definite on this space."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#empirical-assessment-of-positive-definiteness",
    "href": "slides/2024-ufrgs/index.html#empirical-assessment-of-positive-definiteness",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Empirical Assessment of Positive Definiteness",
    "text": "Empirical Assessment of Positive Definiteness\n\n\n\nthe graph displays the smallest eigenvalue of the correlation matrix induced by \\(\\rho\\) (x-axis) and \\(\\nu\\) (y-axis).\nThese matrices are based on the two spatial applications we will discuss in the next chapter.\nThe transparent regions indicate the regions of the parametric space where rho is smaller than 0."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#hgp-recap",
    "href": "slides/2024-ufrgs/index.html#hgp-recap",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "HGP Recap",
    "text": "HGP Recap\n\nFlexibility: A process that handles point-referrenced, areal, and mixed spatial data by construction.\nHausdorff distance: Enables HGP’s correlation function to account for the shape, size, and orientation of spatial objects.\nValidity: Using a PEC function ensures the HGP is a valid process.\n\n\n\n\n\n\nflowchart LR\n    A(Flexible index set) ==&gt; B(GP)\n    B ==&gt; E(((HGP)))\n    C(Hausdorff distance) ==&gt; D(PEC)\n    D ==&gt; E"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#spatial-glmm",
    "href": "slides/2024-ufrgs/index.html#spatial-glmm",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Spatial GLMM",
    "text": "Spatial GLMM\nA generalized linear mixed effects model (GLMM) can be written as \\[\\begin{aligned}\n& Y(\\mathbf{s}_i) \\mid \\mathbf{x}_i, Z(\\mathbf{s}_i) \\overset{{\\rm ind}}{\\sim}\n  f(\\cdot \\mid \\mu_i, \\boldsymbol{\\gamma}) \\\\\n& g(\\mu_i) = \\mathbf{x}_i \\boldsymbol{\\beta} +\n  Z(\\mathbf{s}_i).\n\\end{aligned}\\]\n\nProbability distribution: \\(f(\\cdot)\\)\nConditional mean: \\(\\mu_i = \\mathbb{E}[Y(\\mathbf{s}_i) \\mid\n\\mathbf{x}_i, Z(\\mathbf{s}_i)]\\)\nLink function: \\(g(\\cdot)\\)\nModel parameters: \\(\\boldsymbol{\\theta} =\n{\\{\\boldsymbol{\\beta}^\\top, \\boldsymbol{\\sigma}^\\top,\n\\boldsymbol{\\delta}^\\top, \\boldsymbol{\\gamma}^\\top \\}}^\\top\\)\nJoint density: \\(p(\\mathbf{y} \\mid \\mathbf{z}, \\boldsymbol{\\theta}) =\n\\prod_{i = 1}^n f(y(\\mathbf{s}_i) \\mid \\mu_i, \\boldsymbol{\\gamma})\\)\n\n\n\nRealizations of random variables are represented by lowercase letters.\nModel paramers are greek letters.\nUnder a frequentist perspective, we consider the random effects to follow an HGP.\nFor Bayesian inference, we use the HGP as a prior for the random effects.\nResponse variable \\(Y\\) at a spatial unit \\(s\\) is modeled with an appropriate distribution (e.g., Poisson, Bernoulli).\nCovariates (\\(X\\)) and spatial random effects (\\(Z\\)) explain variation in the conditional mean (\\(\\mu\\)).\nThe HGP defines the spatial random effects (\\(Z\\)), capturing spatial correlation with the Hausdorff distance and a correlation function."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#priors",
    "href": "slides/2024-ufrgs/index.html#priors",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Priors",
    "text": "Priors\n\nIndependent normal priors for the regression coefficients: \\(\\boldsymbol{\\beta} \\sim \\mathcal{N}(\\mathbf{0}, 10 \\mathbf{I})\\)\nHGP prior for the latent random effects: \\(\\mathbf{Z} \\sim\n\\mathrm{HGP}\\{0, v(\\cdot), r(\\cdot) \\}\\)\nExponential prior for the spatial dependence parameter: \\(\\rho\n\\sim \\mathrm{Exp}(a_\\rho)\\), where \\(a_{\\rho} = - \\log(p_{\\rho}) / \\rho_0\\).\n\n\\(a_\\rho\\) is chosen such that \\(\\mathbb{P}(\\rho \\geq \\rho_0) = p_\\rho\\).\n\nHomoscedastic variance: \\(v(\\mathbf{s}) =\n\\sqrt{\\mathrm{Var}(Z(\\mathbf{s}))} = \\sigma \\sim t_{+}(3)\\)\nHeteroscedastic HGP: \\(\\alpha \\sim \\mathcal{N}(\\mathbf{0},\n\\mathbf{I})\\), where \\(v(\\mathbf{s}) = \\exp \\{ \\alpha_0 + \\sum_i \\alpha_i w_i(\\mathbf{s}) \\}\\).\n\n\n\nFor \\(\\rho\\), the prior is inspired in penalized complexity priors. A conservative, but reasonable, choice for its hyperparameter is setting \\(a_\\rho\\) such that \\(\\rho_0\\) is a surprisingly low practical range and \\(p_rho\\) is a small probability (i.e., around .01)"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#bayesian-inference-model-assessment",
    "href": "slides/2024-ufrgs/index.html#bayesian-inference-model-assessment",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Bayesian Inference & Model Assessment",
    "text": "Bayesian Inference & Model Assessment\n\nPosterior: \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y},\n\\mathbf{z}) \\propto p(\\mathbf{y} \\mid \\mathbf{z}, \\boldsymbol{\\theta})\np(\\mathbf{z} \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta})\\)\nMCMC sampler: No-U-Turn (Homan and Gelman 2014).\nConvergence assessment: traceplots and split-\\({\\hat{R}}\\) (Vehtari et al. 2021).\nGoodness-of-fit criteria: LOOIC (lower values indicate better fit)\nPosterior predictive distributions: \\(p(\\mathbf{y}^{\\ast} \\mid\n\\mathbf{y})\\)\nPredictions assessment: Interval Score (IS) and RMSP (lower values indicate better fit)\n\n\n\nPoint and interval estimates: median and percentiles (\\(0.025\\) and \\(0.975\\)) of the marginal MCMC samples.\nParameters initialized by random sampling from their priors.\nRandom effects initialized from a standard normal distribution.\n\\(a_\\rho\\) is chosen so that: \\(\\mathbb{P}(\\rho &gt; U) = p_\\rho\\). In particular, \\(a_\\rho = - \\log(p_\\rho) / \\rho_0\\).\n\\(\\nu\\) hard to be estimated.\n\nPredictions:\n\nuse the properties of GP and multivariate Normal distribution to obtain the closed-form distribution of the vector of spatial random effects \\(\\mathbf{Z}^\\ast\\) (Diggle et al. 1998);\nsample \\(\\mathbf{z}^\\ast_{(b)}\\) from the distribution derived in the previous step;\nsample \\(\\mathbf{y}^{\\ast}_{(b)}\\) from \\(p(\\mathbf{y}^{\\ast} \\mid \\boldsymbol{\\theta}_{(b)},\n\\mathbf{z}^{\\ast}_{(b)})\\), where \\(\\boldsymbol{\\theta}_{(b)}\\) is the \\(b\\)-th MCMC sample of \\(\\boldsymbol{\\theta}\\)."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#bayesian-modeling-recap",
    "href": "slides/2024-ufrgs/index.html#bayesian-modeling-recap",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Bayesian Modeling Recap",
    "text": "Bayesian Modeling Recap\n\nHGP as a prior for the random effects disribution in a GLMM.\nBayesian inference through MCMC.\nUncertainty quantification of predictions through the posterior predictive distributions.\n\n\nDAGAR priors: \\[\n\\begin{aligned}\n  \\pi(\\beta_0) & \\propto 1 \\\\\n  \\beta_1 & \\sim N(0, 1000^2) \\\\\n  \\tau & \\sim Gamma(2, 1) \\\\\n  \\psi & \\sim U(0, 1).\n\\end{aligned}\n\\] - Precision matrix is defined based on the order of the observations and adjacency matrix (and the two parameters)"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#respiratory-disease-hospitalization-in-glasgow",
    "href": "slides/2024-ufrgs/index.html#respiratory-disease-hospitalization-in-glasgow",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Respiratory Disease Hospitalization in Glasgow",
    "text": "Respiratory Disease Hospitalization in Glasgow"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#respiratory-disease-hospitalization-in-glasgow-1",
    "href": "slides/2024-ufrgs/index.html#respiratory-disease-hospitalization-in-glasgow-1",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Respiratory Disease Hospitalization in Glasgow",
    "text": "Respiratory Disease Hospitalization in Glasgow\n\\[\\begin{aligned}\n& (Y(\\mathbf{s}_i) \\mid x_i, z(\\mathbf{s}_i)) \\sim \\text{Poisson}(E_i \\mu_i) \\\\\n& \\log(\\mu_i) = \\beta_0 + x_i \\beta_1 + z(\\mathbf{s}_i)\n\\end{aligned}\\]\n\nSample units: 134 intermediate zones (IZ), where the \\(i\\)-th IZ is denoted \\(\\mathbf{s}_i\\).\nNumber of hospitalizations: \\(\\mathbf{Y} = {(Y(\\mathbf{s}_1),\n\\ldots, Y(\\mathbf{s}_n))}^\\top\\).\nExpected number of hospitalizations based on the national age- and sex-standardized rates: \\(E_i\\).\nPercentage of people classified as income deprived: \\(x_i\\).\n\n\n\nData from the north portion of the river Clyde in the Great Glasgow and Clyde health board in Scotland.\nAssumption: Conditional on \\(\\mathbf{Z}\\), \\(\\mathbf{Y}\\) are mutually independent.\nExplain goals of the analysis–estimate risks adjusted for income deprivation, compare methods.\n\\(\\mu_i\\) is the expected SIR at region \\(i\\).\nOutline the modeling choices (HGP, DAGAR, BYM), briefly mention priors."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#disease-mapping-estimation-gof",
    "href": "slides/2024-ufrgs/index.html#disease-mapping-estimation-gof",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Disease Mapping: Estimation & GOF",
    "text": "Disease Mapping: Estimation & GOF\n\n\n\n\n\n\n\n\n\n\nHGP\nDAGAR\n\n\n\n\n\\(\\beta_0\\)\n-0.21 (-0.268, -0.139)\n-0.26 (-0.450, -0.137)\n\n\n\\(\\beta_1\\)\n0.33 (0.284, 0.368)\n0.31 (0.258, 0.370)\n\n\n\\(\\sigma\\)\n0.19 (0.155, 0.234)\n0.30 (0.218, 0.484)\n\n\n\\(\\rho\\)\n2.25 (0.159, 6.948)\n\n\n\n\\(\\psi\\)\n\n0.43 (0.069, 0.827)\n\n\n\n\n\n\n\n\n\n\n\n\nLOOIC\n1081.0\n1081.9\n\n\n\n\n\n\nmedian (95% CI)\nsimilar estimates for covariate\nHGP indicates weak spatial correlation\nDAGAR and BYM spatial dependence are not helpful as they indicate the spatial correlation goes from weak to strong (according to the CI)"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#disease-mapping-spatial-dependence",
    "href": "slides/2024-ufrgs/index.html#disease-mapping-spatial-dependence",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Disease Mapping: Spatial Dependence",
    "text": "Disease Mapping: Spatial Dependence\n\n\n\nHGP provides more insight into spatial dependence\nWe could also plot the correlation function itself"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#disease-mapping-adjusted-sir",
    "href": "slides/2024-ufrgs/index.html#disease-mapping-adjusted-sir",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Disease Mapping: Adjusted SIR",
    "text": "Disease Mapping: Adjusted SIR\n\n\n\nFitted values are similar among the three models\nSome regions with very low risks are shrunk toward a “regional mean”"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#air-pollution-in-ventura-and-los-angeles",
    "href": "slides/2024-ufrgs/index.html#air-pollution-in-ventura-and-los-angeles",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Air Pollution in Ventura and Los Angeles",
    "text": "Air Pollution in Ventura and Los Angeles\n\n\n\n\\[(Y(\\mathbf{s}_i) \\mid z(\\mathbf{s}_i)) \\sim\n  \\mathcal{N}(\\beta_0 + z(\\mathbf{s}_i), \\tau^2)\\]\n\nPM2.5: \\(\\mathbf{Y} = {(Y(\\mathbf{s}_1), \\ldots,\nY(\\mathbf{s}_n))}^\\top\\).\nPoint-referrenced data from 19 measurement stations available daily from 1999 to date;\nSatellite-derived estimates (2010–2012) at 184 areal units.\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngoals: (1); estimate model parameters using both sources. (2) use satellite data to help with interpolation.\nsquare areas (average size \\(\\approx\\) 101.95 km2)\ndata fusion challenges\nadaptability of the hgp to different problems.\nPm25 scale is micrometre per cubic meter: one one-millionth of a meter.\nconditional on \\(z\\) the \\(y\\)s are mutually independent.\nPriors on random effects: AGP1 and 2; heteroscedastic HGP with different variances for areal and point-referrenced data."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#agp-approximation",
    "href": "slides/2024-ufrgs/index.html#agp-approximation",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "AGP Approximation",
    "text": "AGP Approximation"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#air-pollution-estimation-and-prediction-assessment",
    "href": "slides/2024-ufrgs/index.html#air-pollution-estimation-and-prediction-assessment",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Air Pollution: Estimation and Prediction Assessment",
    "text": "Air Pollution: Estimation and Prediction Assessment\n\n\n\n\n\n\n\n\n\n\n\nHGP\n\\(\\rm AGP_1\\)\n\\(\\rm AGP_2\\)\n\n\n\n\n\\(\\beta\\)\n5.61 (4.69, 6.45)\n6.22 (2.16, 10.10)\n6.19 (5.88, 6.48)\n\n\n\\(\\rho\\)\n13.83 (7.82, 23.61)\n13.16 (5.14, 30.24)\n0.63 (0.46, 0.83)\n\n\n\\(\\tau\\)\n0.18 (0.07, 0.31)\n1.39 (1.24, 1.56)\n0.54 (0.39, 0.72)\n\n\n\\(\\sigma\\)\n3.85 (2.92, 5.18)\n1.70 (0.96, 2.91)\n2.41 (2.024, 2.84)\n\n\n\\(\\sigma_a\\)\n1.24 (1.04, 1.51)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRMSP\n1.05\n1.45\n1.64\n\n\nWidth\n3.57\n2.53\n9.67\n\n\nCPP\n95.5\n78.6\n95.5\n\n\nIS\n4.80\n15.11\n13.65\n\n\n\n\n\n\n\\(\\rho\\) rescaled to 100s of km.\nstaggering difference in estimates of the same model with different meshes."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#air-pollution-change-of-support",
    "href": "slides/2024-ufrgs/index.html#air-pollution-change-of-support",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Air Pollution: Change-of-Support",
    "text": "Air Pollution: Change-of-Support\n\n\n\nFigure confirms what we learned from 10-fold CV and simulation studies.\nHGP allows to use data from different sources seamlessly\nNo dependence on meshes/grids\nApparently, a parsimonious compromise between the two meshes.\nOnce again, the AGP seems highly dependend on the mesh and this is not highlighted in the literature."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#applications-key-findings",
    "href": "slides/2024-ufrgs/index.html#applications-key-findings",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Applications: key findings",
    "text": "Applications: key findings\n\nThe proposed method consistently demonstrated performance comparable to specialized models tailored for areal and fused data.\nUnlike traditional areal models, the HGP’s marginal variances are independent of the number of neighbors.\nThe HGP model simplifies data fusion by bypassing the need to define arbitrary grids for numerical integral evaluation, eliminating this step each time the joint probability distribution of the data and parameters is calculated.\nAcross both applications, the HGP provides an interpretable spatial dependence parameter and a spatial correlation function."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#highlights",
    "href": "slides/2024-ufrgs/index.html#highlights",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Highlights",
    "text": "Highlights\nThe HGP has proven to be a powerful model that offers:\n\nVersatility: accomodates diverse spatial data types.\nPerformance: competitive against models designed for specific spatial data types.\nReliable predictions: prediction intervals with near nominal frequentist coverage.\nOur conclusions are further supported by a comprehensive simulation study, detailed in our available preprint.\n\n\nKey Takeaway: The HGP’s versatility and performance make it a valuable tool in your spatial analysis toolkit."
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#future-work-and-limitations",
    "href": "slides/2024-ufrgs/index.html#future-work-and-limitations",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Future work and Limitations",
    "text": "Future work and Limitations\n\nExtensions:\n\nnon-Euclidean spaces\nBig data\n\nLimitations:\n\nBig “n” problem inherited from geostatistics\nUnclear how to incorporate anisotropy\nDifficulties in obtaining spectral densities for correlation functions"
  },
  {
    "objectID": "slides/2024-ufrgs/index.html#references",
    "href": "slides/2024-ufrgs/index.html#references",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "",
    "text": "References\n\n\nBesag, J. (1974), “Spatial interaction and the statistical analysis of lattice systems,” Journal of the Royal Statistical Society. Series B (Methodological), JSTOR, 192–236.\n\n\nBesag, J., York, J., and Mollié, A. (1991), “Bayesian image restoration, with two applications in spatial statistics,” Annals of the Institute of Statistical Mathematics, 43, 1–20.\n\n\nCressie, N. (1993), Statistics for spatial data, Wiley series in probability and statistics, Wiley.\n\n\nDatta, A., Banerjee, S., Hodges, J. S., and Gao, L. (2019), “Spatial disease mapping using directed acyclic graph auto-regressive (DAGAR) models,” Bayesian analysis, NIH Public Access, 14, 1221.\n\n\nDiggle, P. J., Tawn, J. A., and Moyeed, R. A. (1998), “Model-based geostatistics,” Journal of the Royal Statistical Society Series C: Applied Statistics, Oxford University Press, 47, 299–350.\n\n\nHoman, M. D., and Gelman, A. (2014), “The No-U-turn sampler: Adaptively setting path lengths in hamiltonian Monte Carlo,” Journal of Machine Learning Research, JMLR.org, 15, 1593–1623.\n\n\nLi, D., Tang, W., and Banerjee, S. (2023), “Inference for Gaussian processes with Matérn covariogram on compact Riemannian manifolds,” Journal of Machine Learning Research, 24, 1–26.\n\n\nMin, D., Zhilin, L., and Xiaoyong, C. (2007), “Extended Hausdorff distance for spatial objects in GIS,” International Journal of Geographical Information Science, Taylor & Francis, 21, 459–475.\n\n\nMoraga, P., Cramb, S. M., Mengersen, K. L., and Pagano, M. (2017), “A geostatistical model for combined analysis of point-level and area-level data using INLA and SPDE,” Spatial Statistics, Elsevier, 21, 27–41.\n\n\nPalacios, M. B., and Steel, M. F. J. (2006), “Non-Gaussian Bayesian geostatistical modeling,” Journal of the American Statistical Association, Taylor & Francis, 101, 604–618.\n\n\nSendov, B. (2004), “Hausdorff distance and image processing,” Russian Mathematical Surveys, IOP Publishing, 59, 319. https://doi.org/10.1070/RM2004v059n02ABEH000721.\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., and Bürkner, P.-C. (2021), “Rank-normalization, folding, and localization: An improved \\(\\hat{R}\\) for assessing convergence of MCMC (with discussion),” Bayesian Analysis, International Society for Bayesian Analysis, 16, 667–718.\n\n\nZheng, X., Kottas, A., and Sansó, B. (2023), “Nearest-neighbor mixture models for non-gaussian spatial processes,” Bayesian Analysis, International Society for Bayesian Analysis, 18, 1191–1222."
  },
  {
    "objectID": "slides/2024-jsm/index.html#spatial-statistics",
    "href": "slides/2024-jsm/index.html#spatial-statistics",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Spatial Statistics",
    "text": "Spatial Statistics\n\nTaking into account spatial dependence possibly present in data is a foremost aspect of spatial statistics.\nGeneral spatial model (Cressie 1993): \\(\\{\nZ(\\mathbf{s}) \\; : \\; \\mathbf{s} \\in D \\}\\), where \\(D\\) is an index set.\nStatistical inference depends heavily on the spatial structure/geometry of the observed spatial data.\n\n\n\n\nGeometry\nBranch\nIndex set\n\n\n\n\nPoints\nGeostatistics\nContinuum\n\n\nAreas/polygons\nAreal models\nCountable\n\n\nMixed\nSpatial Data Fusion\nContinuum\n\n\n\n\n\nChallenges arise when working with data from different sources:\n\nChange of support\nSpatial misalignment\nData fusion itself.\n\n\nLoosely speaking, this means the GP has stationary mean, variance, and a correlation function such that the correlation between two data points depends solely on their distance.\n\nCommon assumptions are stationarity and isotropy.\nImportance in spatial statistics: predominant foundation of geostatistical modeling.\nCompletely specified by mean and covariance functions.\n\nThe main reasons these models are not applied to areal data are:\n\nCalculating distance between areal spatial units is non-trivial;\nThe commonly used areal models are computationally efficient."
  },
  {
    "objectID": "slides/2024-jsm/index.html#classic-models-for-spatial-data",
    "href": "slides/2024-jsm/index.html#classic-models-for-spatial-data",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Classic Models for Spatial Data",
    "text": "Classic Models for Spatial Data\n\nAreal data\n\nCAR (Besag 1974), ICAR, BYM (Besag et al. 1991), DAGAR (Datta et al. 2019).\n\nPoint-referenced data\n\nGaussian processes (GP)\n\nMixed/fused data\n\n“Aggregated” GP (AGP) (Moraga et al. 2017): \\[\nZ(\\mathbf{s}_i)\n= \\begin{cases}\n{\\mathcal{A}(\\mathbf{s}_i)}^{-1}\n\\int_{\\mathcal{A}(\\mathbf{s}_i)} Z(\\mathbf{s}) \\mathrm{d}\\mathbf{s}, & \\text{if }\n\\mathcal{A}(\\mathbf{s}_i) &gt; 0, \\\\\nZ(\\mathbf{s}_i), & \\text{otherwise,}\n\\end{cases}\n\\]\n\n\n\n\nAreal models are usually heteroscedastic; The marginal variances decrease with the number of neighbors;\nData fusion models are also heteroscedastic (unless all the polygons are of the same size); computationally prohibitive for moderately large datasets; arbitrary choice of grid resolution."
  },
  {
    "objectID": "slides/2024-jsm/index.html#research-questions",
    "href": "slides/2024-jsm/index.html#research-questions",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Research Questions",
    "text": "Research Questions\n\nThe main research questions we are interested in are:\n\nCan we propose a model for spatial data that accomodates areal, point-referrenced, and fused data?\nIf so, is this model competitive when compared to specialized models?\n\nProposal: An isotropic GP defined on a flexible index set.\nMain challenge: Defining a valid correlation function."
  },
  {
    "objectID": "slides/2024-jsm/index.html#distances-between-sets",
    "href": "slides/2024-jsm/index.html#distances-between-sets",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Distances between Sets",
    "text": "Distances between Sets\n\nMetric space: \\((D, d)\\), where \\(D\\) is a spatial region of interest.\nDistance between a point and a set: \\(d(x, A) = \\inf_{a \\in A}\nd(x, a)\\), where \\(d(x, y)\\) is the distance between any two elements \\(x, y \\in\nD\\)\nDirected Hausdorff distance: \\[{\\vec h}(A, B) = \\sup_{a \\in A}\nd(a, B)\\]\nHausdorff distance: \\[h(A, B) = \\max \\left \\{ \\vec{h}(A, B),\n\\vec{h}(B, A) \\right \\}\\]\n\n\n\nSymmetric Hausdorff distance: the greater of the two directed Hausdorff distances.\nNote that if \\(A\\) and \\(B\\) are both singletons, then \\(h(A, B) = d(A, B)\\).\n\nMeric Properties: (1) Symmetry: \\(d(x, y) = d(y, x)\\); (2) Nonnegativeness: \\(d(x,\ny) \\geq 0\\) and \\(d(x, x) = 0\\); (3)Positiveness: \\(d(x, y) = 0 \\implies x = y\\); (4) Triangle inequality: \\(d(x, y) \\leq d(x, z) + d(z, y)\\)"
  },
  {
    "objectID": "slides/2024-jsm/index.html#hausdorff-distance-for-spatial-data-analysis",
    "href": "slides/2024-jsm/index.html#hausdorff-distance-for-spatial-data-analysis",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Hausdorff Distance for Spatial Data Analysis",
    "text": "Hausdorff Distance for Spatial Data Analysis\n\nStudy region: In spatial statistics, \\(D\\) is tipically a closed and bounded subset of \\(\\mathbb{R}^2\\).\nIn this context, the Hausdorff distance is a metric (Sendov 2004).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetric on \\(D \\setminus \\varnothing\\)\nThe Hausdorff distance ability to account for spatial units’ shapes, sizes and orientation(Min et al. 2007) renders it an interesting tool to achieve our goals.\nMoreover, it can distinguish between overlapping, nested, and disjointed regions.\nIn the figure: (1) The dashed lines denote the Hausdorff distances; (2) The infimum distance between to sets is zero for the three cases; (3) Distance between centroids is the same for the first two figures."
  },
  {
    "objectID": "slides/2024-jsm/index.html#the-hgp",
    "href": "slides/2024-jsm/index.html#the-hgp",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "The HGP",
    "text": "The HGP\n\nIndex set: \\(\\mathcal{B}(D)\\) represents the closed and bounded subsets of \\(D \\subset \\mathbb{R}^2\\).\n\\(Z(\\mathbf{s}) \\sim \\mathrm{HGP}\\{m(\\mathbf{s}), v(\\mathbf{s}), r(h)\\}\\), where \\(\\mathbf{s} \\in \\mathcal{B}(D)\\).\nMean function: \\(m(\\mathbf{s}) = \\mathbb{E}[Z(\\mathbf{s})]\\)\nSD function: \\(v(\\mathbf{s}) =\n\\sqrt{\\mathrm{Var}(Z(\\mathbf{s}))}\\)\nCorrelation function: \\(r(h) =\n\\mathrm{Cor}(Z(\\mathbf{s}_1), Z(\\mathbf{s}_2)),\\) where \\(h\\) denotes the Hausdorff distance between \\(\\mathbf{s}_1, \\mathbf{s}_2 \\in\n\\mathcal{B}(D)\\).\nThe induced covariance function is given by \\(\\mathrm{Cov}(Z(\\mathbf{s}_1),\nZ(\\mathbf{s}_2)) = v(\\mathbf{s}_1) v(\\mathbf{s}_2) r(h(\\mathbf{s}_1,\n\\mathbf{s}_2))\\)\n\n\n\nIdeally, we want bounded, compact, and non-empty sets for the Hausdorff distance to be a metric..\nIn \\(\\mathbb{R}^2\\), a compact subset is bounded.\nempty is a subset of any set -&gt; it is bounded bc a subset of a bounded set is bounded itself.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nThe SD function allows the HGP to accommodate both homoscedastic and heteroscedastic scenarios.\n\nFor a valid process, its correlation function must satisfy the following properties:\n\nDiminish with increasing distance: \\(\\lim_{h \\to \\infty}r(h) = 0\\).\nBounded from above by 1: \\(r(0) = 1\\).\nPositive-definiteness: yields positive-definite correlation matrices for all its finite-dimensional marginal distributions.\nUnfortunately, functions that are guaranteed to be positive definite on \\((\\lVert \\cdot \\rVert_2, \\mathbb{R}^2)\\) are not necessarily positive definite on other metric spaces (Li et al. 2023)."
  },
  {
    "objectID": "slides/2024-jsm/index.html#the-powered-exponential-correlation-pec-function",
    "href": "slides/2024-jsm/index.html#the-powered-exponential-correlation-pec-function",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "The Powered Exponential Correlation (PEC) Function",
    "text": "The Powered Exponential Correlation (PEC) Function\n\nPEC function: \\[r(h; \\phi, \\nu) = \\exp\\left \\{ -\n\\frac{h^{\\nu}}{\\phi^{\\nu}}\\right \\},\\] where \\(\\nu\\) is a smoothness parameter and \\(\\phi\\) governs the range of the spatial dependence.\nParametrization: We reparametrize this function with \\(\\rho =\n{\\log(10)}^{1 / \\nu} \\phi\\).\nInterpretation: \\(\\rho\\) is the distance at which the spatial correlation reduces to \\(0.10\\).\n\n\n\nexplain \\(\\rho\\)."
  },
  {
    "objectID": "slides/2024-jsm/index.html#theoretical-foundation-positive-definiteness-of-the-pec",
    "href": "slides/2024-jsm/index.html#theoretical-foundation-positive-definiteness-of-the-pec",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Theoretical Foundation: Positive Definiteness of the PEC",
    "text": "Theoretical Foundation: Positive Definiteness of the PEC\n\n\n\nTheorem\n\n\nLet \\(h = h(\\mathbf{s}, \\mathbf{s}')\\) be the Hausdorff distance between two spatial units, denoted \\(\\mathbf{s}, \\mathbf{s}' \\in \\mathcal{B}(D)\\), where \\(D\n\\subset \\mathbb{R}^2\\). The powered exponential correlation function \\(\\exp \\{ -\nh^{\\nu} / \\phi^{\\nu} \\}\\) is positive definite for \\(\\nu \\in (1/2, 1)\\).\n\n\n\n\nThe theorem above guarantees the validity of the HGP equipped with a PEC function with \\(\\nu \\in\n(1/2, 1)\\).\nThe proof is based on embedding the Hausdorff distance into a high-dimensional \\(L_1\\) normed Euclidean space, and using the fact that the exponential correlation function is positive definite on this space."
  },
  {
    "objectID": "slides/2024-jsm/index.html#hgp-recap",
    "href": "slides/2024-jsm/index.html#hgp-recap",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "HGP Recap",
    "text": "HGP Recap\n\nFlexibility: A process that handles point-referrenced, areal, and mixed spatial data by construction.\nHausdorff distance: Enables HGP’s correlation function to account for the shape, size, and orientation of spatial objects.\nValidity: Using a PEC function ensures the HGP is a valid process.\n\n\n\n\n\n\nflowchart LR\n    A(Flexible index set) ==&gt; B(GP)\n    B ==&gt; E(((HGP)))\n    C(Hausdorff distance) ==&gt; D(PEC)\n    D ==&gt; E"
  },
  {
    "objectID": "slides/2024-jsm/index.html#spatial-glmm",
    "href": "slides/2024-jsm/index.html#spatial-glmm",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Spatial GLMM",
    "text": "Spatial GLMM\nA generalized linear mixed effects model (GLMM) can be written as \\[\\begin{aligned}\n& Y(\\mathbf{s}_i) \\mid \\mathbf{x}_i, Z(\\mathbf{s}_i) \\overset{{\\rm ind}}{\\sim}\n  f(\\cdot \\mid \\mu_i, \\boldsymbol{\\gamma}) \\\\\n& g(\\mu_i) = \\mathbf{x}_i \\boldsymbol{\\beta} +\n  Z(\\mathbf{s}_i).\n\\end{aligned}\\]\n\nProbability distribution: \\(f(\\cdot)\\)\nLink function: \\(g(\\cdot)\\)\nConditional mean: \\(\\mu_i = \\mathbb{E}[Y(\\mathbf{s}_i) \\mid\n\\mathbf{x}_i, Z(\\mathbf{s}_i)]\\)\nModel parameters: \\(\\boldsymbol{\\theta} =\n{\\{\\boldsymbol{\\beta}^\\top, \\boldsymbol{\\sigma}^\\top,\n\\boldsymbol{\\delta}^\\top, \\boldsymbol{\\gamma}^\\top \\}}^\\top\\)\nJoint density: \\(p(\\mathbf{y} \\mid \\mathbf{z}, \\boldsymbol{\\theta}) =\n\\prod_{i = 1}^n f(y(\\mathbf{s}_i) \\mid \\mu_i, \\boldsymbol{\\gamma})\\)\n\n\n\nRealizations of random variables are represented by lowercase letters.\nModel paramers are greek letters.\nUnder a frequentist perspective, we consider the random effects to follow an HGP.\nFor Bayesian inference, we use the HGP as a prior for the random effects.\nResponse variable \\(Y\\) at a spatial unit \\(s\\) is modeled with an appropriate distribution (e.g., Poisson, Bernoulli).\nCovariates (\\(X\\)) and spatial random effects (\\(Z\\)) explain variation in the conditional mean (\\(\\mu\\)).\nThe HGP defines the spatial random effects (\\(Z\\)), capturing spatial correlation with the Hausdorff distance and a correlation function."
  },
  {
    "objectID": "slides/2024-jsm/index.html#bayesian-estimation-prediction",
    "href": "slides/2024-jsm/index.html#bayesian-estimation-prediction",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Bayesian Estimation & Prediction",
    "text": "Bayesian Estimation & Prediction\n\nPriors: \\[\\begin{align*}\n& \\boldsymbol{\\beta} \\sim \\mathcal{N}(\\mathbf{0}, 10\n\\mathbf{I}) & \\mathbf{Z} \\sim \\mathrm{HGP}\\{0, v(\\cdot), r(\\cdot)\n\\} & \\\\\n& \\rho \\sim \\mathrm{Exp}(a_\\rho) & \\alpha \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}) \\qquad \\text{ or } \\quad & \\sigma \\sim t_{+}(3)\n\\end{align*}\\]\nPosterior: \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}, \\mathbf{z}) \\propto\np(\\mathbf{y} \\mid \\mathbf{z}, \\boldsymbol{\\theta}) p(\\mathbf{z} \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta})\\)\nMCMC sampler: No-U-Turn (Homan and Gelman 2014).\nConvergence assessment: traceplots and split-\\({\\hat{R}}\\) (Vehtari et al. 2021).\nPosterior predictive distributions: \\(p(\\mathbf{y}^{\\ast} \\mid\n\\mathbf{y})\\)\n\n\n\nPoint and interval estimates: median and percentiles (\\(0.025\\) and \\(0.975\\)) of the marginal MCMC samples.\nParameters initialized by random sampling from their priors.\nRandom effects initialized from a standard normal distribution.\n\\(a_\\rho\\) is chosen so that: \\(\\mathbb{P}(\\rho &gt; U) = p_\\rho\\). In particular, \\(a_\\rho = - \\log(p_\\rho) / \\rho_0\\).\n\\(\\nu\\) hard to be estimated.\nGoodness-of-fit criteria: WAIC, and LOOIC (lower values indicate better fit)\nPredictions assessment: Interval Score (IS) and RMSP (lower values indicate better fit)\n\nPredictions:\n\nuse the properties of GP and multivariate Normal distribution to obtain the closed-form distribution of the vector of spatial random effects \\(\\mathbf{Z}^\\ast\\) (Diggle et al. 1998);\nsample \\(\\mathbf{z}^\\ast_{(b)}\\) from the distribution derived in the previous step;\nsample \\(\\mathbf{y}^{\\ast}_{(b)}\\) from \\(p(\\mathbf{y}^{\\ast} \\mid \\boldsymbol{\\theta}_{(b)},\n\\mathbf{z}^{\\ast}_{(b)})\\), where \\(\\boldsymbol{\\theta}_{(b)}\\) is the \\(b\\)-th MCMC sample of \\(\\boldsymbol{\\theta}\\)."
  },
  {
    "objectID": "slides/2024-jsm/index.html#bayesian-modeling-recap",
    "href": "slides/2024-jsm/index.html#bayesian-modeling-recap",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Bayesian Modeling Recap",
    "text": "Bayesian Modeling Recap\n\nHGP as a prior for the random effects disribution in a GLMM.\nBayesian inference through MCMC.\nUncertainty quantification of predictions through the posterior predictive distributions.\n\n\nDAGAR priors: \\[\n\\begin{aligned}\n  \\pi(\\beta_0) & \\propto 1 \\\\\n  \\beta_1 & \\sim N(0, 1000^2) \\\\\n  \\tau & \\sim Gamma(2, 1) \\\\\n  \\psi & \\sim U(0, 1).\n\\end{aligned}\n\\] - Precision matrix is defined based on the order of the observations and adjacency matrix (and the two parameters)"
  },
  {
    "objectID": "slides/2024-jsm/index.html#respiratory-disease-hospitalization-in-glasgow",
    "href": "slides/2024-jsm/index.html#respiratory-disease-hospitalization-in-glasgow",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Respiratory Disease Hospitalization in Glasgow",
    "text": "Respiratory Disease Hospitalization in Glasgow\n\nSample units: 134 intermediate zones (IZ), where the \\(i\\)-th IZ is denoted \\(\\mathbf{s}_i\\).\nNumber of hospitalizations: \\(\\mathbf{Y} = {(Y(\\mathbf{s}_1),\n\\ldots, Y(\\mathbf{s}_n))}^\\top\\).\nExpected number of hospitalizations based on the national age- and sex-standardized rates: \\(E_i\\).\nPercentage of people classified as income deprived: \\(\\mathbf{X}\\).\n\n\\[\\begin{aligned}\n& (Y(\\mathbf{s}_i) \\mid x_i, z(\\mathbf{s}_i)) \\sim \\text{Poisson}(E_i \\mu_i) \\\\\n& \\log(\\mu_i) = \\beta_0 + x_i \\beta_1 + z(\\mathbf{s}_i)\n\\end{aligned}\\]\n\n\nData from the north portion of the river Clyde in the Great Glasgow and Clyde health board in Scotland.\nAssumption: Conditional on \\(\\mathbf{Z}\\), \\(\\mathbf{Y}\\) are mutually independent.\nExplain goals of the analysis–estimate risks adjusted for income deprivation, compare methods.\n\\(\\mu_i\\) is the expected SIR at region \\(i\\).\nOutline the modeling choices (HGP, DAGAR, BYM), briefly mention priors."
  },
  {
    "objectID": "slides/2024-jsm/index.html#disease-mapping-estimation-gof",
    "href": "slides/2024-jsm/index.html#disease-mapping-estimation-gof",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Disease Mapping: Estimation & GOF",
    "text": "Disease Mapping: Estimation & GOF\n\n\n\n\n\nHGP\nDAGAR\n\n\n\n\n\\(\\beta_0\\)\n-0.21 (-0.268, -0.139)\n-0.26 (-0.450, -0.137)\n\n\n\\(\\beta_1\\)\n0.33 (0.284, 0.368)\n0.31 (0.258, 0.370)\n\n\n\\(\\sigma\\)\n0.19 (0.155, 0.234)\n0.30 (0.218, 0.484)\n\n\n\\(\\rho\\)\n2.25 (0.159, 6.948)\n\n\n\n\\(\\psi\\)\n\n0.43 (0.069, 0.827)\n\n\n\n\n\n\n\n\n\n\n\n\nLOOIC\n1081.0\n1081.9\n\n\nWAIC\n1038.0\n1032.4\n\n\n\n\n\n\nmedian (95% CI)\nsimilar estimates for covariate\nHGP indicates weak spatial correlation\nDAGAR and BYM spatial dependence are not helpful as they indicate the spatial correlation goes from weak to strong (according to the CI)"
  },
  {
    "objectID": "slides/2024-jsm/index.html#disease-mapping-spatial-dependence",
    "href": "slides/2024-jsm/index.html#disease-mapping-spatial-dependence",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Disease Mapping: Spatial Dependence",
    "text": "Disease Mapping: Spatial Dependence\n\n\n\nHGP provides more insight into spatial dependence\nWe could also plot the correlation function itself"
  },
  {
    "objectID": "slides/2024-jsm/index.html#disease-mapping-adjusted-sir",
    "href": "slides/2024-jsm/index.html#disease-mapping-adjusted-sir",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Disease Mapping: Adjusted SIR",
    "text": "Disease Mapping: Adjusted SIR\n\n\n\nFitted values are similar among the three models\nSome regions with very low risks are shrunk toward a “regional mean”"
  },
  {
    "objectID": "slides/2024-jsm/index.html#air-pollution-in-ventura-and-los-angeles",
    "href": "slides/2024-jsm/index.html#air-pollution-in-ventura-and-los-angeles",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Air Pollution in Ventura and Los Angeles",
    "text": "Air Pollution in Ventura and Los Angeles\n\n\n\n\nPoint-referrenced data from 19 measurement stations available daily from 1999 to date;\nSatellite-derived estimates (2010–2012) at 184 areal units.\nPM2.5: \\(\\mathbf{Y} = {(Y(\\mathbf{s}_1), \\ldots,\nY(\\mathbf{s}_n))}^\\top\\).\nModel: \\((Y(\\mathbf{s}_i) \\mid z(\\mathbf{s}_i)) \\sim\n\\mathcal{N}(\\beta_0 + z(\\mathbf{s}_i), \\tau^2)\\)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngoals: (1); estimate model parameters using both sources. (2) use satellite data to help with interpolation.\nsquare areas (average size \\(\\approx\\) 101.95 km2)\ndata fusion challenges\nadaptability of the hgp to different problems.\nPm25 scale is micrometre per cubic meter: one one-millionth of a meter.\nconditional on \\(z\\) the \\(y\\)s are mutually independent.\nPriors on random effects: AGP1 and 2; heteroscedastic HGP with different variances for areal and point-referrenced data."
  },
  {
    "objectID": "slides/2024-jsm/index.html#agp-approximation",
    "href": "slides/2024-jsm/index.html#agp-approximation",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "AGP Approximation",
    "text": "AGP Approximation"
  },
  {
    "objectID": "slides/2024-jsm/index.html#air-pollution-estimation-and-prediction-assessment",
    "href": "slides/2024-jsm/index.html#air-pollution-estimation-and-prediction-assessment",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Air Pollution: Estimation and Prediction Assessment",
    "text": "Air Pollution: Estimation and Prediction Assessment\n\n\n\n\n\n\n\n\n\n\n\nHGP\n\\(\\rm AGP_1\\)\n\\(\\rm AGP_2\\)\n\n\n\n\n\\(\\beta\\)\n5.61 (4.69, 6.45)\n6.22 (2.16, 10.10)\n6.19 (5.88, 6.48)\n\n\n\\(\\rho\\)\n13.83 (7.82, 23.61)\n13.16 (5.14, 30.24)\n0.63 (0.46, 0.83)\n\n\n\\(\\tau\\)\n0.18 (0.07, 0.31)\n1.39 (1.24, 1.56)\n0.54 (0.39, 0.72)\n\n\n\\(\\sigma\\)\n3.85 (2.92, 5.18)\n1.70 (0.96, 2.91)\n2.41 (2.024, 2.84)\n\n\n\\(\\sigma_a\\)\n1.24 (1.04, 1.51)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRMSP\n1.05\n1.45\n1.64\n\n\nWidth\n3.57\n2.53\n9.67\n\n\nCPP\n95.5\n78.6\n95.5\n\n\nIS\n4.80\n15.11\n13.65\n\n\n\n\n\n\n\\(\\rho\\) rescaled to 100s of km.\nstaggering difference in estimates of the same model with different meshes."
  },
  {
    "objectID": "slides/2024-jsm/index.html#air-pollution-change-of-support",
    "href": "slides/2024-jsm/index.html#air-pollution-change-of-support",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Air Pollution: Change-of-Support",
    "text": "Air Pollution: Change-of-Support\n\n\n\nFigure confirms what we learned from 10-fold CV and simulation studies.\nHGP allows to use data from different sources seamlessly\nNo dependence on meshes/grids\nApparently, a parsimonious compromise between the two meshes.\nOnce again, the AGP seems highly dependend on the mesh and this is not highlighted in the literature."
  },
  {
    "objectID": "slides/2024-jsm/index.html#applications-key-findings",
    "href": "slides/2024-jsm/index.html#applications-key-findings",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Applications: key findings",
    "text": "Applications: key findings\n\nThe proposed method consistently demonstrated performance comparable to specialized models tailored for areal and fused data.\nUnlike traditional areal models, the HGP’s marginal variances are independent of the number of neighbors.\nThe HGP model simplifies data fusion by bypassing the need to define arbitrary grids for numerical integral evaluation, eliminating this step each time the joint probability distribution of the data and parameters is calculated.\nAcross both applications, the HGP provides an interpretable spatial dependence parameter and a spatial correlation function."
  },
  {
    "objectID": "slides/2024-jsm/index.html#highlights",
    "href": "slides/2024-jsm/index.html#highlights",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Highlights",
    "text": "Highlights\nThe HGP has proven to be a powerful model that offers:\n\nVersatility: accomodates diverse spatial data types.\nPerformance: competitive against models designed for specific spatial data types.\nReliable predictions: prediction intervals with near nominal frequentist coverage.\nOur conclusions are further supported by a comprehensive simulation study, detailed in our available preprint.\n\n\nKey Takeaway: The HGP’s versatility and performance make it a valuable tool in your spatial analysis toolkit."
  },
  {
    "objectID": "slides/2024-jsm/index.html#future-work-and-limitations",
    "href": "slides/2024-jsm/index.html#future-work-and-limitations",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "Future work and Limitations",
    "text": "Future work and Limitations\n\nExtensions:\n\nnon-Euclidean spaces\nBig data\n\nLimitations:\n\nBig “n” problem inherited from geostatistics\nUnclear how to incorporate anisotropy\nDifficulties in obtaining spectral densities for correlation functions"
  },
  {
    "objectID": "slides/2024-jsm/index.html#references",
    "href": "slides/2024-jsm/index.html#references",
    "title": "FROM POINT TO POLYGON: A UNIFIED FRAMEWORK FOR MODELING SPATIAL DEPENDENCE",
    "section": "",
    "text": "References\n\n\nBesag, J. (1974), “Spatial interaction and the statistical analysis of lattice systems,” Journal of the Royal Statistical Society. Series B (Methodological), JSTOR, 192–236.\n\n\nBesag, J., York, J., and Mollié, A. (1991), “Bayesian image restoration, with two applications in spatial statistics,” Annals of the Institute of Statistical Mathematics, 43, 1–20.\n\n\nCressie, N. (1993), Statistics for spatial data, Wiley series in probability and statistics, Wiley.\n\n\nDatta, A., Banerjee, S., Hodges, J. S., and Gao, L. (2019), “Spatial disease mapping using directed acyclic graph auto-regressive (DAGAR) models,” Bayesian analysis, NIH Public Access, 14, 1221.\n\n\nDiggle, P. J., Tawn, J. A., and Moyeed, R. A. (1998), “Model-based geostatistics,” Journal of the Royal Statistical Society Series C: Applied Statistics, Oxford University Press, 47, 299–350.\n\n\nHoman, M. D., and Gelman, A. (2014), “The No-U-turn sampler: Adaptively setting path lengths in hamiltonian Monte Carlo,” Journal of Machine Learning Research, JMLR.org, 15, 1593–1623.\n\n\nLi, D., Tang, W., and Banerjee, S. (2023), “Inference for Gaussian processes with Matérn covariogram on compact Riemannian manifolds,” Journal of Machine Learning Research, 24, 1–26.\n\n\nMin, D., Zhilin, L., and Xiaoyong, C. (2007), “Extended Hausdorff distance for spatial objects in GIS,” International Journal of Geographical Information Science, Taylor & Francis, 21, 459–475.\n\n\nMoraga, P., Cramb, S. M., Mengersen, K. L., and Pagano, M. (2017), “A geostatistical model for combined analysis of point-level and area-level data using INLA and SPDE,” Spatial Statistics, Elsevier, 21, 27–41.\n\n\nSendov, B. (2004), “Hausdorff distance and image processing,” Russian Mathematical Surveys, IOP Publishing, 59, 319. https://doi.org/10.1070/RM2004v059n02ABEH000721.\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., and Bürkner, P.-C. (2021), “Rank-normalization, folding, and localization: An improved \\(\\hat{R}\\) for assessing convergence of MCMC (with discussion),” Bayesian Analysis, International Society for Bayesian Analysis, 16, 667–718."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Publications\n\n\n\n\n\n[1] Frank, S., Ibrahim, B., Feng, R., Bidra, A., Lafreniere, D., Kuo, C.-L., Godoy, L. da C., & Falcone, T. E. (n.d.). Tolerability of nasal and oral povidone-iodine antisepsis for in-office procedures. Clinical Otolaryngology, 48(4), 696–699. https://doi.org/10.1111/coa.14045\n\n\n[2] Pandya, S. S., Godoy, L. da C., Alexander, C. S., Schneider, D., & Harknett, K. (2025). Using worker surveys to detect labor standards non-compliance. Statistics and Public Policy.\n\n\n[3] Al-Naggar, I. M., Antony, M., Baker, D., Wang, L., Godoy, L. da C., Kuo, C.-L., Fraser, M. O., Smith, P. P., Xu, M., & Kuchel, G. A. (2025). Polyploid superficial uroepithelial bladder barrier cells express features of cellular senescence across the lifespan and are insensitive to senolytics. Aging Cell, 24(2), e14399. https://doi.org/10.1111/acel.14399\n\n\n[4] Fredston, A., Ovando, D., Godoy, L. da C., Kong, J., Muffley, B., Thorson, J. T., & Pinsky, M. (2025). Dynamic range models improve the near-term forecast for a marine species on the move. Ecology Letters. https://doi.org/10.32942/X24D00\n\n\n[5] Godoy, L. da C., Prates, M., & Quintana, F. (2025). A note on defining positive definite functions. https://arxiv.org/abs/2502.15146\n\n\n[6] Hernández, G. G., Seemann, J. R., Godoy, L. da C., Slot, M., & García-Robledo, C. (2025). Heat tolerance of tropical herbaceous plants increases with elevation. Cold Spring Harbor Laboratory. https://doi.org/10.1101/2025.03.12.642681\n\n\n[7] Michelin, L., Godoy, L. da C., Ramos, H. S., & Prates, M. O. (2025). Fast mixture spatial regression: A mixture in the geographical and feature space applied to predict porosity in the Post-salt. Spatial Statistics, 65, 100873. https://doi.org/10.1016/j.spasta.2024.100873\n\n\n[8] Moriarty, K. L., Manfredi, K., Carrel, P., Kryzanski, E., Schwartz, D. A., Godoy, L. da C., Kuo, C.-L., & Shields, A. (2025). Findings of reduced head circumference with COVID-19 infection in the third trimester: A retrospective cohort study. Biomedicines, 13(4). https://doi.org/10.3390/biomedicines13040832\n\n\n[9] Sieger, M., Goldsborough, E. J., Nichols, C., Godoy, L. da C., Moore, T. E., Chen, S., Terplan, M., Griffin, B. A., & Patrick, S. W. (2025). Connecticut’s novel prenatal substance exposure policy is associated with declining CPS reports and foster placements. Health Affairs, 44(7). https://doi.org/10.1377/hlthaff.2024.01160\n\n\n[10] Chaluparambil, M., Abu-Arqub, S., Kuo, C.-L., Godoy, L. da C., Upadhyay, M., & Yadav, S. (2024). Age-stratified assessment of orthodontic tooth movement outcomes with clear aligners. Progress in Orthodontics, 25(1), 43. https://doi.org/10.1186/s40510-024-00542-2\n\n\n[11] Abu-Arqub, S., Al-Moghrabi, D., Kuo, C.-L., Godoy, L. da C., & Uribe, F. (2024). Perceptions and utilization of tele-orthodontics: A survey of the members of the American Association of Orthodontists. Progress in Orthodontics, 25(1), 16. https://doi.org/10.1186/s40510-024-00516-4\n\n\n[12] Abu-Arqub, S., Greene, R., Greene, S., Laing, K., Kuo, C.-L., Godoy, L. da C., & Uribe, F. (2024). Retrospective evaluation of the success rate and factors associated with the stability of alveolar ridge orthodontic miniscrews: Pilot study. Journal of the World Federation of Orthodontists, 13(4), 181–188. https://doi.org/https://doi.org/10.1016/j.ejwf.2024.02.001\n\n\n[13] Andreyeva, T., Moore, T. E., Godoy, L. da C., & Kenney, E. L. (2024). Federal nutrition assistance for young children: Underutilized and unequally accessed. American Journal of Preventive Medicine, 66(1), 18–26. https://doi.org/https://doi.org/10.1016/j.amepre.2023.09.008\n\n\n[14] Fryc, G. A., Godoy, L. da C., Kuo, C.-L., & Lurie, A. G. (2024). Prevalence of likely retro-odontoid pseudotumor in patients receiving dental CBCT examinations. Oral Surgery, Oral Medicine, Oral Pathology and Oral Radiology, 137(3), 301–309. https://doi.org/10.1016/j.oooo.2023.11.005\n\n\n[15] Godoy, L. da C. (2024). sapo: Spatial association of different types of polygon. https://CRAN.R-project.org/package=sapo\n\n\n[16] Godoy, L. da C. (2024). smile: Spatial misalignment, interpolation, linkage, and estimation. https://doi.org/10.32614/CRAN.package.smile\n\n\n[17] Godoy, L. da C., Prates, M. O., & Yan, J. (2024). Statistical inferences and predictions for areal data and spatial data fusion with Hausdorff–Gaussian processes. Journal of Agricultural Biological and Environmental Statistics. https://doi.org/10.48550/arXiv.2208.07900\n\n\n[18] Godoy, L. da C., Prates, M. O., & Yan, J. (2024). Voronoi linkage between mismatching voting stations and census tracts in analyzing the 2018 Brazilian presidential election data. New England Journal of Statistics in Data Science.\n\n\n[19] Irsheid, R., Godoy, L. D. C., Kuo, C.-L., Metz, J., Dolce, C., & Abu-Arqub, S. (2024). Comparative assessment of the clinical outcomes of clear aligners compared to fixed appliance in class II malocclusion. Clinical Oral Investigations, 28(8), 1–10. https://doi.org/10.1186/s12903-018-0695-z\n\n\n[20] Wilson, C., Taxel, P., Shafer, D., Tadinada, A., Godoy, L. da C., Kuo, C.-L., & Freilich, M. (2024). Cone beam computed tomography outcomes in patients diagnosed with compromised bone health undergoing dental implant therapy and bone augmentation. The Journal of Prosthetic Dentistry. https://doi.org/10.1016/j.prosdent.2024.10.030\n\n\n[21] Abu-Arqub, S., Ahmida, A., Godoy, L. da C., Kuo, C.-L., Upadhyay, M., & Yadav, S. (2023). Insight into clear aligner therapy protocols and preferences among members of the American Association of Orthodontists in the United States and Canada. The Angle Orthodontist, 93(4), 417–428. https://doi.org/10.2319/101022-694.1\n\n\n[22] Abu-Arqub, S., Bashir, R., Obeng, K., Godoy, L. da C., Kuo, C.-L., Upadhyay, M., & Yadav, S. (2023). Survival and failure rate of lower lingual bonded retainers: A retrospective cohort evaluation. Orthodontics & Craniofacial Research, 26(2), 256–264. https://doi.org/10.1111/ocr.12608\n\n\n[23] Abu-Arqub, S., Greene, R., Greene, S., Laing, K., Kuo, C.-L., Godoy, L. da C., & Uribe, F. (2023). Ridge mini-implants, a versatile biomechanical anchorage device whose success is significantly enhanced by splinting: A clinical report. Progress in Orthodontics, 24(1), 27. https://doi.org/10.1186/s40510-023-00480-5\n\n\n[24] Duong, C., Zhu, Q., Aseltine Jr, R. H., Kuo, C.-L., Godoy, L. da C., & Kaufman, B. (2023). A survey on cone-beam computed tomography usage among endodontists in the United States. Journal of Endodontics, 49(11), 1559–1564. https://doi.org/10.1016/j.joen.2023.08.020\n\n\n[25] Harandi, M. T., Abu-Arqub, S., Warren, E., Kuo, C.-L., Godoy, L. da C., Mehta, S., Feldman, J., Upadhyay, M., & Yadav, S. (2023). Assessment of clear aligner accuracy of 2 clear aligners systems. American Journal of Orthodontics and Dentofacial Orthopedics, 164(6), 793–804. https://doi.org/https://doi.org/10.1016/j.ajodo.2023.05.028\n\n\n[26] Jesus, M. de, Maheshwary, A., Kumar, M., Godoy, L. da C., Kuo, C.-L., & Grover, P. (2023). Association of electrocardiographic and echocardiographic variables with neurological outcomes after ischemic stroke. American Heart Journal Plus: Cardiology Research and Practice, 34, 100313. https://doi.org/10.1016/j.ahjo.2023.100313\n\n\n[27] Kuo, C.-L., Liu, R., Godoy, L. da C., Pilling, L. C., Fortinsky, R. H., & Brugge, D. (2023). Association between residential exposure to air pollution and incident coronary heart disease is not mediated by leukocyte telomere length: A UK Biobank study. Toxics, 11(6). https://doi.org/10.3390/toxics11060489\n\n\n[28] Leonard, J. F., Taxel, P., Kuo, C.-L., Godoy, L. da C., & Freilich, M. (2023). Dental implant and bone augmentation treatment in bone-compromised patients: Oral health-related quality of life outcomes. The Journal of Prosthetic Dentistry. https://doi.org/10.1016/j.prosdent.2023.01.011\n\n\n[29] Turshudzhyan, A., Godoy, L. da C., Kuo, C.-L., & Wu, G. Y. (2023). Alpha Feto-protein expression trends for screening early hepatocellular carcinoma. Gene Expression, 22(2), 109–114. https://doi.org/10.14218/GE.2023.00001\n\n\n[30] Abu-Arqub, S., Banankhah, S., Sharma, R., Godoy, L. da C., Kuo, C.-L., Ahmed, M., Alfardan, M., & Uribe, F. (2022). Association between initial complexity, frequency of refinements, treatment duration, and outcome in Invisalign orthodontic treatment. American Journal of Orthodontics and Dentofacial Orthopedics. https://doi.org/10.1016/j.ajodo.2022.06.017\n\n\n[31] Godoy, L. da C., Assunção, R. M., & Butler, K. A. (2022). Testing the spatial association of different types of polygons. Spatial Statistics, 51, 100695. https://doi.org/10.1016/j.spasta.2022.100695\n\n\n[32] Hariharan, A., Abu-Arqub, S., Gandhi, V., Godoy, L. da C., Kuo, C.-L., & Uribe, F. (2022). Evaluation of interproximal reduction in individual teeth, and full arch assessment in clear aligner therapy: Digital planning versus 3d model analysis after reduction. Progress in Orthodontics, 23(1), 1–10. https://doi.org/10.1186/s40510-022-00403-w\n\n\n[33] Kumar, M., Patil, S., Godoy, L. da C., Kuo, C.-L., Swede, H., Kuchel, G. A., & Chen, K. (2022). Demand ischemia as a predictor of mortality in older patients with delirium. Frontiers in Cardiovascular Medicine, 9. https://doi.org/10.3389/fcvm.2022.917252\n\n\n[34] Arqub-Abu, S., Voldman, R., Ahmida, A., Kuo, C.-L., Godoy, L. da C., Nasrawi, Y., Al-Khateeb, S. N., & Uribe, F. (2021). Patients’ perceptions of orthodontic treatment experiences during COVID-19: A cross-sectional study. Progress in Orthodontics, 22(1), 1–12. https://doi.org/10.1186/s40510-021-00363-7\n\n\n[35] Huynh, C., Godoy, L. da C., Kuo, C.-L., Smeds, M., & Amankwah, K. S. (2021). Examining the development of operative autonomy in vascular surgery training and when trainees and program directors agree and disagree. Annals of Vascular Surgery, 74, 1–10. https://doi.org/10.1016/j.avsg.2021.01.121\n\n\n[36] Lin, G., Murase, J. E., Murrell, D. F., Godoy, L. da C., & Grant-Kels, J. M. (2021). The impact of gender in mentor-mentee success: Results from the women’s dermatologic society mentorship survey. International Journal of Women’s Dermatology, 7(4), 398–402. https://doi.org/10.1016/j.ijwd.2021.04.010\n\n\n[37] Prates, M. O., Azevedo, D. R. M., Godoy, L. da C., & Bandyopadhyay, D. (2021). Can Gaussian Markov random fields handle spatial confounding? Journal of the Indian Statistical Association, 59(2), 197–220.\n\n\n[38] Abu-Arqub, S., Hariharan, A., Banankhah, S., Godoy, L. da C., Liu, P., Kuo, C.-L., & Uribe, F. Accuracy of full arch scans using the itero element 2® intra-oral scanner: A clinical study. Journal of Orthodontics, 0(0), 0–0. https://doi.org/10.1177/14653125241268755"
  },
  {
    "objectID": "posts/lmnet/2021-06-23-lmnnet.html",
    "href": "posts/lmnet/2021-06-23-lmnnet.html",
    "title": "Estimating regression coefficients using a Neural Network (from scratch)",
    "section": "",
    "text": "The idea behind the Neural Networks models, as its nomenclature suggests, is to mimic the way human brain learns to execute of some tasks. Some works in the literature (Cheng and Titterington (1994), Stern (1996), Warner and Misra (1996)) attribute of the first attempts to build a “Neural Network emulator” to McCulloch and Pitts (1943). The popularity of this method in the past decades was held down by the computation intensive calculations needed for such procedures. However, the computation resources advances in the last few years allied to the algorithmic nature of Neural Networks have contributed to the adoption of the methodology by computer scientists. These days, this models are very popular in the industry and are applied to several interesting applications such as speech recognition, image classification, and automatic text translation."
  },
  {
    "objectID": "posts/lmnet/2021-06-23-lmnnet.html#intro",
    "href": "posts/lmnet/2021-06-23-lmnnet.html#intro",
    "title": "Estimating regression coefficients using a Neural Network (from scratch)",
    "section": "",
    "text": "The idea behind the Neural Networks models, as its nomenclature suggests, is to mimic the way human brain learns to execute of some tasks. Some works in the literature (Cheng and Titterington (1994), Stern (1996), Warner and Misra (1996)) attribute of the first attempts to build a “Neural Network emulator” to McCulloch and Pitts (1943). The popularity of this method in the past decades was held down by the computation intensive calculations needed for such procedures. However, the computation resources advances in the last few years allied to the algorithmic nature of Neural Networks have contributed to the adoption of the methodology by computer scientists. These days, this models are very popular in the industry and are applied to several interesting applications such as speech recognition, image classification, and automatic text translation."
  },
  {
    "objectID": "posts/lmnet/2021-06-23-lmnnet.html#neural-network-regression",
    "href": "posts/lmnet/2021-06-23-lmnnet.html#neural-network-regression",
    "title": "Estimating regression coefficients using a Neural Network (from scratch)",
    "section": "Neural Network Regression",
    "text": "Neural Network Regression\nA neural network is a highly parametrized model that, provided we have enough data, can approximate any functional relationship between a set of features1 𝐱\\mathbf{x} and a response variable yy (Efron and Hastie (2016), pages 151-152). Although there are several possible structures for neural networks, for this post we are going to consider only the feed-forward2 neural networks. In order to explain how these neural networks are designed, let’s consider its graphical representation (see Figure 1). We have vertices, which are called a units (or neurons), ordered horizontally by layers. An edge coming from one vertex can only be connected to vertices associated with “higher” layers. These connections represent a information flow from left to right (hence, the name feed-forward), where each unit computed by 1) giving weights to each of its inputs, 2) calculating the dot product between weights and inputs, 3) adding a constant( usually referred to as bias) to it, and, finally, 4) applying an element-wise activation function f(⋅)f(\\cdot) to it. These activation functions are used to establish non-linear relationships between units.\nThe number of hidden layers as well as the number of units associated with every layer can both be regard as tuning parameters. The design and architecture of a neural network is a complex task. In summary, when having a single hidden layer, the number of units associated with the hidden layer determines the number of parameters associated with the model. Efron and Hastie (2016) suggest that, under this scenario, it is better to consider several units for the hidden layer and use some kind of regularization to avoid overfitting. Penalizations analogous to the Ridge and Lasso penalty for linear models are often used in the regularization context for neural networks (Hastie, Tibshirani, and Wainwright (2015), pages 210-211).\nAn important remark regarding the neural network models is that they are “pure prediction algorithms”. That is, these models are focused only on prediction, neglecting the estimation, as pointed by Efron (2020). The strategy is simple and consists in searching for high predictive accuracy. That being said, these algorithms make no assumption on the probability distribution of the data and, as one of the consequences of losing these assumptions, it is not possible to make interval predictions or to calculate confidence intervals for the “estimated” parameters.\n\n\n\n\n\n\n\n\nFigure 1: A feed-forward neural network with a single hidden layer.\n\n\n\n\n\n\nSingle neuron feed-forward networks\nA single neuron feed-forward network does not possess any hidden layer in its structure. The absence of hidden layers makes these models resemble the statistical models we are most used to, like, for example, the linear regression and logistic regression. By analyzing the graphical representation of a single layer feed-forward network (Figure 2), it is easy to see that by taking the identity as the activation function, the functional relationship between 𝐱\\mathbf{x} and yy considered by the neural network is equivalent to the one used for the general linear model. Considering the same representation, if we take f(x)=logit(x)f(x) = \\textrm{logit}(x) (sigmoid function, according to the neural network models literature) and y∈{0,1}y \\in \\{ 0, 1 \\}, then the neural network provides the same relationship between 𝐱\\mathbf{x} and yy as the one used by the logistic regression.\n\n\n\n\n\n\n\n\nFigure 2: A single layer feed-forward neural network.\n\n\n\n\n\nAlthough the functional relationship between 𝐱\\mathbf{x} and yy assumed by the single layer neural network coincides with some statistical models, we cannot promptly claim an equivalence between models because the way the neural networks learn, that is estimates, the weights can lead to different solutions depending on the loss and cost functions selected, we are going to talk more about these functions in the next section.\n\n\nActivation functions\nActivation functions are applied in every “Layer connection” in neural network models. Suppose, for example, we have a design matrix $\\mathbf{X} \\in {\\rm\nI\\!R}^{n \\times p}$, and a response variable 𝐲\\mathbf{y}. Then, given appropriate choices of the K−1K - 1 (one for each layer connection), the mathematical model, for a single observation, behind the neural network, can be written in a vectorial notation as follows 𝐳(k)=𝐖(k−1)𝐚(k−1)\n\\mathbf{z}^{(k)} = \\mathbf{W}^{(k - 1)} \\mathbf{a}^{(k - 1)}\n 𝐚(k)=f(k)(𝐳(k)),\n\\mathbf{a}^{(k)} = f_{(k)} \\left( \\mathbf{z}^{(k)} \\right),\n where $\\mathbf{W}^{(k - 1)} \\in {\\rm I\\!R}^{m_{k - 1} \\times m_{k}}$ is the matrix of weights that go from from the layer Lk−1L_{k - 1} to the layer LkL_{k}, $\\mathbf{a}^{(k)} \\in {\\rm I\\!R}^{m_k \\times m_{k + 1}}$ matrix of units at layer LkL_k, and f(k)f_{(k)} is a (element-wise) activation function used at the layer LkL_k. Note that, when k=0k = 0, then 𝐚(0)=𝐗\\mathbf{a}^{(0)} = \\mathbf{X}. Observe that mkm_k is the number of units in the layer kk and, consequently, for the input and output layers, respectively, we have m0=pm_0 = p and mK=1m_K = 1.\nFrom this example, it is clear that we can apply different activation functions when connecting different layers. Nevertheless, the activation for one layer is the same along all of its units.\nAlthough, theoretically, there exists no restriction on which functions to use as activation function, we want these functions to be at least one time differentiable. This is due to the fact that most of the methods used to find the optimal weights are based on gradients. Another aspect to be considered when choosing an activation function is the domain of the output variable yy. That is, if y∈[0,1]y \\in [0, 1], we want an activation function that maps real values to the [0,1][0, 1] interval. In summary, for the output layer, we use a activation function that makes predictions on the same domain as the output variable, while, for hidden layers, we have no restrictions on the activation functions, besides the ones already mentioned.\nSome commonly used link functions are the logit\\textrm{logit}, or sigmoid, function, defined as f(x)=11+e−x,\nf(x) = \\frac{1}{1 + e^{-x}},\n the hyperbolic tangent function, referred to as tanh\\textrm{tanh}, f(x)=ez−e−zez+e−z.\nf(x) = \\frac{e^z - e^{-z}}{e^{z} + e^{-z}}.\n Note that the tanh\\textrm{tanh} is mapping from the real line to the (−1,1)(-1, 1) interval. The Rectified Linear Unit (ReLU) is also a popular choice and is defined as f(x)=x+=max(0,x),\nf(x) = x_{+} = \\max(0, x),\n the main advantage of this function is a cheap to compute gradient. A different version of the ReLU called leaky ReLU is also quite popular, its definition is given as follows f(x)=x+=max(.01*x,x),\nf(x) = x_{+} = \\max(.01 * x, x),\n\nThese are only some examples of commonly used activation functions and they are illustrated in Figure 3. The user does need to be restrict to these options since there are several other functions implemented in the software available to compute neural networks. However, if you want to use a activation function that is not implemented yet, you may have to implement your own version for the algorithm.\n\n\n\n\n\n\n\n\nFigure 3: The most popular activation functions (figure inspired by Figure 18.6 from Efron and Hastie (2016) ).\n\n\n\n\n\nAlthough there are no restrictions on the functions used as activation functions in the hidden layers (besides being differentiable functions), it is not advisable to use the identity function because it implies a waste of computational power. This is due to the fact that using a linear function in a hidden layer, makes the units from that layer a linear combination of the units from the previous layer. To make this clear, let’s prove that a Neural Network model with a single hidden layer collapses to a Generalized Linear Model when the identity function is used as the activation function.\nSuppose a nn-dimensional vector 𝐲\\mathbf{y} is assumed to follow a distribution 𝒫\\mathcal{P}, where 𝒫\\mathcal{P} belongs to the exponential family of distributions. Then, given a design matrix $\\mathbf{X} \\in\n{\\rm I\\!R}^{n \\times p}$, the Generalized Linear Model for 𝐲\\mathbf{y} is composed by the random component, given by the probability density function associated with the distribution 𝒫\\mathcal{P}, the systematic component, defined by 𝛈=𝐗𝛃,(1)\n\\boldsymbol{\\eta} = \\mathbf{X} \\boldsymbol{\\beta},\n \\qquad(1) and a (canonical) link function g(⋅)g(\\cdot) such that 𝛍=g(𝛈).(2)\n\\boldsymbol{\\mu} = g(\\boldsymbol{\\eta}).\n \\qquad(2) Once we estimate the parameters 𝛃\\boldsymbol{\\beta}, we have 𝐲̂=g(𝐗𝛃̂).\n\\hat{\\mathbf{y}} = g( \\mathbf{X} \\hat{\\boldsymbol{\\beta}} ).\n\nDefine now our Neural Network model having a single hidden layer with MM units. The activation function for the hidden layer is fh(x)=g(x)f_h(x) = g(x), that is, the same as the identity function. The weights we want to find are $\\mathbf{W}^{(1)} \\in {\\rm I\\!R}^{p \\times 1}$, and $\\mathbf{W}^{(2)} \\in\n{\\rm I\\!R}^{M \\times n}$. The activation function for the activation layer is the previously mentioned canonical link function. Finally, let the loss be the deviance residual associated with the distribution 𝒫\\mathcal{P}, and the cost function be the average of the losses. Then, the mathematical representation of the Neural Network becomes 𝐳(1)=𝐗𝐖(1)=𝐚(1),(3)\n\\mathbf{z}^{(1)} = \\mathbf{X} \\mathbf{W}^{(1)} = \\mathbf{a}^{(1)},\n \\qquad(3) because the activation function for the hidden layer is the identity. Then, we have 𝐳(2)=𝐚(1)𝐖(2)(4)\n\\mathbf{z}^{(2)} = \\mathbf{a}^{(1)} \\mathbf{W}^{(2)}\n \\qquad(4) 𝐲=𝐚(2)=g(𝐳(𝟐)).(5)\n\\mathbf{y} = \\mathbf{a}^{(2)} = g( \\mathbf{\\mathbf{z}^{(2)}} ).\n \\qquad(5) However, note that, by combining 3, 4, and 5 we get $$\\begin{align*}\n\\mathbf{y} & = g( \\mathbf{\\mathbf{z}^{(2)}} ) \\\\\n& = g( \\mathbf{a}^{(1)} \\mathbf{W}^{(2)} ) \\\\\n& = g( \\mathbf{X} \\underbrace{\\mathbf{W}^{(1)} \\mathbf{W}^{(2)}}_{{\\rm I\\!R}_{p\n\\times 1}} ),\n\\end{align*}$$ which yields to optimal weights (see Fitting a Neural Network and Backpropagation, for more information on how to fit a neural network model) satisfying $$\n\\underbrace{\\mathbf{W}^{(1)} \\mathbf{W}^{(2)}}_{{\\rm I\\!R}_{p\n\\times 1}} = \\hat{\\boldsymbol{\\beta}},\n$$ where 𝛃̂\\hat{\\boldsymbol{\\beta}} is the Maximum Likelihood Estimator for 𝛃\\boldsymbol{\\beta} that can be obtained using the Iterative Reweighted Least Squares for the model defined by the probability density function associated with the distribution 𝒫\\mathcal{P}, the systematic component 1 and a (canonical) link function 2.\n\n\nCost functions\nWhenever we want to fit a neural network to a dataset we need to specify a Cost function, which is usually based on loss functions. A loss function, in the context of Neural Network models, measures how far our predictions f(𝐱;𝐖)f(\\mathbf{x}; \\mathbf{W}) are from the true value yy. Examples of commonly used loss functions, for a single observation, are the mean square error loss and the binomial deviance defined, respectively, as L(𝐰,𝐱;y)=12(f(𝐱;𝐰)−y)2,(6)\nL(\\mathbf{w}, \\mathbf{x}; y) = \\frac{1}{2} (f(\\mathbf{x}; \\mathbf{w}) - y)^{2},\n \\qquad(6) and L(𝐖,𝐱;y)=ylog(yf(𝐱,𝐰))+(1−y)log(1−y1−f(𝐱,𝐰)).(7)\nL(\\mathbf{W}, \\mathbf{x}; y) = y \\log \\left( \\frac{y}{f(\\mathbf{x}, \\mathbf{w})}\n\\right) + \n(1 - y) \\log \\left( \\frac{1 - y}{1 - f(\\mathbf{x}, \\mathbf{w})} \\right).\n \\qquad(7) The loss function 6 is usually employed when the output (response) variable assumes continuous values, while the 7 is used for binary output variables.\nAfter choosing an appropriate loss function, the cost function is defined as the average of the loss function over all the observation, that is C(𝐲;𝐱,𝐖)=1n∑i=1nL(𝐰𝐢,𝐱𝐢;𝐲𝐢)+λJ(𝐖),\nC(\\mathbf{y}; \\mathbf{x}, \\mathbf{W}) = \\frac{1}{n} \\sum_{i = 1}^{n}\nL(\\mathbf{w_i, \\mathbf{x}_i; y_i}) + \\lambda J(\\mathbf{W}),\n where J(𝐖)J(\\mathbf{W}) is a non-negative regularization term and λ≥0\\lambda \\geq\n0 is a tuning parameter.\nIn practice, we may have a regularization term for each layer, each one having its own λ\\lambda. Some commonly used regularization terms are J(𝐖)=12∑k=1K−1‖𝐰(k)‖2,\nJ(\\mathbf{W}) = \\frac{1}{2} \\sum_{k = 1}^{K - 1} \\lVert \\mathbf{w}^{(k)} \\rVert^2,\n and J(𝐖)=12∑k=1K−1‖𝐰(k)‖,\nJ(\\mathbf{W}) = \\frac{1}{2} \\sum_{k = 1}^{K - 1} \\lVert \\mathbf{w}^{(k)} \\rVert,\n where KK is the number of layers of our neural network model, and 𝐰(k)\\mathbf{w}^{(k)} is the vector of weights from the units in the layer LkL_k to the layer Lk+1L_{k + 1}. Note that, these two regularization terms are analogous to the Ridge and Lasso penalizations, and they play the exact same role in neural networks as its analogous versions do for the linear models (Efron and Hastie 2016). Mixtures of these two regularization terms, as in the elastic net (Zou and Hastie 2005), are also common.\n\n\nFitting a Neural Network\nSupposing a user has set the number of layers, units, an activation function and a loss function, to fit a neural network we seek the set of weights 𝐖={𝐖(1),…,𝐖(k−1)}\\mathbf{W}\n= \\{ \\mathbf{W}^{(1)}, \\ldots, \\mathbf{W}^{(k - 1)} \\} such that the cost function is minimized, that is min𝐖{𝒞(𝐲;𝐗,𝐖)}. \n\\min_{\\mathbf{W}} \\left \\{ \\mathcal{C}(\\mathbf{y}; \\mathbf{X}, \\mathbf{W}) \\right \\}.\n Therefore, the neural network fit has turned into an optimization problem. The most common algorithm used to solve this optimization problem is the Backpropagation algorithm, which is described in the next section for a general situation.\n\n\nBackpropagation\nBackpropagation (or gradient descent) is the method used to find the weights which minimize the chosen cost and loss functions for a given neural network. It is an iterative algorithm that is guaranteed to converge whenever the cost function has a single local minima (Efron and Hastie 2016). However, even if the cost function does not have a single local minima, the algorithm works fairly well. The updates for a weight matrix, 𝐖(k)\\mathbf{W}^{(k)} let’s say, is done as follows 𝐖(k)=𝐖(k)−α∂𝒞(𝐲;𝐗,𝐖)∂𝐖(k),(8)\n\\mathbf{W}^{(k)} = \\mathbf{W}^{(k)} - \\alpha \\frac{\\partial\n\\mathcal{C}(\\mathbf{y}; \\mathbf{X}, \\mathbf{W})}{\\partial \\mathbf{W}^{(k)}},\n \\qquad(8) where α\\alpha is a tuning parameter called learning rate. The name backpropagation comes from the fact that the derivatives (or gradients) are computed according to something called a computation graph in a backward fashion. It is heavily based on the chain rule for differentiation.\nGiven initial values for the 𝐖\\mathbf{W} matrices, the method repeats the update rule 8 until convergence. Provided that the columns of the design matrix are rescaled to mean 0 and variance 1, Hastie, Tibshirani, and Friedman (2009) suggest the use of random starting values for the weights as uniform random variables on the interval [−.75,.75][-.75, .75]."
  },
  {
    "objectID": "posts/lmnet/2021-06-23-lmnnet.html#sec:imple",
    "href": "posts/lmnet/2021-06-23-lmnnet.html#sec:imple",
    "title": "Estimating regression coefficients using a Neural Network (from scratch)",
    "section": "Implementation",
    "text": "Implementation\nI created functions for the implementation of a Neural Network with a single hidden layer model for generic activation functions. The implementation considers the cost function defined as C(𝐲;𝐗,𝐘)=1n‖𝐲−𝐲̂‖2.\nC(\\mathbf{y}; \\mathbf{X}, \\mathbf{Y}) = \\frac{1}{n} \\lVert \\mathbf{y} -\n\\hat{\\mathbf{y}} \\rVert^2.\n\nThe inputs for the implemented function are:\n\nA design matrix 𝐗\\mathbf{X}, including the columns of ones for the intercept;\nA column vector 𝐲\\mathbf{y} containing the response variable;\nThe number of units for the hidden layer;\nThe activation function for the hidden layer;\nThe activation function for the output layer;\nA scalar for the learning rate α\\alpha;\nTwo control parameters for the convergence of the algorithm. The maximum number of iterations allowed, and a relative error ϵ\\epsilon which controls when to stop the iteration algorithm.\n\nThe function returns a list of size 5. Its first element is the predicted vector for 𝐲\\mathbf{y}, the second contains the values of the cost function for each iteration of the algorithm. The third position of this list stores the weight matrices 𝐖(1)\\mathbf{W}^{(1)} and 𝐖(2)\\mathbf{W}^{(2)}, while the last two positions store the number of iterations until attain the convergence and a string indicating whether the algorithm converged or not, respectively.\nSee below the implementation of some activation functions (and their derivatives)\n\n##--- activation functions and their derivatives ----\n\n## ReLU\nrelu &lt;- function(x) {\n    pmax(x, 0)\n}\n\n## derivative leaky ReLU\nd_relu &lt;- function(x) {\n    ifelse(x &gt; 0, 1, 0)\n}\n\n## leaky ReLU\nlrelu &lt;- function(x) {\n    pmax(x * .01, x)\n}\n\n## derivative leaky ReLU\nd_lrelu &lt;- function(x) {\n    ifelse(x &gt; 0, 1, .01)\n}\n\n## derivative tanh\nd_tanh &lt;- function(x) {\n    1 - (tanh(x)^2)\n}\n\n## derivative logit\nd_logit &lt;- function(x) {\n    plogis(x) * ( 1 - plogis(x) )\n}\n\n## derivative identity\nd_ident &lt;- function(x) {\n    pmax( -2 * abs(x), 1 )\n}\n\nNow, let’s implement some helper functions to fit our neural network models. First, the cost function used in our examples is given by\n\n## cost function\ncost_f &lt;- function(y, yhat) {\n    crossprod(yhat - y) / NROW(y)\n}\n\nThe implementation of the functions that will need to be executed at each step of the optimization algorithm are defined below. compute_nn computes the hidden layers given the matrix of covariates (or features) X, the list containing the the weights W associated to each layer connection, and two activation functions act_hidden and act_out for the hidden and output layers, respectively (this is a the implementation for a 2 layers network). The compute_grad function computes the gradient and needs some further information like y (the response variable), n the sample size, and the derivatives of the activation functions. update_aux and update_w are helper functions used to update the weights.\n\n##--- functiosn to fit the neural network ----\n\n## computing the forward step of the neural network\ncompute_nn &lt;- function(X, W, act_hidden, act_out) {\n    Z &lt;- vector(mode = \"list\", length = 2)\n    \n    Z[[1]] &lt;- X %*% W[[1]]\n    A &lt;- act_hidden(Z[[1]])\n\n    Z[[2]] &lt;- A %*% W[[2]]\n\n    return( list(y = act_out(Z[[2]]),\n                 z = Z) )\n}\n\n## computing the gradient of the neural network\ncompute_grad &lt;- function(y, X, W, act_hidden, act_out,\n                         d1_hidden, d1_out, n) {\n    nn    &lt;- compute_nn(X, W, act_hidden, act_out)\n    aux_out &lt;- (nn$y - y) * d1_out(nn$z[[2]])\n    aux_hid &lt;- tcrossprod(aux_out, W[[2]]) *\n        d1_hidden(nn$z[[1]])\n    \n    return(\n        list(crossprod(X, aux_hid) / n,\n             crossprod(act_hidden(nn$z[[1]]), aux_out) / n)\n    )\n}\n\n## aux function for updating W\nupdate_aux &lt;- function(w, dw, alpha) {\n    w - alpha * dw\n}\n\n## update the weights of a neural network\nupdate_w &lt;- function(W, alpha, y, X, act_hidden, act_out,\n                     d1_hidden, d1_out, n) {\n\n    grad_w &lt;- compute_grad(y, X, W, act_hidden, act_out,\n                           d1_hidden, d1_out, n)\n    \n    return( Map(f = update_aux, w = W,\n                dw = grad_w, alpha = alpha) )\n}\n\nFinally, all these functions previously describer are used to build the fit_nn function (which is used to compute the optimal weights for the neural network). The alpha is the α\\alpha previously mentioned in this post, maxit and eps are parameters used in the optimization process. The first one stands for the maximum number of iterations to be used in the optimization process, while the second stand for the “optimization error”. That is, if, from one iteration to another, the change between the weights does not exceed eps, then we consider that the algorithm converged and a (maybe local) optimum has been found.\n\nfit_nn &lt;- function(y, X, hid_units,\n                   act_hidden, act_out,\n                   d1_hidden, d1_out,\n                   alpha = .25,\n                   maxit = 500L,\n                   eps   = 1e-05) {\n    m &lt;- hid_units\n    p &lt;- ncol(X)\n    N &lt;- NROW(y)\n\n    \n    W &lt;- list(matrix(runif(m * p, -.75, .75),\n                     ncol = m, nrow = p),\n              matrix(runif(m, -.75, .75), ncol = 1))\n\n    nn   &lt;- vector(mode = \"list\", length = maxit)\n    cost &lt;- vector(mode = \"numeric\", length = maxit)\n\n    ## initialiazing\n    nn[[1]] &lt;- compute_nn(X, W, act_hidden, act_out)\n\n    cost[1] &lt;- cost_f(y, nn[[1]]$y)\n    \n    for( i in seq_len(maxit)[-1] ) {\n        W &lt;- update_w(W, alpha, y, X,\n                      act_hidden, act_out,\n                      d1_hidden, d1_out,\n                      n = N)\n        \n        nn[[i]] &lt;- compute_nn(X, W, act_hidden, act_out)\n        cost[i] &lt;- cost_f(y, nn[[i]]$y)\n        \n        if( abs(cost[i] - cost[i - 1]) &lt; eps ) {\n            output &lt;- list(nn   = nn[[i - 1]],\n                           cost = cost[1:(i - 1)],\n                           W    = W,\n                           it   = (i - 1),\n                           conv = \"yes\")\n            break\n        }\n    }\n\n    if( i == maxit ) {\n        output &lt;- list(yhat = nn[[maxit]]$y,\n                       cost = cost[1:maxit],\n                       W    = W,\n                       it   = maxit,\n                       conv = \"no\")\n    }\n\n    return(output)\n}\n\nHaving all these functions, we can play with some numerical examples!"
  },
  {
    "objectID": "posts/lmnet/2021-06-23-lmnnet.html#sec:ne",
    "href": "posts/lmnet/2021-06-23-lmnnet.html#sec:ne",
    "title": "Estimating regression coefficients using a Neural Network (from scratch)",
    "section": "Numerical Examples",
    "text": "Numerical Examples\n\nExample 1: Equivalence between Neural Network and Linear Model\nConsider a simulated dataset where 𝐲∼N(𝐗𝛃,σ2𝐈n),\n\\mathbf{y} \\sim N(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I}_n),\n where $\\mathbf{X} \\in {\\rm I\\!R}^{n \\times 3}$, with the first column being the intercept term. To simulate the model we used 𝛃=(2,3,1.5)\\boldsymbol{\\beta} = (2, 3,\n1.5). Additionally, suppose n=2000n = 2000.\nConsidering the identity function as the activation function for both layers, the goal here is to show that the 𝐖(1)𝐖(2)=𝛃̂\\mathbf{W}^{(1)} \\mathbf{W}^{(2)} =\n\\hat{\\boldsymbol{\\beta}}, where 𝛃̂\\hat{\\boldsymbol{\\beta}} is the least squares solution for a linear model established as 𝐲=𝐗𝛃\\mathbf{y} = \\mathbf{X}\n\\boldsymbol{\\beta}, and 𝐖(1),𝐖(2)\\mathbf{W}^{(1)}, \\, \\mathbf{W}^{(2)} are the optimal weights according to the Neural Network fitted to the data, as proved in the subsection @ref(subsec:act).\nTable 1 displays the results from the simulated example. The two different approaches have yielded the exactly same results. If we were to make predictions, the two methods would provide the same predicted values under these circumstances.\n\n\n\n\nTable 1: Comparing the LS solution and the product of the neural network weight matrices.\n\n\n\n\n\n\n𝛃̂\\hat{\\boldsymbol{\\beta}}\n𝐖(1)𝐖(2)\\mathbf{W}^{(1)} \\mathbf{W}^{(2)}\n\n\n\n\n2.996\n2.996\n\n\n3.004\n3.004\n\n\n1.512\n1.512\n\n\n\n\n\n\n\n\nSee below the code used on this example.\n\n##--- numerical examples ----\n\n##--- example 1 ----\n\nset.seed(123)\n\nn &lt;- 2000\n\nx1 &lt;- rnorm(n)\nx2 &lt;- as.numeric( scale( rexp(n) ) )\n\ny &lt;- 3 + 3 * x1 + 1.5 * x2 + rnorm(n, sd = .5)\n\nmy_x &lt;- cbind( rep(1, n), x1, x2 )\ncolnames(my_x) &lt;- NULL\n\ndt &lt;- as.data.frame( cbind(y, my_x[, 2:3]) )\nnames(dt) &lt;- c(\"y\", \"x1\", \"x2\")\n\nm &lt;- 6\n\nfit_1 &lt;-\n    fit_nn(y = y, X = my_x,\n           hid_units = m,\n           act_hidden = identity,\n           act_out    = identity,\n           d1_hidden  = d_ident,\n           d1_out     = d_ident,\n           alpha = .05,\n           maxit = 1000L,\n           eps   = 1e-16)\n\nbeta_hat &lt;- coef(lm(y ~ x1 + x2, data = dt))\n\ntbl_1 &lt;- as.data.frame(cbind(beta_hat,\n                             fit_1$W[[1]] %*% fit_1$W[[2]]))\nnames(tbl_1) &lt;- c(\"$\\\\hat{\\\\boldsymbol{\\\\beta}}$\",\n                  \"$\\\\mathbf{W}^{(1)} \\\\mathbf{W}^{(2)}$\")\nrownames(tbl_1) &lt;- NULL\n\n\n\nExample 2: Nonlinear relationship and number of hidden units\nConsider now the following model yi=β0+β1(x2)+εi.\ny_i = \\beta_0 + \\beta_1 (x^2) + \\varepsilon_i.\n\nIn practice, we do not know before-hand the relationship between the response and explanatory variables is not linear. In fig-fit-nn2, we show the fitted curves the linear model and for neural networks under different settings for a dataset simulated from this example. The Neural Network deals nicely with the nonlinearity at the cost of possibly overfit the data.\n\n\n\n\n\n\n\n\nFigure 4: Different models fitted to the same simulated dataset.\n\n\n\n\n\nSee the code used on this example below.\n\n##--- example 2 ----\n\nset.seed(124)\n\nx12 &lt;- rnorm(n)\n\ny2 &lt;- 5 - 2.5 * (x12^2) + rnorm(n, sd = .5)\n\nmy_x2 &lt;- cbind(rep(1, n), x12)\ncolnames(my_x2) &lt;- NULL\n\ndt2 &lt;- as.data.frame( cbind(y2, my_x2[, 2]) )\nnames(dt2) &lt;- c(\"y\", \"x1\")\n\nn_pred &lt;- 4000\n\n## fitting linear model\n\nmy_lm2 &lt;- lm(y ~ x1, data = dt2)\n\n## fitting neural network with tanh as the activation function for the hidden\n## layer - 5 hidden units\nfit_2 &lt;-\n    fit_nn(y = y2, X = my_x2,\n           hid_units  = 5,\n           act_hidden = tanh,\n           act_out    = identity,\n           d1_hidden  = d_tanh,\n           d1_out     = d_ident,\n           alpha = .05,\n           maxit = 1000L,\n           eps   = 1e-04)\n\n## fitting neural network with tanh as the activation function for the hidden\n## layer - 15 hidden units\nfit_3 &lt;-\n    fit_nn(y = y2, X = my_x2,\n           hid_units  = 15,\n           act_hidden = tanh,\n           act_out    = identity,\n           d1_hidden  = d_tanh,\n           d1_out     = d_ident,\n           alpha = .05,\n           maxit = 1000L,\n           eps   = 1e-04)\n\n## fitting neural network with leaky ReLU as the activation function for the\n## hidden layer - 10 hidden units\nfit_4 &lt;-\n    fit_nn(y = y2, X = my_x2,\n           hid_units  = 10,\n           act_hidden = lrelu,\n           act_out    = identity,\n           d1_hidden  = d_lrelu,\n           d1_out     = d_ident,\n           alpha = .05,\n           maxit = 1000L,\n           eps   = 1e-04)\n\npred_data &lt;- data.frame(x = seq(from = min(x12), to = max(x12),\n                                length.out = n_pred))\n\npred_data &lt;- transform(pred_data,\n                       lm = coef(my_lm2)[[1]] + coef(my_lm2)[[1]] * x)\n\npred_data &lt;- transform(pred_data,\n                       nn_tanh_1 =\n                           compute_nn(X = cbind(rep(1, 4000),\n                                                x),\n                                      W = fit_2$W,\n                                      act_hidden = tanh,\n                                      act_out = identity)$y)\n\npred_data &lt;- transform(pred_data,\n                       nn_tanh_2 =\n                           compute_nn(X = cbind(rep(1, 4000),\n                                                x),\n                                      W = fit_3$W,\n                                      act_hidden = tanh,\n                                      act_out = identity)$y)\n\npred_data &lt;- transform(pred_data,\n                       nn_lrelu =\n                           compute_nn(X = cbind(rep(1, 4000),\n                                                x),\n                                      W = fit_4$W,\n                                      act_hidden = lrelu,\n                                      act_out = identity)$y)\n\nsetDT(pred_data)\n\npred_data &lt;- melt(pred_data, id = 1,\n                  value.name = \"pred\",\n                  variable.name = \"method\")\n\npred_data[, method := fcase(method == \"nn_tanh_1\", \"tanh - 5\",\n                            method == \"nn_tanh_2\", \"tanh - 15\",\n                            method == \"nn_lrelu\", \"leaky ReLU - 10\",\n                            default = \"lm\")]\n\nggplot(data = pred_data) +\n    geom_point(data = dt2, aes(x = x1, y = y),\n               alpha = .5) +\n    geom_line(aes(x = x, y = pred, color = method),\n              lwd = 1.05) +\n    scale_color_discrete(name = NULL) +\n    theme_bw() +\n    theme(\n        legend.position = \"bottom\",\n        legend.margin = margin(6, 6, 6, 6)\n    ) +\n    labs(x = \"X\", y = \"Y\")"
  },
  {
    "objectID": "posts/lmnet/2021-06-23-lmnnet.html#final-thoughts",
    "href": "posts/lmnet/2021-06-23-lmnnet.html#final-thoughts",
    "title": "Estimating regression coefficients using a Neural Network (from scratch)",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThe Neural Network Regression models are very interesting but certainly are not magical as it is sold in the market. By the end of the day, these models consist of simple linear algebra allied to the use of element-wise nonlinear functions and optimization algorithms. Speaking on optimization algorithm, the gradient descent looks like a fixed-point iteration algorithm. These kind of algorithms have the advantage of not need the second derivative of the functions, however their convergence can be slow. I believe that using different learning rates for different parameters could improve the speed on which the algorithm converges.\nAlthough these models do not make any distributional assumption on the data, we can easily make it more suitable for certain distributions by working with the cost and activation functions on an appropriate fashion.\nThere are several variants of these models suited for different problems, like text and image classification, for example. The idea is the same, what changes is the way the researchers deal with the hidden layers. I think an interesting application is to try to use neural networks to estimate non-parametrically covariance matrices for spatial data."
  },
  {
    "objectID": "posts/lmnet/2021-06-23-lmnnet.html#footnotes",
    "href": "posts/lmnet/2021-06-23-lmnnet.html#footnotes",
    "title": "Estimating regression coefficients using a Neural Network (from scratch)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFeatures are the name given for predictors in the neural networks literature↩︎\nSometimes referred to as multi-layer-perceptron, and back-propagation.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lucas Godoy",
    "section": "",
    "text": "Hello there. It’s Lucas. I recently earned a Ph.D. in Statistics from UConn. Soon after graduating, I have begun working with species distribution as a Postdoctoral researcher in the Global Change Research Group at UCSC. My research interests primarily revolve around statistical computing, Bayesian inference, spatial statistics, and exploring innovative applications of statistical methodologies. Apart from that, I enjoy learning about programming languages and playing football (or soccer, pff).\nIn this website, you’ll find some of my blog posts, mainly discussing R or statistical concepts, as well as my CV, publications, and (someday) ongoing projects."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n\n\n\n\n\nUsing jupyter on an HPC cluster\n\n\n\n\n\nJun 9, 2022\n\n\nLucas Godoy\n\n4 min\n\n\n\n\n\n\nAll models are wrong\n\n\n\n\n\nAug 15, 2021\n\n\nLucas Godoy\n\n2 min\n\n\n\n\n\n\nEstimating regression coefficients using a Neural Network (from scratch)\n\n\n\n\n\nJul 28, 2021\n\n\nLucas Godoy\n\n48 min\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/jupyter_hpc/jupyter_hpc.html",
    "href": "posts/jupyter_hpc/jupyter_hpc.html",
    "title": "Using jupyter on an HPC cluster",
    "section": "",
    "text": "This post was originally written for the CBC-UCONN HC wiki\nThe purpose of this post is to enable cluster users to run jupyter on the cluster interactively, enabling them to conduct data analysis and visualization. There are different “flavors” of jupyter notebooks, the most appropriate are going to be pointed out at picking a container."
  },
  {
    "objectID": "posts/jupyter_hpc/jupyter_hpc.html#preliminaries",
    "href": "posts/jupyter_hpc/jupyter_hpc.html#preliminaries",
    "title": "Using jupyter on an HPC cluster",
    "section": "Preliminaries",
    "text": "Preliminaries\nWe assume that the user has access to ssh through a terminal. In addition, it is necessary to have SingularityCE (singularity for short) installed on a computer on which you have root privileges.\n\nIn order to use singularity on a Windows (or Mac) machine, a Linux Virtual Machine(VM) needs to be set up. Setting up a VM and installing SingularityCE os beyond the scope of this document.\n\nIn addition, singularity is assumed to be available on the HPC that you have access to. Usually, users have to run\n\nmodule load singularity/&lt;version&gt;\n\nbefore using it.\nFamiliarity with containers is helpful but not necessary. Loosely speaking, a container allows us to “isolate” a set of tools and software in order to guarantee code reproducibility and portability. Moreover, singularity was developed (among other reasons) to integrate these tools with HPC clusters."
  },
  {
    "objectID": "posts/jupyter_hpc/jupyter_hpc.html#pick-cont",
    "href": "posts/jupyter_hpc/jupyter_hpc.html#pick-cont",
    "title": "Using jupyter on an HPC cluster",
    "section": "Picking a container",
    "text": "Picking a container\nThe Jupyter Docker Stacks contains several useful docker containers that can be easily used to build singularity containers.\nA list of the containers (along with their principal features) maintained by the Jupyter team can be found here. Some of these containers are detailed below\n\njupyter/r-notebook: a container containing a basic installation for Machine Learning using R.\njupyter/scipy-notebook: contains popular libraries for scientific computing using python.\njupyter/tensorflow-notebook: this is the jupyter/scipy-notebook with tensorflow installed on it.\njupyter/datascience-notebook: includes libraries for data analysis from the julia, python, andR` communities."
  },
  {
    "objectID": "posts/jupyter_hpc/jupyter_hpc.html#converting-a-docker-into-a-singularity-container",
    "href": "posts/jupyter_hpc/jupyter_hpc.html#converting-a-docker-into-a-singularity-container",
    "title": "Using jupyter on an HPC cluster",
    "section": "Converting a docker into a singularity container",
    "text": "Converting a docker into a singularity container\nOnce you have chosen a container suitable for your needs (and have root access to a machine with singularity), a singularity container can be generated by executing the following chunk of code in the terminal.\n\n## singularity pull &lt;choose-a-name&gt;.sif docker://jupyter/&lt;preferred-notebook&gt;\nsingularity pull mycontainer.sif docker://jupyter/datascience-notebook\n\nIn the example above, I choose to use the datascience-notebook. After doing so, the .sif file generated by singularity needs to be transferred to the cluster. My personal preference is to use either scp or rsync, for example\n\nrsync mycontainer.sif &lt;username&gt;@&lt;hpc-url&gt;:&lt;location&gt;"
  },
  {
    "objectID": "posts/jupyter_hpc/jupyter_hpc.html#using-the-singularity-container-on-the-cluster",
    "href": "posts/jupyter_hpc/jupyter_hpc.html#using-the-singularity-container-on-the-cluster",
    "title": "Using jupyter on an HPC cluster",
    "section": "Using the singularity container on the cluster",
    "text": "Using the singularity container on the cluster\nAfter transferring the .sif file to the cluster, follow the following steps. Firstly, set up the VPN and log-in to the cluster using ssh, then navigate to the location where you transferred the container (.sif) to. Next, you will have to start a interactive job. If the workload manager used in the HPC that you have access to is SLURM, this can be done either with srun or fisbatch. To start an interactive job with srun use\n\nsrun --partition=&lt;partition-name&gt; --qos=&lt;queue-name&gt; --mem=64G --pty bash\n\nThe same task can be achieved with fisbatch (if available) with\n\nfisbatch --partition=&lt;partition-name&gt; --qos=&lt;queue-name&gt; --mem=64G\n\nEither of these commands will allocate your job to a specific node. It is important to save the name of the node that your job has been allocated to. Next, load singularity on that node as follows\n\nmodule load singularity/&lt;version&gt;\n\nThe penultimate step is to start the jupyter instance. It is done as follows\n\nsingularity exec --nv mycontainer.sif jupyter notebook --no-browser --ip='*'\n\nAfter executing the last chunk of code, the terminal will be “busy” and will provide three URLs, they will look somewhat like “http://127.0.0.1:8888/” this. Copy the last address provided by the output. The last step before being able to access the notebook through the provided address is to create a ssh tunnel. To do so, open another terminal window and execute\n\nssh -NL localhost:8888:&lt;node&gt;:8888 &lt;username&gt;@&lt;hpc-url&gt;\n\nwhere &lt;node&gt; should be replaced by the node to which the job submitted using srun (or fisbatch) was submitted to. This tunnel will keep the other terminal window busy to.\nFinally, copy the address provided by the notebook (e.g., “http://127.0.0.1:8888/”) and paste it into your browser."
  },
  {
    "objectID": "posts/models/models.html",
    "href": "posts/models/models.html",
    "title": "All models are wrong",
    "section": "",
    "text": "George Box’s 1976 paper named “Science and Statistics” is famous for that “all models are wrong” quote. Unfortunately, The number of people who know this quote is larger than those who have read the paper entirely.\nThe paper provides interesting (and insightful) discussions that still apply to the field of statistics nowadays. In my opinion, one of the most remarkable things Dr. Box pointed out is about “Mathematistry,” he defines (or explains) it as follows: &gt; “Mathematistry is characterized by development of theory for theory’s sake, &gt; which since it seldom touches down with practice, has a tendency to redefine &gt; the problem rather than solve it.”\nLater on, in the same paper, he mentions how this “malady” (in his words) is harmful to statistics as a field. &gt; “An even more serious consequence of mathematistry concerns the training of &gt; statisticians. We have recently been passing through a period where nothing &gt; very much was expected of the statistician. A great deal of research money &gt; was available and one had the curious situation where the highest objective of &gt; the teacher of statistics was to produce a student who would be another &gt; teacher of statistics. It was thus possible for successive generations of &gt; teachers to be produced with no practical knowledge of the subject whatever. &gt; Although statistics departments in universities are now commonplace there &gt; continues to be a severe shortage of statisticians competent to deal with real &gt; problems. But such are needed.”\nWe still face these challenges (on many others he mentioned in that paper) in Statistics. Therefore, it would be nice to share this to make people think about it.\n\n\n\nCitationBibTeX citation:@online{godoy2021,\n  author = {Godoy, Lucas},\n  title = {All Models Are Wrong},\n  date = {2021-08-15},\n  url = {https://lcgodoy.me/posts/models/models.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGodoy, Lucas. 2021. “All Models Are Wrong.” August 15,\n2021. https://lcgodoy.me/posts/models/models.html."
  },
  {
    "objectID": "slides/2024-cobal/index.html#too-many-slides",
    "href": "slides/2024-cobal/index.html#too-many-slides",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Too many slides…",
    "text": "Too many slides…"
  },
  {
    "objectID": "slides/2024-cobal/index.html#tuberculosis-in-context",
    "href": "slides/2024-cobal/index.html#tuberculosis-in-context",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Tuberculosis in context",
    "text": "Tuberculosis in context\n\nMortality: Tuberculosis (TB) remains a major global health threat, second in infectious disease mortality only to COVID-19.\nRio Grande do Sul (RS) reported significantly higher incidence than the national average in 2021, with the eastern region even more affected.\nDependence: Studies demonstrate strong spatial dependence of TB infections in Brazil, but temporal and spatiotemporal structures have been largely overlooked.\nRisk Factors: TB risk factors include densely populated areas, poverty, substance abuse, and incarceration (Cortez et al. 2021)."
  },
  {
    "objectID": "slides/2024-cobal/index.html#spatiotemporal-spt-models-for-areal-data",
    "href": "slides/2024-cobal/index.html#spatiotemporal-spt-models-for-areal-data",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Spatiotemporal (SPT) models for areal data",
    "text": "Spatiotemporal (SPT) models for areal data\n\nSpatial models: CAR (Besag 1974), ICAR, BYM (Besag et al. 1991), DAGAR (Datta et al. 2019), RENeGe (Cruz-Reyes et al. 2023).\nNonseparable SPT models are more complex as they consider that the spatial and temporal correlations might be intertwined (Cressie and Wikle 2015, pg. 309–321).\nSeparable models one way to look at these models is as multivariate spatial processes (MacNab 2022).\nAdvantages of separable models: Computational efficiency & positive-definiteness of the covariance function."
  },
  {
    "objectID": "slides/2024-cobal/index.html#proposed-methodology-objectives",
    "href": "slides/2024-cobal/index.html#proposed-methodology-objectives",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Proposed methodology & Objectives",
    "text": "Proposed methodology & Objectives\n\nHausdorff–Gaussian Process (HGP): we propose using the newly developed HGP for the spatial portion of the model (Godoy et al. 2024).\nReliable incidence estimates:\n\nSmaller municipalities benefit from borrowed strength from neighbors, improving estimate reliability.\nResults enable the calculation of standardized incidence ratios to pinpoint high-risk areas.\n\nForecasting: Predicted TB incidence rates one year ahead offer crucial insights for proactive public health planning."
  },
  {
    "objectID": "slides/2024-cobal/index.html#preliminaries",
    "href": "slides/2024-cobal/index.html#preliminaries",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nAreal spatial units are (closed and bounded) sets.\nWe need to generalize distance between points to distance between sets.\nIdeally, this distance should:\n\nTake into account the shape, size, and orientation of spatial sample units.\nBe “spatially interpretable”."
  },
  {
    "objectID": "slides/2024-cobal/index.html#distances-between-sets",
    "href": "slides/2024-cobal/index.html#distances-between-sets",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Distances between sets",
    "text": "Distances between sets\n\n\n\nDistance between a point and a set: \\(d(x, A) = \\inf_{a \\in A}\nd(x, a)\\), where \\(d(x, y)\\) is the distance between any two elements \\(x, y \\in\nD\\)\nDirected Hausdorff & Hausdorff distance: \\[{\\vec h}(A, B) =\n\\sup_{a \\in A} d(a, B) \\quad \\text{and} \\quad h(A, B) = \\max \\left \\{\n\\vec{h}(A, B), \\vec{h}(B, A) \\right \\}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymmetric Hausdorff distance: the greater of the two directed Hausdorff distances.\nNote that if \\(A\\) and \\(B\\) are both singletons, then \\(h(A, B) = d(A, B)\\).\n\nMeric Properties: (1) Symmetry: \\(d(x, y) = d(y, x)\\); (2) Nonnegativeness: \\(d(x,\ny) \\geq 0\\) and \\(d(x, x) = 0\\); (3)Positiveness: \\(d(x, y) = 0 \\implies x = y\\); (4) Triangle inequality: \\(d(x, y) \\leq d(x, z) + d(z, y)\\)\n\nMetric on \\(D \\setminus \\varnothing\\)\nThe Hausdorff distance ability to account for spatial units’ shapes, sizes and orientation(Min et al. 2007) renders it an interesting tool to achieve our goals.\nMoreover, it can distinguish between overlapping, nested, and disjointed regions.\nIn the figure: (1) The dashed lines denote the Hausdorff distances; (2) The infimum distance between to sets is zero for the three cases; (3) Distance between centroids is the same for the first two figures."
  },
  {
    "objectID": "slides/2024-cobal/index.html#the-hgp",
    "href": "slides/2024-cobal/index.html#the-hgp",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "The HGP",
    "text": "The HGP\n\nGeneral spatial model: \\(\\{ Z(\\mathbf{s}) \\; : \\; \\mathbf{s} \\in\n\\mathcal{B}(D) \\}\\).\nIndex set: \\(\\mathcal{B}(D)\\) represents the closed and bounded subsets of \\(D \\subset \\mathbb{R}^2\\).\nAssumption: The HGP assumes \\(Z(\\mathbf{s})\\) to be an isotropic Gaussian Process such that its spatial correlation function depends on the Hausdorff distance.\nPowered Exponential Correlation (PEC) function: \\(r(h) =\n\\exp\\left \\{ - \\frac{h^{\\nu}}{\\phi^{\\nu}}\\right \\},\\) where \\(h\\) denotes the Hausdorff distance between \\(\\mathbf{s}_1, \\mathbf{s}_2 \\in\n\\mathcal{B}(D)\\).\n\n\n\nIdeally, we want bounded, compact, and non-empty sets for the Hausdorff distance to be a metric..\nIn \\(\\mathbb{R}^2\\), a compact subset is bounded.\nempty is a subset of any set -&gt; it is bounded bc a subset of a bounded set is bounded itself.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nThe SD function allows the HGP to accommodate both homoscedastic and heteroscedastic scenarios."
  },
  {
    "objectID": "slides/2024-cobal/index.html#data-model",
    "href": "slides/2024-cobal/index.html#data-model",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Data & Model",
    "text": "Data & Model\n\nSample units: 54 municipalities, across 11 years (2011 to 2021). We use 2022 to assess the quality of predictions.\nNumber of TB cases: \\(Y_t(\\mathbf{s}_i)\\) at location \\(\\mathbf{s}_i\\) and time \\(t\\).\nPopulation: \\(P_t(\\mathbf{s}_i)\\).\nFive covariates and two way interactions with presence of prison (except IDESE).\n\n\\[\\begin{aligned}\n& (Y_t(\\mathbf{s}_i) \\mid \\mathbf{X}_{t}(\\mathbf{s}_i), Z(\\mathbf{s}_i, t))\n  \\overset{{\\rm ind}}{\\sim}\n  \\text{Poisson}(P_t(\\mathbf{s}_i) \\mu_{it}) \\\\\n& \\log(\\mu_{it}) = \\alpha + \\mathbf{X}^\\top_{t}(\\mathbf{s}_i) \\beta + Z(\\mathbf{s}_i, t)\n\\end{aligned}\\]\n\n\n\\(\\mu_it\\): rate\nA weakly informative Beta prior with mode at 0.75 and standard deviation around 0.22.\nPrior sensitivity using Importance Sampling and power-scaling."
  },
  {
    "objectID": "slides/2024-cobal/index.html#priors",
    "href": "slides/2024-cobal/index.html#priors",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Priors",
    "text": "Priors\n\nWe assume \\(Z(\\mathbf{s}, t)\\) is a separable zero-mean Gaussian model such that its SPT covariance matrix is the kronecker product between a spatial covariance (HGP, BYM, & DAGAR) and a temporal correlation (\\(\\mathrm{AR}(1)\\)).\nHGP spatial dependence: \\(\\rho \\sim \\mathrm{Exp}(a_\\rho)\\), where \\(a_{\\rho} = - \\log(p_{\\rho}) / \\rho_0\\). \\(a_\\rho\\) is chosen such that \\(\\mathbb{P}(\\rho &gt; \\rho_0) = p_\\rho\\).\nSmoothness & marginal SD: \\(\\nu \\sim \\mathrm{Beta}(2.5, 1.5)\\) (mode at \\(0.75\\)) & \\(\\sigma \\sim t_{+}(3)\\).\nTemporal dependence: PC prior (Sørbye and Rue 2017) where \\(\\mathbb{P}(\\lvert \\psi \\rvert &gt; 0.8) = 0.1\\).\nIntercept & regression coefficients: \\(\\alpha\\) (i.e., \\(\\pi(\\alpha) \\propto 1\\)) & \\(\\boldsymbol{\\beta} \\sim \\mathcal{N}(\\mathbf{0},\n10 \\mathbf{I})\\)\n\n\n\nFor \\(\\rho\\), the prior is inspired in penalized complexity priors. A conservative, but reasonable, choice for its hyperparameter is setting \\(a_\\rho\\) such that \\(\\rho_0\\) is a surprisingly low practical range and \\(p_rho\\) is a small probability (i.e., around .01)"
  },
  {
    "objectID": "slides/2024-cobal/index.html#computational-considerations",
    "href": "slides/2024-cobal/index.html#computational-considerations",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Computational considerations",
    "text": "Computational considerations\n\nSuper effortful: \\(vec(\\mathbf{Z}) \\sim \\mathcal{N}(\\mathbf{0},\n\\sigma^2 \\mathrm{R}_s \\otimes \\mathrm{R}_t)\\) requires \\(\\mathcal{O}(N^3 T^3)\\) flops (and storage).\nEffortful: With linear algebra, we can reduce the computational complexity (and storage) to \\(\\approx \\mathcal{O}(N^3 + T^3)\\)\nNeutral: More linear algebra can be used to evaluate a quadratic form with less operations.\nClever: The Cholesky decomposition of \\(R^{-1}_t\\) is tridiagonal.\nSuper clever: The complexity to obtain \\(chol(R^{-1}_s)\\) is dramatically decreased using nearest-neighbor approximations (Finley et al. 2019)."
  },
  {
    "objectID": "slides/2024-cobal/index.html#bayesian-inference-model-assessment",
    "href": "slides/2024-cobal/index.html#bayesian-inference-model-assessment",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Bayesian Inference & Model Assessment",
    "text": "Bayesian Inference & Model Assessment\n\nPosterior: \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y},\n\\mathbf{z}) \\propto p(\\mathbf{y} \\mid \\mathbf{z}, \\boldsymbol{\\theta})\np(\\mathbf{z} \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta})\\)\nMCMC sampler: No-U-Turn (Homan and Gelman 2014).\nConvergence assessment: traceplots and split-\\({\\hat{R}}\\) (Vehtari et al. 2021).\nGoodness-of-fit criteria: LOOIC (lower values indicate better fit)\nPosterior predictive distributions: \\(p(\\mathbf{y}^{\\ast} \\mid\n\\mathbf{y})\\)\nPredictions assessment: Interval Score (IS) and RMSP (lower values indicate better fit)\n\n\n\nPoint and interval estimates: median and percentiles (\\(0.025\\) and \\(0.975\\)) of the marginal MCMC samples.\nParameters initialized by random sampling from their priors.\nRandom effects initialized from a standard normal distribution.\n\\(a_\\rho\\) is chosen so that: \\(\\mathbb{P}(\\rho &gt; U) = p_\\rho\\). In particular, \\(a_\\rho = - \\log(p_\\rho) / \\rho_0\\).\n\\(\\nu\\) hard to be estimated.\n\nPredictions:\n\nuse the properties of GP and multivariate Normal distribution to obtain the closed-form distribution of the vector of spatial random effects \\(\\mathbf{Z}^\\ast\\) (Diggle et al. 1998);\nsample \\(\\mathbf{z}^\\ast_{(b)}\\) from the distribution derived in the previous step;\nsample \\(\\mathbf{y}^{\\ast}_{(b)}\\) from \\(p(\\mathbf{y}^{\\ast} \\mid \\boldsymbol{\\theta}_{(b)},\n\\mathbf{z}^{\\ast}_{(b)})\\), where \\(\\boldsymbol{\\theta}_{(b)}\\) is the \\(b\\)-th MCMC sample of \\(\\boldsymbol{\\theta}\\)."
  },
  {
    "objectID": "slides/2024-cobal/index.html#spatiotemporal-trend",
    "href": "slides/2024-cobal/index.html#spatiotemporal-trend",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Spatiotemporal Trend",
    "text": "Spatiotemporal Trend\n\n\n\n\nAnother COVARIATE: Presence of prison. Around 24% of the municipalities had at least one prison. Incarcerated population was not available at a yearly basis.\n\nCases per 100k inhabitants.\n2015 and 2016: 2014 - World Cup; 2016 Olympic Games.\n2019 COVID.\nIn general, we can see a spatial pattern and a decreasing trend."
  },
  {
    "objectID": "slides/2024-cobal/index.html#explanatory-variables",
    "href": "slides/2024-cobal/index.html#explanatory-variables",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Explanatory Variables",
    "text": "Explanatory Variables\n\n\n\npop. dens: log and then scaled.\nidese: scaled (IDESE is released yearly in RS and it is similar to IDH).\nhomicide rates: EB then log-transformed then scaled\nHSDR: scaled.\nTransformations: Avoiding long-tails and highly influential observations"
  },
  {
    "objectID": "slides/2024-cobal/index.html#results-gof-and-predictive-performance",
    "href": "slides/2024-cobal/index.html#results-gof-and-predictive-performance",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Results: GOF and Predictive Performance",
    "text": "Results: GOF and Predictive Performance\n\n\n\n\n\n\n\n\n\n\n\nLOOIC\nRMSP\nIS\n\n\n\n\nHGP\n3516.1\n21.1\n87.8\n\n\nBYM\n3606.1\n123.3\n176.6\n\n\nDAGAR\n3520.9\n22.4\n88.8\n\n\n\n\n\n\nHGP vs. Specialized Models: When compared to specialized models like DAGAR, the HGP demonstrates highly competitive GOF performance.\nMinor Differences: While DAGAR slightly outperformed on some fit criteria, the overall goodness-of-fit differences between the HGP and DAGAR were minimal.\nPredictive Power: The HGP excels in predictive performance, outperforming competitors on both RMSP (point prediction accuracy) and IS (interval prediction accuracy)."
  },
  {
    "objectID": "slides/2024-cobal/index.html#results-relative-risks",
    "href": "slides/2024-cobal/index.html#results-relative-risks",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Results: Relative Risks",
    "text": "Results: Relative Risks\n\n\n\n\nParameter\nDescription\nEstimate\n\n\n\n\n\\(\\exp(\\beta_1)\\)\nPrison\n2.34 (1.70, 3.19)\n\n\n\\(\\exp(\\beta_2)\\)\nPop / km2\n1.33 (1.15, 1.56)\n\n\n\\(\\exp(\\beta_2 + \\beta_{21})\\)\n\n1.75 (1.18, 2.52)\n\n\n\\(\\exp(\\beta_3)\\)\nHS dropout %\n1.03 (0.99, 1.07)\n\n\n\\(\\exp(\\beta_3 + \\beta_{31})\\)\n\n2.25 (1.63, 3.09)\n\n\n\\(\\exp(\\beta_4)\\)\nHomicide rate\n0.97 (0.93, 1.00)\n\n\n\\(\\exp(\\beta_4 + \\beta_{41})\\)\n\n2.51 (1.83, 3.46)\n\n\n\\(\\exp(\\beta_5)\\)\nIDESE\n0.99 (0.92, 1.07)\n\n\n\n\n\n\nrelative risk estimates derived from regression coefficients.\n(1): dummy for prison presence; (2) pop/km2; (3) homicides; (4) high school;\n\nIDESE;\n\nDouble-digit indices represent interactions between variables\nMunicipalities with prisons have a 2.34 times higher average TB incidence, even when controlling for other factors.\nhomicide rates and hsdr not important in prison-free municipalities but worsen the risk in municipalities with prisons."
  },
  {
    "objectID": "slides/2024-cobal/index.html#spatiotemporal-dependence",
    "href": "slides/2024-cobal/index.html#spatiotemporal-dependence",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Spatiotemporal Dependence",
    "text": "Spatiotemporal Dependence\n\n\n\nImportance of spatiotemporal term\nWithout the municipality random intercept we get even stronger spatial dependence.\nNot possible to make such graph for other areal models."
  },
  {
    "objectID": "slides/2024-cobal/index.html#small-municipalities",
    "href": "slides/2024-cobal/index.html#small-municipalities",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Small Municipalities",
    "text": "Small Municipalities"
  },
  {
    "objectID": "slides/2024-cobal/index.html#forecast",
    "href": "slides/2024-cobal/index.html#forecast",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Forecast",
    "text": "Forecast"
  },
  {
    "objectID": "slides/2024-cobal/index.html#closing-remarks-1",
    "href": "slides/2024-cobal/index.html#closing-remarks-1",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Closing remarks",
    "text": "Closing remarks\n\nTailored an HGP extension for spatiotemporal disease mapping.\nCompetitive with specialized models\nIt helps to gain insights into spatiotemporal disease mapping through spatiotemporal correlation functions.\nMore reliable estimates of risk factors\nOut-of-sample predictions to inform public policies\n\n\nKey Takeaway: The HGP’s versatility and performance make it a valuable tool in your spatial analysis toolkit."
  },
  {
    "objectID": "slides/2024-cobal/index.html#references",
    "href": "slides/2024-cobal/index.html#references",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "",
    "text": "References\n\n\nBesag, J. (1974), “Spatial interaction and the statistical analysis of lattice systems,” Journal of the Royal Statistical Society. Series B (Methodological), JSTOR, 192–236.\n\n\nBesag, J., York, J., and Mollié, A. (1991), “Bayesian image restoration, with two applications in spatial statistics,” Annals of the Institute of Statistical Mathematics, 43, 1–20.\n\n\nCortez, A. O., Melo, A. C. de, Neves, L. de O., Resende, K. A., and Camargos, P. (2021), “Tuberculosis in Brazil: One country, multiple realities,” Jornal Brasileiro de Pneumologia, Sociedade Brasileira de Pneumologia e Tisiologia, 47, e20200119. https://doi.org/10.36416/1806-3756/e20200119.\n\n\nCressie, N., and Wikle, C. K. (2015), Statistics for spatio-temporal data, Wiley.\n\n\nCruz-Reyes, D. L., Assunção, R. M., and Loschi, R. H. (2023), “Inducing high spatial correlation with randomly edge-weighted neighborhood graphs,” Bayesian Analysis, International Society for Bayesian Analysis, 1, 1–35.\n\n\nDatta, A., Banerjee, S., Hodges, J. S., and Gao, L. (2019), “Spatial disease mapping using directed acyclic graph auto-regressive (DAGAR) models,” Bayesian analysis, NIH Public Access, 14, 1221.\n\n\nDiggle, P. J., Tawn, J. A., and Moyeed, R. A. (1998), “Model-based geostatistics,” Journal of the Royal Statistical Society Series C: Applied Statistics, Oxford University Press, 47, 299–350.\n\n\nFinley, A. O., Datta, A., Cook, B. D., Morton, D. C., Andersen, H. E., and Banerjee, S. (2019), “Efficient algorithms for bayesian nearest neighbor gaussian processes,” Journal of Computational and Graphical Statistics, ASA Website, 28, 401–414. https://doi.org/10.1080/10618600.2018.1537924.\n\n\nGodoy, L. da C., Prates, M. O., and Yan, J. (2024), “Statistical inferences and predictions for areal data and spatial data fusion with hausdorff–gaussian processes,” Journal of the American Statistical Association (under review). https://doi.org/10.48550/arXiv.2208.07900.\n\n\nHoman, M. D., and Gelman, A. (2014), “The No-U-turn sampler: Adaptively setting path lengths in hamiltonian Monte Carlo,” Journal of Machine Learning Research, JMLR.org, 15, 1593–1623.\n\n\nMacNab, Y. C. (2022), “Bayesian disease mapping: Past, present, and future,” Spatial Statistics, Elsevier, 50, 100593.\n\n\nMin, D., Zhilin, L., and Xiaoyong, C. (2007), “Extended Hausdorff distance for spatial objects in GIS,” International Journal of Geographical Information Science, Taylor & Francis, 21, 459–475.\n\n\nSørbye, S. H., and Rue, H. (2017), “Penalised complexity priors for stationary autoregressive processes,” Journal of Time Series Analysis, Wiley Online Library, 38, 923–935.\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., and Bürkner, P.-C. (2021), “Rank-normalization, folding, and localization: An improved \\(\\hat{R}\\) for assessing convergence of MCMC (with discussion),” Bayesian Analysis, International Society for Bayesian Analysis, 16, 667–718."
  },
  {
    "objectID": "slides/2024-cobal/index.html#sensitivity-analysis",
    "href": "slides/2024-cobal/index.html#sensitivity-analysis",
    "title": "Spatiotemporal Analysis of Tuberculosis using Hausdorff–Gaussian Processes",
    "section": "Sensitivity analysis",
    "text": "Sensitivity analysis"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#spatial-statistics",
    "href": "slides/2024-ucsc/index.html#spatial-statistics",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Spatial Statistics",
    "text": "Spatial Statistics\n\nTaking into account spatial dependence possibly present in data is a foremost aspect of spatial statistics.\nGeneral spatial model (Cressie 1993): \\(\\{\nZ(\\mathbf{s}) \\; : \\; \\mathbf{s} \\in D \\}\\), where \\(D\\) is an index set.\nStatistical inference depends heavily on the spatial structure/geometry of the observed spatial data.\n\n\n\n\nGeometry\nBranch\nIndex set\n\n\n\n\nAreas/polygons\nAreal models\nCountable\n\n\nPoints\nGeostatistics\nContinuum\n\n\nMixed\nSpatial Data Fusion\n\n\n\n\n\n\nChallenges arise when working with data from different sources:\n\nChange of support\nSpatial misalignment\nData fusion itself.\n\n\nLoosely speaking, this means the GP has stationary mean, variance, and a correlation function such that the correlation between two data points depends solely on their distance.\n\nCommon assumptions are stationarity and isotropy.\nImportance in spatial statistics: predominant foundation of geostatistical modeling.\nCompletely specified by mean and covariance functions.\n\nThe main reasons these models are not applied to areal data are:\n\nCalculating distance between areal spatial units is non-trivial;\nThe commonly used areal models are computationally efficient."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#classic-models-for-spatial-data",
    "href": "slides/2024-ucsc/index.html#classic-models-for-spatial-data",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Classic Models for Spatial Data",
    "text": "Classic Models for Spatial Data\n\nAreal data\n\nCAR (Besag 1974), ICAR, BYM (Besag et al. 1991), DAGAR (Datta et al. 2019).\n\nPoint-referenced data\n\nGaussian processes (GP), Nearest-neighbor mixture processes (Zheng et al. 2023)\n\nMixed/fused data\n\n“Aggregated” GP (AGP) (Moraga et al. 2017): \\[\nZ(\\mathbf{s}_i)\n= \\begin{cases}\nZ(\\mathbf{s}_i), & \\text{if } \\mathcal{A}(\\mathbf{s}_i) = 0 \\\\\n{\\mathcal{A}(\\mathbf{s}_i)}^{-1}\n\\int_{\\mathcal{A}(\\mathbf{s}_i)} Z(\\mathbf{s}) \\mathrm{d}\\mathbf{s}, & \\text{if }\n\\mathcal{A}(\\mathbf{s}_i) &gt; 0\n\\end{cases}\n\\]\n\n\n\n\nAreal models are usually heteroscedastic; The marginal variances decrease with the number of neighbors;\nData fusion models are also heteroscedastic (unless all the polygons are of the same size); computationally prohibitive for moderately large datasets; arbitrary choice of grid resolution."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#research-questions",
    "href": "slides/2024-ucsc/index.html#research-questions",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Research Questions",
    "text": "Research Questions\n\nThe main research questions we are interested in are:\n\nCan we propose a model for spatial data that accomodates areal, point-referrenced, and fused data?\nIf so, is this model competitive when compared to specialized models?\n\nProposal: An isotropic GP defined on a flexible index set.\nMain challenge: Defining a valid correlation function."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#preliminaries",
    "href": "slides/2024-ucsc/index.html#preliminaries",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nPoint-referenced and areal spatial units are (closed and bounded) sets.\nWe need to generalize distance between points to distance between sets.\nIdeally, this distance should:\n\nTake into account the shape, size, and orientation of spatial sample units.\nBe “spatially interpretable”."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#distances-between-sets",
    "href": "slides/2024-ucsc/index.html#distances-between-sets",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Distances between sets",
    "text": "Distances between sets\n\nMetric space: \\((D, d)\\), where \\(D\\) is a spatial region of interest.\nDistance between a point and a set: \\(d(x, A) = \\inf_{a \\in A}\nd(x, a)\\), where \\(d(x, y)\\) is the distance between any two elements \\(x, y \\in\nD\\)\nDirected Hausdorff distance: \\[{\\vec h}(A, B) = \\sup_{a \\in A}\nd(a, B)\\]\nHausdorff distance: \\[h(A, B) = \\max \\left \\{ \\vec{h}(A, B),\n\\vec{h}(B, A) \\right \\}\\]\n\n\n\nSymmetric Hausdorff distance: the greater of the two directed Hausdorff distances.\nNote that if \\(A\\) and \\(B\\) are both singletons, then \\(h(A, B) = d(A, B)\\).\n\nMeric Properties: (1) Symmetry: \\(d(x, y) = d(y, x)\\); (2) Nonnegativeness: \\(d(x,\ny) \\geq 0\\) and \\(d(x, x) = 0\\); (3)Positiveness: \\(d(x, y) = 0 \\implies x = y\\); (4) Triangle inequality: \\(d(x, y) \\leq d(x, z) + d(z, y)\\)"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#hausdorff-distance-for-spatial-data-analysis",
    "href": "slides/2024-ucsc/index.html#hausdorff-distance-for-spatial-data-analysis",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Hausdorff Distance for Spatial Data Analysis",
    "text": "Hausdorff Distance for Spatial Data Analysis\n\nStudy region: In spatial statistics, \\(D\\) is tipically a closed and bounded subset of \\(\\mathbb{R}^2\\).\nIn this context, the Hausdorff distance is a metric (Sendov 2004).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetric on \\(D \\setminus \\varnothing\\)\nThe Hausdorff distance ability to account for spatial units’ shapes, sizes and orientation(Min et al. 2007) renders it an interesting tool to achieve our goals.\nMoreover, it can distinguish between overlapping, nested, and disjointed regions.\nIn the figure: (1) The dashed lines denote the Hausdorff distances; (2) The infimum distance between to sets is zero for the three cases; (3) Distance between centroids is the same for the first two figures."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#the-hgp",
    "href": "slides/2024-ucsc/index.html#the-hgp",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "The HGP",
    "text": "The HGP\n\nIndex set: \\(\\mathcal{B}(D)\\) represents the closed and bounded subsets of \\(D \\subset \\mathbb{R}^2\\).\n\\(Z(\\mathbf{s}) \\sim \\mathrm{HGP}\\{m(\\mathbf{s}), v(\\mathbf{s}), r(h)\\}\\), where \\(\\mathbf{s} \\in \\mathcal{B}(D)\\).\nMean function: \\(m(\\mathbf{s}) = \\mathbb{E}[Z(\\mathbf{s})]\\)\nCovariance function: \\(\\mathrm{Cov}(Z(\\mathbf{s}_1),\nZ(\\mathbf{s}_2)) = v(\\mathbf{s}_1) v(\\mathbf{s}_2) r(h(\\mathbf{s}_1,\n\\mathbf{s}_2))\\)\nSD function: \\(v(\\mathbf{s}) =\n\\sqrt{\\mathrm{Var}(Z(\\mathbf{s}))}\\)\nCorrelation function: \\(r(h) =\n\\mathrm{Cor}(Z(\\mathbf{s}_1), Z(\\mathbf{s}_2)),\\) where \\(h\\) denotes the Hausdorff distance between \\(\\mathbf{s}_1, \\mathbf{s}_2 \\in\n\\mathcal{B}(D)\\).\n\n\n\nIdeally, we want bounded, compact, and non-empty sets for the Hausdorff distance to be a metric..\nIn \\(\\mathbb{R}^2\\), a compact subset is bounded.\nempty is a subset of any set -&gt; it is bounded bc a subset of a bounded set is bounded itself.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nThe SD function allows the HGP to accommodate both homoscedastic and heteroscedastic scenarios."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#the-vmathbfs-function",
    "href": "slides/2024-ucsc/index.html#the-vmathbfs-function",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "The \\(v(\\mathbf{s})\\) function",
    "text": "The \\(v(\\mathbf{s})\\) function\nWe may defined: \\[v(\\mathbf{s}) = \\exp \\{ \\alpha_0 + \\alpha_1 w(\\mathbf{s})\n\\},\\] where \\(w(\\mathbf{s})\\) is a covariate available for any \\(\\mathbf{s} \\in\n\\mathcal{B}(D)\\).\n\nUseful special cases:\n\nHomoscedastic: \\(w(\\mathbf{s}) = 0\\) (consequence, \\(\\sigma =\n\\exp \\{ \\alpha_0 \\}\\))\nData Fusion: \\(w(\\mathbf{s}) =\n\\mathbb{1}(\\mathcal{A}(\\mathbf{s}) &gt; 0)\\).\nArea dependent: \\(w(\\mathbf{s}) = \\mathcal{A}(\\mathbf{s})\\)\n\nAlthough flexible, one has to be careful when choosing this function to ensure the process validity (Palacios and Steel 2006).\n\n\n\nfor data fusion: \\(\\sigma_a = \\exp \\{ \\alpha_0 + \\alpha_1 \\}\\)."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#ensuring-the-process-validity",
    "href": "slides/2024-ucsc/index.html#ensuring-the-process-validity",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Ensuring the process’ validity",
    "text": "Ensuring the process’ validity\nFor a valid process, its correlation function must satisfy the following properties:\n\nDiminish with increasing distance: \\(\\lim_{h \\to \\infty}r(h) = 0\\).\nBounded from above by 1: \\(r(0) = 1\\).\nPositive-definiteness: yields positive-definite correlation matrices for all its finite-dimensional marginal distributions.\nUnfortunately, functions that are guaranteed to be positive-definite on \\((\\mathbb{R}^2, \\lVert \\cdot\n\\rVert_2)\\) are not necessarily positive definite on other metric spaces (Li et al. 2023)."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#the-powered-exponential-correlation-pec-function",
    "href": "slides/2024-ucsc/index.html#the-powered-exponential-correlation-pec-function",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "The Powered Exponential Correlation (PEC) Function",
    "text": "The Powered Exponential Correlation (PEC) Function\n\nPEC function: \\[r(h; \\phi, \\nu) = \\exp\\left \\{ -\n\\frac{h^{\\nu}}{\\phi^{\\nu}}\\right \\},\\] where \\(\\nu\\) is a smoothness parameter and \\(\\phi\\) governs the range of the spatial dependence.\n\n\nParametrization: We reparametrize this function with \\(\\rho =\n{\\log(10)}^{1 / \\nu} \\phi\\).\nInterpretation: \\(\\rho\\) is the distance at which the spatial correlation reduces to \\(0.10\\).\n\n\n\nexplain \\(\\rho\\)."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#visualizing-the-pec-function",
    "href": "slides/2024-ucsc/index.html#visualizing-the-pec-function",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Visualizing the PEC function",
    "text": "Visualizing the PEC function"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#theoretical-foundation-positive-definiteness-of-the-pec",
    "href": "slides/2024-ucsc/index.html#theoretical-foundation-positive-definiteness-of-the-pec",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Theoretical Foundation: Positive Definiteness of the PEC",
    "text": "Theoretical Foundation: Positive Definiteness of the PEC\n\n\n\nProposition\n\n\nLet \\(h = h(\\mathbf{s}, \\mathbf{s}')\\) be the Hausdorff distance between two spatial units, denoted \\(\\mathbf{s}, \\mathbf{s}' \\in \\mathcal{B}(D)\\), where \\(D\n\\subset \\mathbb{R}^2\\). The powered exponential correlation function \\(\\exp \\{ -\nh^{\\nu} / \\phi^{\\nu} \\}\\) is positive definite for \\(\\nu \\in (1/2, 1)\\).\n\n\n\n\nThe theorem above guarantees the validity of the HGP equipped with a PEC function with \\(\\nu \\in\n(1/2, 1)\\).\nThe proof is based on embedding the Hausdorff distance into a high-dimensional \\(L_1\\) normed Euclidean space, and using the fact that the exponential correlation function is positive definite on this space."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#empirical-assessment-of-positive-definiteness",
    "href": "slides/2024-ucsc/index.html#empirical-assessment-of-positive-definiteness",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Empirical Assessment of Positive Definiteness",
    "text": "Empirical Assessment of Positive Definiteness\n\n\n\nthe graph displays the smallest eigenvalue of the correlation matrix induced by \\(\\rho\\) (x-axis) and \\(\\nu\\) (y-axis).\nThese matrices are based on the two spatial applications we will discuss in the next chapter.\nThe transparent regions indicate the regions of the parametric space where rho is smaller than 0."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#hgp-recap",
    "href": "slides/2024-ucsc/index.html#hgp-recap",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "HGP Recap",
    "text": "HGP Recap\n\nFlexibility: A process that handles point-referrenced, areal, and mixed spatial data by construction.\nHausdorff distance: Enables HGP’s correlation function to account for the shape, size, and orientation of spatial objects.\nValidity: Using a PEC function ensures the HGP is a valid process.\n\n\n\n\n\n\nflowchart LR\n    A(Flexible index set) ==&gt; B(GP)\n    B ==&gt; E(((HGP)))\n    C(Hausdorff distance) ==&gt; D(PEC)\n    D ==&gt; E"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#spatial-glmm",
    "href": "slides/2024-ucsc/index.html#spatial-glmm",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Spatial GLMM",
    "text": "Spatial GLMM\nA generalized linear mixed effects model (GLMM) can be written as \\[\\begin{aligned}\n& Y(\\mathbf{s}_i) \\mid \\mathbf{x}_i, Z(\\mathbf{s}_i) \\overset{{\\rm ind}}{\\sim}\n  f(\\cdot \\mid \\mu_i, \\boldsymbol{\\gamma}) \\\\\n& g(\\mu_i) = \\mathbf{x}_i \\boldsymbol{\\beta} +\n  Z(\\mathbf{s}_i).\n\\end{aligned}\\]\n\nProbability distribution: \\(f(\\cdot)\\)\nConditional mean: \\(\\mu_i = \\mathbb{E}[Y(\\mathbf{s}_i) \\mid\n\\mathbf{x}_i, Z(\\mathbf{s}_i)]\\)\nLink function: \\(g(\\cdot)\\)\nModel parameters: \\(\\boldsymbol{\\theta} =\n{\\{\\boldsymbol{\\beta}^\\top, \\boldsymbol{\\sigma}^\\top,\n\\boldsymbol{\\delta}^\\top, \\boldsymbol{\\gamma}^\\top \\}}^\\top\\)\nJoint density: \\(p(\\mathbf{y} \\mid \\mathbf{z}, \\boldsymbol{\\theta}) =\n\\prod_{i = 1}^n f(y(\\mathbf{s}_i) \\mid \\mu_i, \\boldsymbol{\\gamma})\\)\n\n\n\nRealizations of random variables are represented by lowercase letters.\nModel paramers are greek letters.\nUnder a frequentist perspective, we consider the random effects to follow an HGP.\nFor Bayesian inference, we use the HGP as a prior for the random effects.\nResponse variable \\(Y\\) at a spatial unit \\(s\\) is modeled with an appropriate distribution (e.g., Poisson, Bernoulli).\nCovariates (\\(X\\)) and spatial random effects (\\(Z\\)) explain variation in the conditional mean (\\(\\mu\\)).\nThe HGP defines the spatial random effects (\\(Z\\)), capturing spatial correlation with the Hausdorff distance and a correlation function."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#priors",
    "href": "slides/2024-ucsc/index.html#priors",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Priors",
    "text": "Priors\n\nIndependent normal priors for the regression coefficients: \\(\\boldsymbol{\\beta} \\sim \\mathcal{N}(\\mathbf{0}, 10 \\mathbf{I})\\)\nHGP prior for the latent random effects: \\(\\mathbf{Z} \\sim\n\\mathrm{HGP}\\{0, v(\\cdot), r(\\cdot) \\}\\)\nExponential prior for the spatial dependence parameter: \\(\\rho\n\\sim \\mathrm{Exp}(a_\\rho)\\), where \\(a_{\\rho} = - \\log(p_{\\rho}) / \\rho_0\\).\n\n\\(a_\\rho\\) is chosen such that \\(\\mathbb{P}(\\rho \\geq \\rho_0) = p_\\rho\\).\n\nHomoscedastic variance: \\(v(\\mathbf{s}) =\n\\sqrt{\\mathrm{Var}(Z(\\mathbf{s}))} = \\sigma \\sim t_{+}(3)\\)\nHeteroscedastic HGP: \\(\\alpha \\sim \\mathcal{N}(\\mathbf{0},\n\\mathbf{I})\\), where \\(v(\\mathbf{s}) = \\exp \\{ \\alpha_0 + \\sum_i \\alpha_i w_i(\\mathbf{s}) \\}\\).\n\n\n\nFor \\(\\rho\\), the prior is inspired in penalized complexity priors. A conservative, but reasonable, choice for its hyperparameter is setting \\(a_\\rho\\) such that \\(\\rho_0\\) is a surprisingly low practical range and \\(p_rho\\) is a small probability (i.e., around .01)"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#bayesian-inference-model-assessment",
    "href": "slides/2024-ucsc/index.html#bayesian-inference-model-assessment",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Bayesian Inference & Model Assessment",
    "text": "Bayesian Inference & Model Assessment\n\nPosterior: \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y},\n\\mathbf{z}) \\propto p(\\mathbf{y} \\mid \\mathbf{z}, \\boldsymbol{\\theta})\np(\\mathbf{z} \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta})\\)\nMCMC sampler: No-U-Turn (Homan and Gelman 2014).\nConvergence assessment: traceplots and split-\\({\\hat{R}}\\) (Vehtari et al. 2021).\nGoodness-of-fit criteria: LOOIC (lower values indicate better fit)\nPosterior predictive distributions: \\(p(\\mathbf{y}^{\\ast} \\mid\n\\mathbf{y})\\)\nPredictions assessment: Interval Score (IS) and RMSP (lower values indicate better fit)\n\n\n\nPoint and interval estimates: median and percentiles (\\(0.025\\) and \\(0.975\\)) of the marginal MCMC samples.\nParameters initialized by random sampling from their priors.\nRandom effects initialized from a standard normal distribution.\n\\(a_\\rho\\) is chosen so that: \\(\\mathbb{P}(\\rho &gt; U) = p_\\rho\\). In particular, \\(a_\\rho = - \\log(p_\\rho) / \\rho_0\\).\n\\(\\nu\\) hard to be estimated.\n\nPredictions:\n\nuse the properties of GP and multivariate Normal distribution to obtain the closed-form distribution of the vector of spatial random effects \\(\\mathbf{Z}^\\ast\\) (Diggle et al. 1998);\nsample \\(\\mathbf{z}^\\ast_{(b)}\\) from the distribution derived in the previous step;\nsample \\(\\mathbf{y}^{\\ast}_{(b)}\\) from \\(p(\\mathbf{y}^{\\ast} \\mid \\boldsymbol{\\theta}_{(b)},\n\\mathbf{z}^{\\ast}_{(b)})\\), where \\(\\boldsymbol{\\theta}_{(b)}\\) is the \\(b\\)-th MCMC sample of \\(\\boldsymbol{\\theta}\\)."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#bayesian-modeling-recap",
    "href": "slides/2024-ucsc/index.html#bayesian-modeling-recap",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Bayesian Modeling Recap",
    "text": "Bayesian Modeling Recap\n\nHGP as a prior for the random effects disribution in a GLMM.\nBayesian inference through MCMC.\nUncertainty quantification of predictions through the posterior predictive distributions.\n\n\nDAGAR priors: \\[\n\\begin{aligned}\n  \\pi(\\beta_0) & \\propto 1 \\\\\n  \\beta_1 & \\sim N(0, 1000^2) \\\\\n  \\tau & \\sim Gamma(2, 1) \\\\\n  \\psi & \\sim U(0, 1).\n\\end{aligned}\n\\] - Precision matrix is defined based on the order of the observations and adjacency matrix (and the two parameters)"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#respiratory-disease-hospitalization-in-glasgow",
    "href": "slides/2024-ucsc/index.html#respiratory-disease-hospitalization-in-glasgow",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Respiratory Disease Hospitalization in Glasgow",
    "text": "Respiratory Disease Hospitalization in Glasgow\n\\[\\begin{aligned}\n& (Y(\\mathbf{s}_i) \\mid x_i, z(\\mathbf{s}_i)) \\sim \\text{Poisson}(E_i \\mu_i) \\\\\n& \\log(\\mu_i) = \\beta_0 + x_i \\beta_1 + z(\\mathbf{s}_i)\n\\end{aligned}\\]\n\nSample units: 134 intermediate zones (IZ), where the \\(i\\)-th IZ is denoted \\(\\mathbf{s}_i\\).\nNumber of hospitalizations: \\(\\mathbf{Y} = {(Y(\\mathbf{s}_1),\n\\ldots, Y(\\mathbf{s}_n))}^\\top\\).\nExpected number of hospitalizations based on the national age- and sex-standardized rates: \\(E_i\\).\nPercentage of people classified as income deprived: \\(x_i\\).\n\n\n\nData from the north portion of the river Clyde in the Great Glasgow and Clyde health board in Scotland.\nAssumption: Conditional on \\(\\mathbf{Z}\\), \\(\\mathbf{Y}\\) are mutually independent.\nExplain goals of the analysis–estimate risks adjusted for income deprivation, compare methods.\n\\(\\mu_i\\) is the expected SIR at region \\(i\\).\nOutline the modeling choices (HGP, DAGAR, BYM), briefly mention priors."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#disease-mapping-estimation-gof",
    "href": "slides/2024-ucsc/index.html#disease-mapping-estimation-gof",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Disease Mapping: Estimation & GOF",
    "text": "Disease Mapping: Estimation & GOF\n\n\n\n\n\n\n\n\n\n\nHGP\nDAGAR\n\n\n\n\n\\(\\beta_0\\)\n-0.21 (-0.268, -0.139)\n-0.26 (-0.450, -0.137)\n\n\n\\(\\beta_1\\)\n0.33 (0.284, 0.368)\n0.31 (0.258, 0.370)\n\n\n\\(\\sigma\\)\n0.19 (0.155, 0.234)\n0.30 (0.218, 0.484)\n\n\n\\(\\rho\\)\n2.25 (0.159, 6.948)\n\n\n\n\\(\\psi\\)\n\n0.43 (0.069, 0.827)\n\n\n\n\n\n\n\n\n\n\n\n\nLOOIC\n1081.0\n1081.9\n\n\n\n\n\n\nmedian (95% CI)\nsimilar estimates for covariate\nHGP indicates weak spatial correlation\nDAGAR and BYM spatial dependence are not helpful as they indicate the spatial correlation goes from weak to strong (according to the CI)"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#disease-mapping-spatial-dependence",
    "href": "slides/2024-ucsc/index.html#disease-mapping-spatial-dependence",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Disease Mapping: Spatial Dependence",
    "text": "Disease Mapping: Spatial Dependence\n\n\n\nHGP provides more insight into spatial dependence\nWe could also plot the correlation function itself"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#disease-mapping-adjusted-sir",
    "href": "slides/2024-ucsc/index.html#disease-mapping-adjusted-sir",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Disease Mapping: Adjusted SIR",
    "text": "Disease Mapping: Adjusted SIR\n\n\n\nFitted values are similar among the three models\nSome regions with very low risks are shrunk toward a “regional mean”"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#air-pollution-in-ventura-and-los-angeles",
    "href": "slides/2024-ucsc/index.html#air-pollution-in-ventura-and-los-angeles",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Air Pollution in Ventura and Los Angeles",
    "text": "Air Pollution in Ventura and Los Angeles\n\n\n\n\\[(Y(\\mathbf{s}_i) \\mid z(\\mathbf{s}_i)) \\sim\n  \\mathcal{N}(\\beta_0 + z(\\mathbf{s}_i), \\tau^2)\\]\n\nPM2.5: \\(\\mathbf{Y} = {(Y(\\mathbf{s}_1), \\ldots,\nY(\\mathbf{s}_n))}^\\top\\).\nPoint-referrenced data from 19 measurement stations available daily from 1999 to date;\nSatellite-derived estimates (2010–2012) at 184 areal units.\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngoals: (1); estimate model parameters using both sources. (2) use satellite data to help with interpolation.\nsquare areas (average size \\(\\approx\\) 101.95 km2)\ndata fusion challenges\nadaptability of the hgp to different problems.\nPm25 scale is micrometre per cubic meter: one one-millionth of a meter.\nconditional on \\(z\\) the \\(y\\)s are mutually independent.\nPriors on random effects: AGP1 and 2; heteroscedastic HGP with different variances for areal and point-referrenced data."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#agp-approximation",
    "href": "slides/2024-ucsc/index.html#agp-approximation",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "AGP Approximation",
    "text": "AGP Approximation"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#air-pollution-estimation-and-prediction-assessment",
    "href": "slides/2024-ucsc/index.html#air-pollution-estimation-and-prediction-assessment",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Air Pollution: Estimation and Prediction Assessment",
    "text": "Air Pollution: Estimation and Prediction Assessment\n\n\n\n\n\n\n\n\n\n\n\nHGP\n\\(\\rm AGP_1\\)\n\\(\\rm AGP_2\\)\n\n\n\n\n\\(\\beta\\)\n5.61 (4.69, 6.45)\n6.22 (2.16, 10.10)\n6.19 (5.88, 6.48)\n\n\n\\(\\rho\\)\n13.83 (7.82, 23.61)\n13.16 (5.14, 30.24)\n0.63 (0.46, 0.83)\n\n\n\\(\\tau\\)\n0.18 (0.07, 0.31)\n1.39 (1.24, 1.56)\n0.54 (0.39, 0.72)\n\n\n\\(\\sigma\\)\n3.85 (2.92, 5.18)\n1.70 (0.96, 2.91)\n2.41 (2.024, 2.84)\n\n\n\\(\\sigma_a\\)\n1.24 (1.04, 1.51)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRMSP\n1.05\n1.45\n1.64\n\n\nWidth\n3.57\n2.53\n9.67\n\n\nCPP\n95.5\n78.6\n95.5\n\n\nIS\n4.80\n15.11\n13.65\n\n\n\n\n\n\n\\(\\rho\\) rescaled to 100s of km.\nstaggering difference in estimates of the same model with different meshes."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#air-pollution-change-of-support",
    "href": "slides/2024-ucsc/index.html#air-pollution-change-of-support",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Air Pollution: Change-of-Support",
    "text": "Air Pollution: Change-of-Support\n\n\n\nFigure confirms what we learned from 10-fold CV and simulation studies.\nHGP allows to use data from different sources seamlessly\nNo dependence on meshes/grids\nApparently, a parsimonious compromise between the two meshes.\nOnce again, the AGP seems highly dependend on the mesh and this is not highlighted in the literature."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#applications-key-findings",
    "href": "slides/2024-ucsc/index.html#applications-key-findings",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Applications: key findings",
    "text": "Applications: key findings\n\nThe proposed method consistently demonstrated performance comparable to specialized models tailored for areal and fused data.\nUnlike traditional areal models, the HGP’s marginal variances are independent of the number of neighbors.\nThe HGP model simplifies data fusion by bypassing the need to define arbitrary grids for numerical integral evaluation, eliminating this step each time the joint probability distribution of the data and parameters is calculated.\nAcross both applications, the HGP provides an interpretable spatial dependence parameter and a spatial correlation function."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#highlights",
    "href": "slides/2024-ucsc/index.html#highlights",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Highlights",
    "text": "Highlights\nThe HGP has proven to be a powerful model that offers:\n\nVersatility: accomodates diverse spatial data types.\nPerformance: competitive against models designed for specific spatial data types.\nReliable predictions: prediction intervals with near nominal frequentist coverage.\nOur conclusions are further supported by a comprehensive simulation study, detailed in our available preprint.\n\n\nKey Takeaway: The HGP’s versatility and performance make it a valuable tool in your spatial analysis toolkit."
  },
  {
    "objectID": "slides/2024-ucsc/index.html#future-work-and-limitations",
    "href": "slides/2024-ucsc/index.html#future-work-and-limitations",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Future work and Limitations",
    "text": "Future work and Limitations\n\nExtensions:\n\nnon-Euclidean spaces\nBig data\n\nLimitations:\n\nBig “n” problem inherited from geostatistics\nUnclear how to incorporate anisotropy\nDifficulties in obtaining spectral densities for correlation functions"
  },
  {
    "objectID": "slides/2024-ucsc/index.html#references",
    "href": "slides/2024-ucsc/index.html#references",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "",
    "text": "References\n\n\nBesag, J. (1974), “Spatial interaction and the statistical analysis of lattice systems,” Journal of the Royal Statistical Society. Series B (Methodological), JSTOR, 192–236.\n\n\nBesag, J., York, J., and Mollié, A. (1991), “Bayesian image restoration, with two applications in spatial statistics,” Annals of the Institute of Statistical Mathematics, 43, 1–20.\n\n\nCressie, N. (1993), Statistics for spatial data, Wiley series in probability and statistics, Wiley.\n\n\nDatta, A., Banerjee, S., Hodges, J. S., and Gao, L. (2019), “Spatial disease mapping using directed acyclic graph auto-regressive (DAGAR) models,” Bayesian analysis, NIH Public Access, 14, 1221.\n\n\nDiggle, P. J., Tawn, J. A., and Moyeed, R. A. (1998), “Model-based geostatistics,” Journal of the Royal Statistical Society Series C: Applied Statistics, Oxford University Press, 47, 299–350.\n\n\nHoman, M. D., and Gelman, A. (2014), “The No-U-turn sampler: Adaptively setting path lengths in hamiltonian Monte Carlo,” Journal of Machine Learning Research, JMLR.org, 15, 1593–1623.\n\n\nLi, D., Tang, W., and Banerjee, S. (2023), “Inference for Gaussian processes with Matérn covariogram on compact Riemannian manifolds,” Journal of Machine Learning Research, 24, 1–26.\n\n\nMin, D., Zhilin, L., and Xiaoyong, C. (2007), “Extended Hausdorff distance for spatial objects in GIS,” International Journal of Geographical Information Science, Taylor & Francis, 21, 459–475.\n\n\nMoraga, P., Cramb, S. M., Mengersen, K. L., and Pagano, M. (2017), “A geostatistical model for combined analysis of point-level and area-level data using INLA and SPDE,” Spatial Statistics, Elsevier, 21, 27–41.\n\n\nPalacios, M. B., and Steel, M. F. J. (2006), “Non-Gaussian Bayesian geostatistical modeling,” Journal of the American Statistical Association, Taylor & Francis, 101, 604–618.\n\n\nSendov, B. (2004), “Hausdorff distance and image processing,” Russian Mathematical Surveys, IOP Publishing, 59, 319. https://doi.org/10.1070/RM2004v059n02ABEH000721.\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., and Bürkner, P.-C. (2021), “Rank-normalization, folding, and localization: An improved \\(\\hat{R}\\) for assessing convergence of MCMC (with discussion),” Bayesian Analysis, International Society for Bayesian Analysis, 16, 667–718.\n\n\nZheng, X., Kottas, A., and Sansó, B. (2023), “Nearest-neighbor mixture models for non-gaussian spatial processes,” Bayesian Analysis, International Society for Bayesian Analysis, 18, 1191–1222."
  },
  {
    "objectID": "slides/2025-frcheck/index.html#drmr-package",
    "href": "slides/2025-frcheck/index.html#drmr-package",
    "title": "FinRisk check-in",
    "section": "drmr package",
    "text": "drmr package\n\nDRMs explicitly incorporate demographic processes that drive range dynamics (Pagel and Schurr 2012). They allow for linking environmental drivers directly to specific processes and have the potential for more robust forecasting under novel conditions.\ndrmr goal: Bridge the gap between DRM potential and practical application.\nCheck out online."
  },
  {
    "objectID": "slides/2025-frcheck/index.html#spoiler-comparison-to-an-sdm",
    "href": "slides/2025-frcheck/index.html#spoiler-comparison-to-an-sdm",
    "title": "FinRisk check-in",
    "section": "Spoiler: Comparison to an SDM",
    "text": "Spoiler: Comparison to an SDM"
  },
  {
    "objectID": "slides/2025-frcheck/index.html#more-spoilers",
    "href": "slides/2025-frcheck/index.html#more-spoilers",
    "title": "FinRisk check-in",
    "section": "More spoilers",
    "text": "More spoilers\n\n\n\nSpecies\nModel\nRMSE\nIS (80%)\n\n\n\n\nSummer flounder\nDRM\n9.49\n7.83\n\n\n\nSDM\n13.20\n11.80\n\n\nRed-bellied woodpecker\nDRM\n4.49\n8.68\n\n\n\nSDM\n6.86\n6.20"
  },
  {
    "objectID": "slides/2025-frcheck/index.html#what-about-finrisk",
    "href": "slides/2025-frcheck/index.html#what-about-finrisk",
    "title": "FinRisk check-in",
    "section": "What about FinRisk?",
    "text": "What about FinRisk?\n\nKey Environmental Drivers: NEA Mackerel distribution is primarily driven by SST, prey availability, and stock size. Mackerel density peaks around \\(8.5\\) to \\(12^\\circ\\) (Ono et al. 2024) with no ocurrences registered when temperature is below \\(4.8^\\circ\\) (Olafsdottir et al. 2019)\nData Availability: Data available from various surveys (Egg Survey for spawning/SSB; Bottom Trawl for juveniles). No single survey offers complete coverage of all life stages or the entire distribution annually.\nIESSNS: The International Ecosystem Summer Survey in the Nordic Seas (IESSNS) is likely the most appropriate for adult summer feeding distribution, providing annual, age-disaggregated abundance indices and tracking distribution.\n\n\nHere is a summary of the text in three bullet points:\n\nEnvironmental Drivers: Prey availability (such as mesozooplankton) and stock size (SSB) are also key drivers, particularly affecting feeding locations and distribution, with temperature often being the most critical predictor, especially for younger fish and in northern areas.\nData Availability: Information on NEA Mackerel is gathered from various sources, including commercial fishery sampling, tagging studies, and several internationally coordinated surveys. The triennial Mackerel and Horse Mackerel Egg Survey is crucial for understanding spawning distribution and estimating spawning stock biomass (SSB). Juvenile (age-0) mackerel distribution is estimated using data from multiple bottom trawl surveys. However, no single survey provides comprehensive data covering all life stages, the entire annual cycle, and the full spatial distribution of the stock.\nIESSNS as Most Appropriate Data Source: Given its annual coverage since 2010, focus on the summer feeding season for adult (age 3+) mackerel across the Nordic Seas, and its ability to provide reliable age-disaggregated abundance indices while tracking the stock’s variable distribution, the International Ecosystem Summer Survey in the Nordic Seas (IESSNS) is likely the most appropriate single data source for understanding the dynamics of this critical life stage and region."
  },
  {
    "objectID": "slides/2025-frcheck/index.html#more-about-data-availability",
    "href": "slides/2025-frcheck/index.html#more-about-data-availability",
    "title": "FinRisk check-in",
    "section": "More about data availability",
    "text": "More about data availability\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurvey\nDistribution\nStart\nAge structure\n\n\n\n\nIESSNS\nSummer feeding\n2010\nAge and size composition (Age 3+)\n\n\nBTS\nOverwinter\n1965\nAge-0 abundance index\n\n\nEgg Survey\nSpawning\n1992\nNo age structure\n\n\n\n\n\n\nBTS\n\nCan be used to estimate an index of recruitment\nRecruitment index would be spatially invariant\nEnvironmental determinants of recruitment?\n\nTriennial Mackerel and Horse Mackerel Egg Survey\n\nCan be used to estimate SSB\nUseful for spatially invariant S-R relationship"
  },
  {
    "objectID": "slides/2025-frcheck/index.html#whats-next",
    "href": "slides/2025-frcheck/index.html#whats-next",
    "title": "FinRisk check-in",
    "section": "What’s next?",
    "text": "What’s next?\n\nPreliminary results for FinRisk September meeting\nTaylor the package code to the NEA species\nSimulation based inference: Neural Bayes Estimators (Sainsbury-Dale et al. 2024)\nCoordinate how (and what) the results would be more useful for the translational tools and the financial risk analyses"
  },
  {
    "objectID": "slides/2025-frcheck/index.html#references",
    "href": "slides/2025-frcheck/index.html#references",
    "title": "FinRisk check-in",
    "section": "",
    "text": "References\n\n\nOlafsdottir, A. H., Utne, K. R., Jacobsen, J. A., Jansen, T., Óskarsson, GuJ., Nøttestad, L., Elvarsson, B., Broms, C., and Slotte, A. (2019), “Geographical expansion of Northeast Atlantic mackerel (Scomber scombrus) in the Nordic Seas from 2007 to 2016 was primarily driven by stock size and constrained by low temperatures,” Deep Sea Research Part II: Topical Studies in Oceanography, 159, 152–168. https://doi.org/10.1016/j.dsr2.2018.05.023.\n\n\nOno, K., Katara, I., Eliasen, S. K., Broms, C., Campbell, A., Santos Schmidt, T. C. dos, Egan, A., Hølleland, S. N., Jacobsen, J. A., Jansen, T., Mackinson, S., Mousing, E. A., Nash, R. D. M., Nikolioudakis, N., Nnanatu, C., Nøttestad, L., Singh, W., Slotte, A., Wieland, K., and Olafsdottir, A. H. (2024), “Effect of environmental drivers on the spatiotemporal distribution of mackerel at age in the Nordic Seas during 2010-20,” ICES Journal of Marine Science, 81, 1282–1294. https://doi.org/10.1093/icesjms/fsae087.\n\n\nPagel, J., and Schurr, F. M. (2012), “Forecasting species ranges by statistical estimation of ecological niches and spatial population dynamics,” Global Ecology and Biogeography, 21, 293–304. https://doi.org/https://doi.org/10.1111/j.1466-8238.2011.00663.x.\n\n\nSainsbury-Dale, M., Zammit-Mangion, A., and and, R. H. (2024), “Likelihood-free parameter estimation with neural bayes estimators,” The American Statistician, ASA Website, 78, 1–14. https://doi.org/10.1080/00031305.2023.2249522."
  },
  {
    "objectID": "slides/2025-git/index.html#what-is-version-control-and-why-should-i-care",
    "href": "slides/2025-git/index.html#what-is-version-control-and-why-should-i-care",
    "title": "Git & friends",
    "section": "What is version control and why should I care?",
    "text": "What is version control and why should I care?\n\nImagine you’re writing a document. Instead of just saving over the same file every time, version control keeps the file’s history, like snapshots of your work.\n\n\nDoes anyone relate to this?"
  },
  {
    "objectID": "slides/2025-git/index.html#why-is-it-useful",
    "href": "slides/2025-git/index.html#why-is-it-useful",
    "title": "Git & friends",
    "section": "Why is it useful?",
    "text": "Why is it useful?\n\nWhy is this useful?\n\nCollaboration: Multiple people can work on the same project without overwriting each other’s changes.\nReverting: You can easily go back to a previous version if you make a mistake or want to try something different.\nTracking History: You can see who made what changes and when."
  },
  {
    "objectID": "slides/2025-git/index.html#what-is-git",
    "href": "slides/2025-git/index.html#what-is-git",
    "title": "Git & friends",
    "section": "What is Git?",
    "text": "What is Git?\n\nGit is a distributed version control system. This means that everyone working on a project has a complete copy of the project’s history on their own computer.\nIt was created by Linus Torvalds (the creator of Linux) in 2005 because he needed a better way to manage the Linux kernel source code.\nThe distributed nature of Git is a key benefit. If one person’s computer crashes, the project history is safe because everyone else has a copy."
  },
  {
    "objectID": "slides/2025-git/index.html#git-vs-github-and-others",
    "href": "slides/2025-git/index.html#git-vs-github-and-others",
    "title": "Git & friends",
    "section": "Git vs GitHub and others",
    "text": "Git vs GitHub and others\nThis is important: Git and GitHub are not the same thing.\n\nGit: The tool itself. It’s the software you install on your computer to track changes to your files.\nGitHub: A website that hosts Git repositories. It’s a platform built around Git. Think of it like a place to store and share your Git projects.\nGitHub is very popular, but it’s not the only option. Other platforms include:\n\nGitLab\nBitbucket"
  },
  {
    "objectID": "slides/2025-git/index.html#downloading-and-installing",
    "href": "slides/2025-git/index.html#downloading-and-installing",
    "title": "Git & friends",
    "section": "Downloading and installing",
    "text": "Downloading and installing\n\nYou can download Git here\nOn MacOS, one can use brew or port to install it\nOn Linux it depends on the package manager being used\nOn Windows, this link provides git and a “terminal emulator” called Git BASH."
  },
  {
    "objectID": "slides/2025-git/index.html#why-using-the-terminal",
    "href": "slides/2025-git/index.html#why-using-the-terminal",
    "title": "Git & friends",
    "section": "Why using the terminal?",
    "text": "Why using the terminal?\n\nGit’s Best Friend: Git relies heavily on the command line (terminal).\nPower and Flexibility: The terminal offers direct control over your computer, enabling complex tasks and automation not easily achievable through graphical interfaces.\nHigh-Performance Computing: A must-have for HPC.\nNot as Scary as it Looks: The terminal is simply a text-based way to communicate with your computer. It’s a skill worth learning!"
  },
  {
    "objectID": "slides/2025-git/index.html#basics",
    "href": "slides/2025-git/index.html#basics",
    "title": "Git & friends",
    "section": "Basics",
    "text": "Basics\n\npwd (print working directory): Tells you where you are in the file system.\nls (list files): Shows you the files and folders in your current directory.\ncd (change directory): Moves you to a different folder. For instance, cd .. goes up one level.\nmkdir (make directory): Creates a new folder.\ntouch (create a file): Creates an empty file (often used for quick testing)."
  },
  {
    "objectID": "slides/2025-git/index.html#initializing-a-repository",
    "href": "slides/2025-git/index.html#initializing-a-repository",
    "title": "Git & friends",
    "section": "Initializing a repository",
    "text": "Initializing a repository\n\nA repository (often shortened to repo) is a directory/folder plus a hidden .git folder, which stores all the version history.\nThere are different ways to start a Git repository.\n\nWe can create or turn an existing directory/folder into a Git repository.\nTo turn a folder into a git repository, open your terminal, navigate to the desired folder (using cd) and then type:\ngit init\nWe can clone a git repository.\ngit clone &lt;repo-url&gt;"
  },
  {
    "objectID": "slides/2025-git/index.html#staging-changes",
    "href": "slides/2025-git/index.html#staging-changes",
    "title": "Git & friends",
    "section": "Staging changes",
    "text": "Staging changes\n\nBefore you can save a version (called a commit), you need to tell Git which changes you want to include. This is called staging\n\ngit add &lt;file&gt;  # e.g., git add my_document.txt\n\nIf we replace &lt;file&gt; by ., then everything that was changed will be staged.\nTo see what’s been staged, use:\n\ngit status"
  },
  {
    "objectID": "slides/2025-git/index.html#committing-changes-viewing-history",
    "href": "slides/2025-git/index.html#committing-changes-viewing-history",
    "title": "Git & friends",
    "section": "Committing changes & viewing history",
    "text": "Committing changes & viewing history\n\nA commit saves your staged changes.\n\ngit commit -m \"Descriptive message\"\n\nThe -m flag lets you pair the staged changes with a message describing the changes you made.\nGood commit messages are essential! They help you and others understand the history of the project.\nTo see the history of commits (the commit messages, author, and date of each commit), use:\n\ngit log"
  },
  {
    "objectID": "slides/2025-git/index.html#the-.gitignore-file",
    "href": "slides/2025-git/index.html#the-.gitignore-file",
    "title": "Git & friends",
    "section": "The .gitignore file",
    "text": "The .gitignore file\n\nThe .gitignore file is text file that tells Git which files and directories to ignore. This prevents them from being accidentally added to your repository and keeps your commit history clean.\nExclude unnecessary files: Avoid committing temporary files, log files, or system-specific files that clutter your repository.\nProtect sensitive data: Prevent accidentally committing passwords, API keys, or other confidential information.\nExample .gitignore:\n\n.DS_Store      # macOS file\n*.tmp          # Temporary files\nconfig.ini     # Sensitive configuration\nmy_secret_key  # Never commit secrets!"
  },
  {
    "objectID": "slides/2025-git/index.html#pushing-pulling",
    "href": "slides/2025-git/index.html#pushing-pulling",
    "title": "Git & friends",
    "section": "Pushing & pulling",
    "text": "Pushing & pulling\n\nPushing: Uploading your changes to a remote repository (like on GitHub). After a commit, to upload our changes to the remote repository, we run:\ngit push\nPulling: Downloading changes from a remote repository to your local computer.\ngit pull\nBest practice: Run git pull before starting to edit a file to avoid conflicts."
  },
  {
    "objectID": "slides/2025-git/index.html#there-is-much-more-out-there",
    "href": "slides/2025-git/index.html#there-is-much-more-out-there",
    "title": "Git & friends",
    "section": "There is much more out there",
    "text": "There is much more out there\n\nBranches\nPull requests\nMerging"
  },
  {
    "objectID": "slides/2025-git/index.html#live-example",
    "href": "slides/2025-git/index.html#live-example",
    "title": "Git & friends",
    "section": "Live example",
    "text": "Live example"
  },
  {
    "objectID": "slides/2025-git/index.html#recap",
    "href": "slides/2025-git/index.html#recap",
    "title": "Git & friends",
    "section": "Recap",
    "text": "Recap\n\nVersion control helps you track changes to your files.\nGit is a powerful, distributed version control system.\nGitHub is a platform for hosting Git repositories.\nBasic commands: init, add, commit, log, clone."
  },
  {
    "objectID": "slides/2025-git/index.html#resources",
    "href": "slides/2025-git/index.html#resources",
    "title": "Git & friends",
    "section": "Resources",
    "text": "Resources\n\nOfficial Git documentation\nHappy Git and GitHub for the useR\nGit practice: more advanced exercises"
  },
  {
    "objectID": "slides/2025-git/index.html#next-steps",
    "href": "slides/2025-git/index.html#next-steps",
    "title": "Git & friends",
    "section": "Next steps",
    "text": "Next steps\n\nExperiment with Git! Create a simple project and try out the basic commands.\nPractice is key! The more you use Git, the more comfortable you’ll become."
  },
  {
    "objectID": "slides/2025-git/index.html#references",
    "href": "slides/2025-git/index.html#references",
    "title": "Git & friends",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#spatial-statistics",
    "href": "slides/2025-ucsf/index.html#spatial-statistics",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Spatial Statistics",
    "text": "Spatial Statistics\n\nTaking into account spatial dependence possibly present in data is a foremost aspect of spatial statistics.\nGeneral spatial model (Cressie 1993): \\(\\{\nZ(\\mathbf{s}) \\; : \\; \\mathbf{s} \\in D \\}\\), where \\(D\\) is an index set.\nStatistical inference depends heavily on the spatial structure/geometry of the observed spatial data.\n\n\n\n\nGeometry\nBranch\nIndex set\n\n\n\n\nAreas/polygons\nAreal models\nCountable\n\n\nPoints\nGeostatistics\nContinuum\n\n\nMixed\nSpatial Data Fusion\n\n\n\n\n\n\nChallenges arise when working with data from different sources:\n\nChange of support\nSpatial misalignment\nData fusion itself.\n\n\nLoosely speaking, this means the GP has stationary mean, variance, and a correlation function such that the correlation between two data points depends solely on their distance.\n\nCommon assumptions are stationarity and isotropy.\nImportance in spatial statistics: predominant foundation of geostatistical modeling.\nCompletely specified by mean and covariance functions.\n\nThe main reasons these models are not applied to areal data are:\n\nCalculating distance between areal spatial units is non-trivial;\nThe commonly used areal models are computationally efficient."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#classic-models-for-spatial-data",
    "href": "slides/2025-ucsf/index.html#classic-models-for-spatial-data",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Classic Models for Spatial Data",
    "text": "Classic Models for Spatial Data\n\nAreal data\n\nCAR (Besag 1974), ICAR, BYM (Besag et al. 1991), DAGAR (Datta et al. 2019).\n\nPoint-referenced data\n\nGaussian processes (GP), Nearest-neighbor mixture processes (Zheng et al. 2023)\n\nMixed/fused data\n\n“Aggregated” GP (AGP) (Moraga et al. 2017): \\[\nZ(\\mathbf{s}_i)\n= \\begin{cases}\nZ(\\mathbf{s}_i), & \\text{if } \\mathcal{A}(\\mathbf{s}_i) = 0 \\\\\n{\\mathcal{A}(\\mathbf{s}_i)}^{-1}\n\\int_{\\mathcal{A}(\\mathbf{s}_i)} Z(\\mathbf{s}) \\mathrm{d}\\mathbf{s}, & \\text{if }\n\\mathcal{A}(\\mathbf{s}_i) &gt; 0\n\\end{cases}\n\\]\n\n\n\n\nAreal models are usually heteroscedastic; The marginal variances decrease with the number of neighbors;\nData fusion models are also heteroscedastic (unless all the polygons are of the same size); computationally prohibitive for moderately large datasets; arbitrary choice of grid resolution."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#research-questions",
    "href": "slides/2025-ucsf/index.html#research-questions",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Research Questions",
    "text": "Research Questions\n\nThe main research questions we are interested in are:\n\nCan we propose a model for spatial data that accomodates areal, point-referrenced, and fused data?\nIf so, is this model competitive when compared to specialized models?\n\nProposal: An isotropic GP defined on a flexible index set.\nMain challenge: Defining a valid correlation function."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#preliminaries",
    "href": "slides/2025-ucsf/index.html#preliminaries",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nPoint-referenced and areal spatial units are (closed and bounded) sets.\nWe need to generalize distance between points to distance between sets.\nIdeally, this distance should:\n\nTake into account the shape, size, and orientation of spatial sample units.\nBe “spatially interpretable”."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#distances-between-sets",
    "href": "slides/2025-ucsf/index.html#distances-between-sets",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Distances between sets",
    "text": "Distances between sets\n\nMetric space: \\((D, d)\\), where \\(D\\) is a spatial region of interest.\nDistance between a point and a set: \\(d(x, A) = \\inf_{a \\in A}\nd(x, a)\\), where \\(d(x, y)\\) is the distance between any two elements \\(x, y \\in\nD\\)\nDirected Hausdorff distance: \\[{\\vec h}(A, B) = \\sup_{a \\in A}\nd(a, B)\\]\nHausdorff distance: \\[h(A, B) = \\max \\left \\{ \\vec{h}(A, B),\n\\vec{h}(B, A) \\right \\}\\]\n\n\n\nNote that if \\(A\\) and \\(B\\) are both singletons, then \\(h(A, B) = d(A, B)\\).\n\nMeric Properties: (1) Symmetry: \\(d(x, y) = d(y, x)\\); (2) Nonnegativeness: \\(d(x,\ny) \\geq 0\\) and \\(d(x, x) = 0\\); (3)Positiveness: \\(d(x, y) = 0 \\implies x = y\\); (4) Triangle inequality: \\(d(x, y) \\leq d(x, z) + d(z, y)\\)"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#hausdorff-distance-for-spatial-data-analysis",
    "href": "slides/2025-ucsf/index.html#hausdorff-distance-for-spatial-data-analysis",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Hausdorff Distance for Spatial Data Analysis",
    "text": "Hausdorff Distance for Spatial Data Analysis\n\nStudy region: In spatial statistics, \\(D\\) is tipically a closed and bounded subset of \\(\\mathbb{R}^2\\).\nIn this context, the Hausdorff distance is a metric (Appendix C, Molchanov 2005).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetric on \\(D \\setminus \\varnothing\\)\nThe Hausdorff distance ability to account for spatial units’ shapes, sizes and orientation(Min et al. 2007) renders it an interesting tool to achieve our goals.\nMoreover, it can distinguish between overlapping, nested, and disjointed regions.\nIn the figure: (1) The dashed lines denote the Hausdorff distances; (2) The infimum distance between to sets is zero for the three cases; (3) Distance between centroids is the same for the first two figures."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#the-hgp",
    "href": "slides/2025-ucsf/index.html#the-hgp",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "The HGP",
    "text": "The HGP\n\nIndex set: \\(\\mathcal{B}(D)\\) represents the closed and bounded subsets of \\(D \\subset \\mathbb{R}^2\\).\n\\(Z(\\mathbf{s}) \\sim \\mathrm{HGP}\\{m(\\mathbf{s}), v(\\mathbf{s}), r(h)\\}\\), where \\(\\mathbf{s} \\in \\mathcal{B}(D)\\).\nMean function: \\(m(\\mathbf{s}) = \\mathbb{E}[Z(\\mathbf{s})]\\)\nCovariance function: \\(\\mathrm{Cov}(Z(\\mathbf{s}_1),\nZ(\\mathbf{s}_2)) = v(\\mathbf{s}_1) v(\\mathbf{s}_2) r(h(\\mathbf{s}_1,\n\\mathbf{s}_2))\\)\nSD function: \\(v(\\mathbf{s}) =\n\\sqrt{\\mathrm{Var}(Z(\\mathbf{s}))}\\)\nCorrelation function: \\(r(h) =\n\\mathrm{Cor}(Z(\\mathbf{s}_1), Z(\\mathbf{s}_2)),\\) where \\(h\\) denotes the Hausdorff distance between \\(\\mathbf{s}_1, \\mathbf{s}_2 \\in\n\\mathcal{B}(D)\\).\n\n\n\nIdeally, we want bounded, compact, and non-empty sets for the Hausdorff distance to be a metric..\nIn \\(\\mathbb{R}^2\\), a compact subset is bounded.\nempty is a subset of any set -&gt; it is bounded bc a subset of a bounded set is bounded itself.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nMean and SD functions can be informed by covariates.\nThe ensure the validity of the process, the function \\(r(\\cdot)\\) must be positive definite.\nComplex functional parametric space.\nInference is simplified (or possible) by assuming parametric forms to those functions.\nThe SD function allows the HGP to accommodate both homoscedastic and heteroscedastic scenarios."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#the-vmathbfs-function",
    "href": "slides/2025-ucsf/index.html#the-vmathbfs-function",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "The \\(v(\\mathbf{s})\\) function",
    "text": "The \\(v(\\mathbf{s})\\) function\nWe may defined: \\[v(\\mathbf{s}) = \\exp \\{ \\alpha_0 + \\alpha_1 w(\\mathbf{s})\n\\},\\] where \\(w(\\mathbf{s})\\) is a covariate available for any \\(\\mathbf{s} \\in\n\\mathcal{B}(D)\\).\n\nUseful special cases:\n\nHomoscedastic: \\(w(\\mathbf{s}) = 0\\) (consequence, \\(\\sigma =\n\\exp \\{ \\alpha_0 \\}\\))\nData Fusion: \\(w(\\mathbf{s}) =\n\\mathbb{1}(\\mathcal{A}(\\mathbf{s}) &gt; 0)\\).\nArea dependent: \\(w(\\mathbf{s}) = \\mathcal{A}(\\mathbf{s})\\)\n\nAlthough flexible, one has to be careful when choosing this function to ensure the process validity (Palacios and Steel 2006).\n\n\n\nfor data fusion: \\(\\sigma_a = \\exp \\{ \\alpha_0 + \\alpha_1 \\}\\)."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#ensuring-the-process-validity",
    "href": "slides/2025-ucsf/index.html#ensuring-the-process-validity",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Ensuring the process’ validity",
    "text": "Ensuring the process’ validity\nFor a valid process, its correlation function must satisfy the following properties:\n\nDiminish with increasing distance: \\(\\lim_{h \\to \\infty}r(h) = 0\\).\nBounded from above by 1: \\(r(0) = 1\\).\nPositive definiteness (PD): yields positive definite correlation matrices for all its finite-dimensional marginal distributions.\nUnfortunately, functions that are guaranteed to be positive definite on \\((\\mathbb{R}^2, \\lVert \\cdot\n\\rVert_2)\\) are not necessarily positive definite on other metric spaces (Li et al. 2023)."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#pd-and-empirical-assessment",
    "href": "slides/2025-ucsf/index.html#pd-and-empirical-assessment",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "PD and Empirical Assessment",
    "text": "PD and Empirical Assessment\n\nDefinition: A real function \\(k\\) on a metric space \\((D, d)\\) is PD if it is continuous and satisfies:\n\\[ \\sum_{i = 1}^{m} \\sum_{j = 1}^{m} a_i a_j k(\\mathbf{s}_i, \\mathbf{s}_j)\n\\geq 0 \\]\nfor real numbers \\(a_1, \\ldots, a_m\\) and \\(\\mathbf{s}_1, \\ldots, \\mathbf{s}_m\n\\in D\\).\nNecessary condition: All the eigenvalues of the resulting correlation matrix must be non-negative.\nEmpirical assessment: We can check for PD by examining the smallest eigenvalue of the correlation matrix across the parameter space."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#the-powered-exponential-correlation-pec-function",
    "href": "slides/2025-ucsf/index.html#the-powered-exponential-correlation-pec-function",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "The Powered Exponential Correlation (PEC) Function",
    "text": "The Powered Exponential Correlation (PEC) Function\n\nPEC function: \\[r(h; \\phi, \\nu) = \\exp\\left \\{ -\n\\frac{h^{\\nu}}{\\phi^{\\nu}}\\right \\},\\] where \\(\\nu\\) is a smoothness parameter and \\(\\phi\\) governs the range of the spatial dependence.\n\n\nParametrization: We reparametrize this function with \\(\\rho =\n{\\log(10)}^{1 / \\nu} \\phi\\).\nInterpretation: \\(\\rho\\) is the distance at which the spatial correlation reduces to \\(0.10\\).\n\n\n\nexplain \\(\\rho\\)."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#visualizing-the-pec-function",
    "href": "slides/2025-ucsf/index.html#visualizing-the-pec-function",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Visualizing the PEC function",
    "text": "Visualizing the PEC function"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#empirical-assessment-of-pecs-positive-definiteness",
    "href": "slides/2025-ucsf/index.html#empirical-assessment-of-pecs-positive-definiteness",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Empirical Assessment of PEC’s Positive Definiteness",
    "text": "Empirical Assessment of PEC’s Positive Definiteness\n\n\n\nthe graph displays the smallest eigenvalue of the correlation matrix induced by \\(\\rho\\) (x-axis) and \\(\\nu\\) (y-axis).\nThese matrices are based on the two spatial applications we will discuss in the next chapter.\nThe transparent regions indicate the regions of the parametric space where rho is smaller than 0."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#hgp-recap",
    "href": "slides/2025-ucsf/index.html#hgp-recap",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "HGP Recap",
    "text": "HGP Recap\n\nFlexibility: A process that handles point-referrenced, areal, and mixed spatial data by construction.\nHausdorff distance: Enables HGP’s correlation function to account for the shape, size, and orientation of spatial objects.\nPEC Function Validity: A valid HGP depends on selecting an appropriate PEC correlation function.\nEmpirical assessments: When analyzing a new dataset or trying a new correlation function, it is imperative to empirically assess the validity of the function."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#spatial-glmm",
    "href": "slides/2025-ucsf/index.html#spatial-glmm",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Spatial GLMM",
    "text": "Spatial GLMM\nA generalized linear mixed effects model (GLMM) can be written as \\[\\begin{aligned}\n& Y(\\mathbf{s}_i) \\mid \\mathbf{x}_i, Z(\\mathbf{s}_i) \\overset{{\\rm ind}}{\\sim}\n  f(\\cdot \\mid \\mu_i, \\boldsymbol{\\gamma}) \\\\\n& g(\\mu_i) = \\mathbf{x}_i \\boldsymbol{\\beta} +\n  Z(\\mathbf{s}_i).\n\\end{aligned}\\]\n\nProbability distribution: \\(f(\\cdot)\\)\nConditional mean: \\(\\mu_i = \\mathbb{E}[Y(\\mathbf{s}_i) \\mid\n\\mathbf{x}_i, Z(\\mathbf{s}_i)]\\)\nLink function: \\(g(\\cdot)\\)\nModel parameters: \\(\\boldsymbol{\\theta} =\n{\\{\\boldsymbol{\\beta}^\\top, \\boldsymbol{\\sigma}^\\top,\n\\boldsymbol{\\delta}^\\top, \\boldsymbol{\\gamma}^\\top \\}}^\\top\\)\nJoint density: \\(p(\\mathbf{y} \\mid \\mathbf{z}, \\boldsymbol{\\theta}) =\n\\prod_{i = 1}^n f(y(\\mathbf{s}_i) \\mid \\mu_i, \\boldsymbol{\\gamma})\\)\n\n\n\nRealizations of random variables are represented by lowercase letters.\nModel paramers are greek letters.\nUnder a frequentist perspective, we consider the random effects to follow an HGP.\nFor Bayesian inference, we use the HGP as a prior for the random effects.\nResponse variable \\(Y\\) at a spatial unit \\(s\\) is modeled with an appropriate distribution (e.g., Poisson, Bernoulli).\nCovariates (\\(X\\)) and spatial random effects (\\(Z\\)) explain variation in the conditional mean (\\(\\mu\\)).\nThe HGP defines the spatial random effects (\\(Z\\)), capturing spatial correlation with the Hausdorff distance and a correlation function."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#bayesian-inference-model-assessment",
    "href": "slides/2025-ucsf/index.html#bayesian-inference-model-assessment",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Bayesian Inference & Model Assessment",
    "text": "Bayesian Inference & Model Assessment\n\nPosterior: \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y},\n\\mathbf{z}) \\propto p(\\mathbf{y} \\mid \\mathbf{z}, \\boldsymbol{\\theta})\np(\\mathbf{z} \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta})\\)\nMCMC sampler: No-U-Turn (Homan and Gelman 2014).\nConvergence assessment: traceplots and split-\\({\\hat{R}}\\) (Vehtari et al. 2021).\nGoodness-of-fit criteria: LOOIC (lower values indicate better fit)\nPosterior predictive distributions: \\(p(\\mathbf{y}^{\\ast} \\mid\n\\mathbf{y})\\)\nPredictions assessment: Interval Score (IS) and RMSP (lower values indicate better fit)\n\n\n\nPoint and interval estimates: median and percentiles (\\(0.025\\) and \\(0.975\\)) of the marginal MCMC samples.\nParameters initialized by random sampling from their priors.\nRandom effects initialized from a standard normal distribution.\n\\(a_\\rho\\) is chosen so that: \\(\\mathbb{P}(\\rho &gt; U) = p_\\rho\\). In particular, \\(a_\\rho = - \\log(p_\\rho) / \\rho_0\\).\n\\(\\nu\\) hard to be estimated.\n\nPredictions:\n\nuse the properties of GP and multivariate Normal distribution to obtain the closed-form distribution of the vector of spatial random effects \\(\\mathbf{Z}^\\ast\\) (Diggle et al. 1998);\nsample \\(\\mathbf{z}^\\ast_{(b)}\\) from the distribution derived in the previous step;\nsample \\(\\mathbf{y}^{\\ast}_{(b)}\\) from \\(p(\\mathbf{y}^{\\ast} \\mid \\boldsymbol{\\theta}_{(b)},\n\\mathbf{z}^{\\ast}_{(b)})\\), where \\(\\boldsymbol{\\theta}_{(b)}\\) is the \\(b\\)-th MCMC sample of \\(\\boldsymbol{\\theta}\\)."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#priors",
    "href": "slides/2025-ucsf/index.html#priors",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Priors",
    "text": "Priors\n\nIndependent normal priors for the regression coefficients: \\(\\boldsymbol{\\beta} \\sim \\mathcal{N}(\\mathbf{0}, 10 \\mathbf{I})\\)\nHGP prior for the latent random effects: \\(\\mathbf{Z} \\sim\n\\mathrm{HGP}\\{0, v(\\cdot), r(\\cdot) \\}\\)\nExponential prior for the spatial dependence parameter: \\(\\rho\n\\sim \\mathrm{Exp}(a_\\rho)\\), where \\(a_{\\rho} = - \\log(p_{\\rho}) / \\rho_0\\).\n\n\\(a_\\rho\\) is chosen such that \\(\\mathbb{P}(\\rho \\geq \\rho_0) = p_\\rho\\).\n\nHomoscedastic variance: \\(v(\\mathbf{s}) =\n\\sqrt{\\mathrm{Var}(Z(\\mathbf{s}))} = \\sigma \\sim t_{+}(3)\\)\nHeteroscedastic HGP: \\(\\alpha \\sim \\mathcal{N}(\\mathbf{0},\n\\mathbf{I})\\), where \\(v(\\mathbf{s}) = \\exp \\{ \\alpha_0 + \\sum_i \\alpha_i w_i(\\mathbf{s}) \\}\\).\n\n\n\nFor \\(\\rho\\), the prior is inspired in penalized complexity priors. A conservative, but reasonable, choice for its hyperparameter is setting \\(a_\\rho\\) such that \\(\\rho_0\\) is a surprisingly low practical range and \\(p_rho\\) is a small probability (i.e., around .01)"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#bayesian-modeling-recap",
    "href": "slides/2025-ucsf/index.html#bayesian-modeling-recap",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Bayesian Modeling Recap",
    "text": "Bayesian Modeling Recap\n\nHGP as a prior for the random effects disribution in a GLMM.\nBayesian inference through MCMC.\nUncertainty quantification of predictions through the posterior predictive distributions.\n\n\nDAGAR priors: \\[\n\\begin{aligned}\n  \\pi(\\beta_0) & \\propto 1 \\\\\n  \\beta_1 & \\sim N(0, 1000^2) \\\\\n  \\tau & \\sim Gamma(2, 1) \\\\\n  \\psi & \\sim U(0, 1).\n\\end{aligned}\n\\] - Precision matrix is defined based on the order of the observations and adjacency matrix (and the two parameters)"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#respiratory-disease-hospitalization-in-glasgow",
    "href": "slides/2025-ucsf/index.html#respiratory-disease-hospitalization-in-glasgow",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Respiratory Disease Hospitalization in Glasgow",
    "text": "Respiratory Disease Hospitalization in Glasgow"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#respiratory-disease-hospitalization-in-glasgow-1",
    "href": "slides/2025-ucsf/index.html#respiratory-disease-hospitalization-in-glasgow-1",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Respiratory Disease Hospitalization in Glasgow",
    "text": "Respiratory Disease Hospitalization in Glasgow\n\\[\\begin{aligned}\n& (Y(\\mathbf{s}_i) \\mid x_i, z(\\mathbf{s}_i)) \\sim \\text{Poisson}(E_i \\mu_i) \\\\\n& \\log(\\mu_i) = \\beta_0 + x_i \\beta_1 + z(\\mathbf{s}_i)\n\\end{aligned}\\]\n\nSample units: 134 intermediate zones (IZ), where the \\(i\\)-th IZ is denoted \\(\\mathbf{s}_i\\).\nNumber of hospitalizations: \\(\\mathbf{Y} = {(Y(\\mathbf{s}_1),\n\\ldots, Y(\\mathbf{s}_n))}^\\top\\).\nExpected number of hospitalizations based on the national age- and sex-standardized rates: \\(E_i\\).\nPercentage of people classified as income deprived: \\(x_i\\).\n\n\n\nData from the north portion of the river Clyde in the Great Glasgow and Clyde health board in Scotland.\nAssumption: Conditional on \\(\\mathbf{Z}\\), \\(\\mathbf{Y}\\) are mutually independent.\nExplain goals of the analysis–estimate risks adjusted for income deprivation, compare methods.\n\\(\\mu_i\\) is the expected SIR at region \\(i\\).\nOutline the modeling choices (HGP, DAGAR, BYM), briefly mention priors."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#disease-mapping-estimation-gof",
    "href": "slides/2025-ucsf/index.html#disease-mapping-estimation-gof",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Disease Mapping: Estimation & GOF",
    "text": "Disease Mapping: Estimation & GOF\n\n\n\n\n\n\n\n\n\n\nHGP\nDAGAR\n\n\n\n\n\\(\\beta_0\\)\n-0.21 (-0.268, -0.139)\n-0.26 (-0.450, -0.137)\n\n\n\\(\\beta_1\\)\n0.33 (0.284, 0.368)\n0.31 (0.258, 0.370)\n\n\n\\(\\sigma\\)\n0.19 (0.155, 0.234)\n0.30 (0.218, 0.484)\n\n\n\\(\\rho\\)\n2.25 (0.159, 6.948)\n\n\n\n\\(\\psi\\)\n\n0.43 (0.069, 0.827)\n\n\n\n\n\n\n\n\n\n\n\n\nLOOIC\n1081.0\n1081.9\n\n\n\n\n\n\nmedian (95% CI)\nsimilar estimates for covariate\nHGP indicates weak spatial correlation\nDAGAR and BYM spatial dependence are not helpful as they indicate the spatial correlation goes from weak to strong (according to the CI)"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#disease-mapping-spatial-dependence",
    "href": "slides/2025-ucsf/index.html#disease-mapping-spatial-dependence",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Disease Mapping: Spatial Dependence",
    "text": "Disease Mapping: Spatial Dependence\n\n\n\nHGP provides more insight into spatial dependence\nWe could also plot the correlation function itself"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#disease-mapping-adjusted-sir",
    "href": "slides/2025-ucsf/index.html#disease-mapping-adjusted-sir",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Disease Mapping: Adjusted SIR",
    "text": "Disease Mapping: Adjusted SIR\n\n\n\nFitted values are similar among the three models\nSome regions with very low risks are shrunk toward a “regional mean”"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#air-pollution-in-ventura-and-los-angeles",
    "href": "slides/2025-ucsf/index.html#air-pollution-in-ventura-and-los-angeles",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Air Pollution in Ventura and Los Angeles",
    "text": "Air Pollution in Ventura and Los Angeles\n\n\n\n\\[(Y(\\mathbf{s}_i) \\mid z(\\mathbf{s}_i)) \\sim\n  \\mathcal{N}(\\beta_0 + z(\\mathbf{s}_i), \\tau^2)\\]\n\nPM2.5: \\(\\mathbf{Y} = {(Y(\\mathbf{s}_1), \\ldots,\nY(\\mathbf{s}_n))}^\\top\\).\nPoint-referrenced data from 19 measurement stations available daily from 1999 to date;\nSatellite-derived estimates (2010–2012) at 184 areal units.\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngoals: (1); estimate model parameters using both sources. (2) use satellite data to help with interpolation.\nsquare areas (average size \\(\\approx\\) 101.95 km2)\ndata fusion challenges\nadaptability of the hgp to different problems.\nPm25 scale is micrometre per cubic meter: one one-millionth of a meter.\nconditional on \\(z\\) the \\(y\\)s are mutually independent.\nPriors on random effects: AGP1 and 2; heteroscedastic HGP with different variances for areal and point-referrenced data."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#agp-approximation",
    "href": "slides/2025-ucsf/index.html#agp-approximation",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "AGP Approximation",
    "text": "AGP Approximation"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#air-pollution-estimation-and-prediction-assessment",
    "href": "slides/2025-ucsf/index.html#air-pollution-estimation-and-prediction-assessment",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Air Pollution: Estimation and Prediction Assessment",
    "text": "Air Pollution: Estimation and Prediction Assessment\n\n\n\n\n\n\n\n\n\n\n\nHGP\n\\(\\rm AGP_1\\)\n\\(\\rm AGP_2\\)\n\n\n\n\n\\(\\beta\\)\n5.61 (4.69, 6.45)\n6.22 (2.16, 10.10)\n6.19 (5.88, 6.48)\n\n\n\\(\\rho\\)\n13.83 (7.82, 23.61)\n13.16 (5.14, 30.24)\n0.63 (0.46, 0.83)\n\n\n\\(\\tau\\)\n0.18 (0.07, 0.31)\n1.39 (1.24, 1.56)\n0.54 (0.39, 0.72)\n\n\n\\(\\sigma\\)\n3.85 (2.92, 5.18)\n1.70 (0.96, 2.91)\n2.41 (2.024, 2.84)\n\n\n\\(\\sigma_a\\)\n1.24 (1.04, 1.51)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRMSP\n1.05\n1.45\n1.64\n\n\nWidth\n3.57\n2.53\n9.67\n\n\nCPP\n95.5\n78.6\n95.5\n\n\nIS\n4.80\n15.11\n13.65\n\n\n\n\n\n\n\\(\\rho\\) rescaled to 100s of km.\nstaggering difference in estimates of the same model with different meshes."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#air-pollution-change-of-support",
    "href": "slides/2025-ucsf/index.html#air-pollution-change-of-support",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Air Pollution: Change-of-Support",
    "text": "Air Pollution: Change-of-Support\n\n\n\nFigure confirms what we learned from 10-fold CV and simulation studies.\nHGP allows to use data from different sources seamlessly\nNo dependence on meshes/grids\nApparently, a parsimonious compromise between the two meshes.\nOnce again, the AGP seems highly dependend on the mesh and this is not highlighted in the literature."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#applications-key-findings",
    "href": "slides/2025-ucsf/index.html#applications-key-findings",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Applications: key findings",
    "text": "Applications: key findings\n\nThe proposed method consistently demonstrated performance comparable to specialized models tailored for areal and fused data.\nUnlike traditional areal models, the HGP’s marginal variances are independent of the number of neighbors.\nThe HGP model simplifies data fusion by bypassing the need to define arbitrary grids for numerical integral evaluation, eliminating this step each time the joint probability distribution of the data and parameters is calculated.\nAcross both applications, the HGP provides an interpretable spatial dependence parameter and a spatial correlation function."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#highlights",
    "href": "slides/2025-ucsf/index.html#highlights",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Highlights",
    "text": "Highlights\nThe HGP has proven to be a powerful model that offers:\n\nVersatility: accomodates diverse spatial data types.\nPerformance: competitive against models designed for specific spatial data types.\nReliable predictions: prediction intervals with near nominal frequentist coverage.\nOur conclusions are further supported by a comprehensive simulation study, detailed in our available preprint.\n\n\nKey Takeaway: The HGP’s versatility and performance make it a valuable tool in your spatial analysis toolkit."
  },
  {
    "objectID": "slides/2025-ucsf/index.html#future-work-and-limitations",
    "href": "slides/2025-ucsf/index.html#future-work-and-limitations",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "Future work and Limitations",
    "text": "Future work and Limitations\n\nExtensions:\n\nnon-Euclidean spaces\nBig data\n\nLimitations:\n\nBig “n” problem inherited from geostatistics\nUnclear how to incorporate anisotropy\nDifficulties in obtaining spectral densities for correlation functions"
  },
  {
    "objectID": "slides/2025-ucsf/index.html#references",
    "href": "slides/2025-ucsf/index.html#references",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "",
    "text": "References\n\n\nBesag, J. (1974), “Spatial interaction and the statistical analysis of lattice systems,” Journal of the Royal Statistical Society. Series B (Methodological), JSTOR, 192–236.\n\n\nBesag, J., York, J., and Mollié, A. (1991), “Bayesian image restoration, with two applications in spatial statistics,” Annals of the Institute of Statistical Mathematics, 43, 1–20.\n\n\nCressie, N. (1993), Statistics for spatial data, Wiley series in probability and statistics, Wiley.\n\n\nDatta, A., Banerjee, S., Hodges, J. S., and Gao, L. (2019), “Spatial disease mapping using directed acyclic graph auto-regressive (DAGAR) models,” Bayesian analysis, NIH Public Access, 14, 1221.\n\n\nDiggle, P. J., Tawn, J. A., and Moyeed, R. A. (1998), “Model-based geostatistics,” Journal of the Royal Statistical Society Series C: Applied Statistics, Oxford University Press, 47, 299–350.\n\n\nHoman, M. D., and Gelman, A. (2014), “The No-U-turn sampler: Adaptively setting path lengths in hamiltonian Monte Carlo,” Journal of Machine Learning Research, JMLR.org, 15, 1593–1623.\n\n\nLi, D., Tang, W., and Banerjee, S. (2023), “Inference for Gaussian processes with Matérn covariogram on compact Riemannian manifolds,” Journal of Machine Learning Research, 24, 1–26.\n\n\nMin, D., Zhilin, L., and Xiaoyong, C. (2007), “Extended Hausdorff distance for spatial objects in GIS,” International Journal of Geographical Information Science, Taylor & Francis, 21, 459–475.\n\n\nMolchanov, I. S. (2005), Theory of random sets, Probability and its applications, London, England: Springer. https://doi.org/10.1007/1-84628-150-4.\n\n\nMoraga, P., Cramb, S. M., Mengersen, K. L., and Pagano, M. (2017), “A geostatistical model for combined analysis of point-level and area-level data using INLA and SPDE,” Spatial Statistics, Elsevier, 21, 27–41.\n\n\nPalacios, M. B., and Steel, M. F. J. (2006), “Non-Gaussian Bayesian geostatistical modeling,” Journal of the American Statistical Association, Taylor & Francis, 101, 604–618.\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., and Bürkner, P.-C. (2021), “Rank-normalization, folding, and localization: An improved \\(\\hat{R}\\) for assessing convergence of MCMC (with discussion),” Bayesian Analysis, International Society for Bayesian Analysis, 16, 667–718.\n\n\nZheng, X., Kottas, A., and Sansó, B. (2023), “Nearest-neighbor mixture models for non-gaussian spatial processes,” Bayesian Analysis, International Society for Bayesian Analysis, 18, 1191–1222."
  },
  {
    "objectID": "talks/2018-csds/index.html",
    "href": "talks/2018-csds/index.html",
    "title": "Voronoi Data Linkage: Extracting Information from Polygons to Points",
    "section": "",
    "text": "Details\n\nDate: October 16, 2018\nLocation: Salvador, Brazil\nSlides\n\n\n\nSlides"
  },
  {
    "objectID": "talks/2021-ness/index.html",
    "href": "talks/2021-ness/index.html",
    "title": "Spatially misaligned data: An application to the 2018 Brazilian Presidential Election",
    "section": "",
    "text": "Details\n\nDate: October 01, 2021\nLocation: Providence, RI, USA.\nSlides\n\n\n\nAbstract\nIn Brazil, socioeconomic data are available at census tracts (polygons), while election data are available at voting locations (point-referenced). The misaligned data makes studying the association between election outcomes and socioeconomic variables challenging. Since voters are assigned to the nearest electoral sections, we use Voronoi tessellation to associate each voting station with a Voronoi polygon. Socioeconomic variables for each polygon are then constructed from such data at the census tract level, assuming that both sets of areal data were constructed from the same underlying Gaussian random field (GRF). Predictions for the Voronoi cells are derived from the underlying GRF with estimated parameters. Since the socioeconomic variables are not normally distributed, we also consider a nonparametric approach that uses spatial areal interpolation to construct data for the Voronoi cells from the census tract data. The interpolated outputs are used as a baseline. Our simulation study shows that the method based on an underlying GRF is robust in prediction under model misspecification. In application to the 2018 Brazilian presidential election in Belo Horizonte, more socioeconomically deprived regions were found to have a higher percentage of null votes. The methods are publicly available in an R package smile.\n\n\nSlides"
  },
  {
    "objectID": "talks/2024-defense/index.html",
    "href": "talks/2024-defense/index.html",
    "title": "Hausdorff–Gaussian Process with Spatial and Spatiotemporal Applications",
    "section": "",
    "text": "Details\n\nDate: April 10, 2024\nLocation: Storrs, CT\nSlides\n\n\n\nAbstract\nAccurate modeling of spatial dependence is crucial for analyzing spatial and spatiotemporal data, as it directly influences parameter estimation and prediction accuracy. The unique structure and geometry of spatial data demand tailored approaches for valid statistical inference. Traditional areal data models, often reliant on adjacency matrices, may not adequately capture the nuances of polygons with varying sizes and shapes. Data fusion models, while effective, can become computationally prohibitive for even moderately large datasets due to their reliance on intensive numerical integrals.\nTo address these challenges, we propose the Hausdorff-Gaussian Process~(HGP), a flexible model class that employs the Hausdorff distance to quantify spatial dependence in both point and areal data. We establish a valid correlation function for the HGP, facilitating its use in diverse modeling techniques, including geostatistical and areal models. Seamless integration into generalized linear mixed-effects models expands its applicability, making it particularly well-suited for tackling change of support and data fusion problems.\nOur comprehensive simulation study and applications to three real-world datasets validate the HGP’s efficacy. Applications with both areal and fused spatial data demonstrate our model’s capabilities. Additionally, we adapt the HGP for spatiotemporal modeling of areal Tuberculosis data using a separable model. Results indicate that the HGP delivers competitive goodness-of-fit and prediction performance compared to specialized models. In conclusion, the HGP provides a versatile and robust framework for modeling spatial data across various types and geometries, holding significant promise for applications in fields like public health and climate science.\n\n\nSlides"
  },
  {
    "objectID": "talks/2024-ness/index.html",
    "href": "talks/2024-ness/index.html",
    "title": "HAUSDORFF–GAUSSIAN PROCESS WITH A SPATIOTEMPORAL APPLICATION",
    "section": "",
    "text": "Details\n\nDate: May 23, 2024\nLocation: Storrs, CT\nSlides\n\n\n\nAbstract\nTuberculosis (TB) remains a significant global health challenge, and Brazil exemplifies the complexities of controlling this infectious disease. Reliable estimates and forecasts of TB incidence rates are crucial to guide public health policies. This study focuses on the high-burden municipalities of Eastern Rio Grande do Sul, Brazil. We propose a novel spatiotemporal model based on the Hausdorff-Gaussian process to analyze TB incidence data. This model incorporates spatial dependence dictated by the Hausdorff distance, allowing it to “borrow strength” from neighboring municipalities and generate more reliable estimates, particularly for smaller areas. Our analysis has two primary goals. First, we aim to generate accurate TB incidence estimates by incorporating municipality-specific characteristics through covariates and a spatiotemporal random effect. The model delivers trustworthy expected incidence rates, consequently allowing for calculating standardized incidence ratios (SIRs). Second, our model offers predictive capabilities, forecasting TB incidence rates one year ahead to support proactive public health planning. We demonstrate our model’s effectiveness and competitive performance against other specialized areal data models. The insights gained from this study can guide policymakers in developing effective TB control strategies.\n\n\nSlides"
  },
  {
    "objectID": "talks/2024-ufrgs/index.html",
    "href": "talks/2024-ufrgs/index.html",
    "title": "STATISTICAL INFERENCES AND PREDICTIONS FOR AREAL DATA AND SPATIAL DATA FUSION WITH HAUSDORFF-GAUSSIAN PROCESSES",
    "section": "",
    "text": "Details\n\nDate: Nov 21, 2024\nLocation: Porto Alegre, RS - Brazil\nSlides\n\n\n\nAbstract\nAccurate modeling of spatial dependence is pivotal in analyzing spatial data, influencing parameter estimation and predictions. The spatial structure of the data significantly impacts valid statistical inference. Existing models for areal data often rely on adjacency matrices, struggling to differentiate between polygons of varying sizes and shapes. Conversely, data fusion models rely on computationally intensive numerical integrals, presenting challenges for moderately large datasets. In response to these issues, we propose the Hausdorff-Gaussian process (HGP), a versatile model utilizing the Hausdorff distance to capture spatial dependence in both point and areal data. We introduce a valid correlation function for this model, accommodating diverse modeling techniques, including geostatistical and areal models. Integration into generalized linear mixed-effects models enhances its applicability, particularly in addressing data fusion challenges. We validate our approach through a comprehensive simulation study and application to two real-world scenarios involve areal data, and another demonstrates its effectiveness in data fusion. The results suggest that the HGP is competitive with specialized models regarding goodness-of-fit and prediction performances. In summary, the HGP offers a flexible and robust solution for modeling spatial data of various types and shapes, with potential applications spanning fields such as public health and climate science.\n\n\nSlides"
  },
  {
    "objectID": "talks/2025-slmdrmr/index.html",
    "href": "talks/2025-slmdrmr/index.html",
    "title": "drmr: A Bayesian approach to Dynamic Range Models in R",
    "section": "",
    "text": "Details\n\nDate: Mar 12, 2025\nLocation: San Francisco, CA - USA\nSlides\n\n\n\nAbstract\nPredicting species’ responses to environmental change is a critical challenge in ecology. Traditional species distribution models (SDMs) often rely on correlative relationships with strong equilibrium assumptions and limited skill at forecasting distributions under novel conditions. Dynamic range models (DRMs) offer a more mechanistic approach by explicitly incorporating the demographic processes (recruitment, death, movement) that drive range dynamics. However, the complexity of DRMs has hindered their widespread adoption. We introduce drmr, an open-source R package that substantially lowers the barrier to entry for DRM applications. drmr provides a user-friendly framework for building, fitting, visualizing, evaluating, and projecting age-structured DRMs, leveraging the power of Stan for efficient Bayesian inference. Users can readily relate environmental drivers to demographic processes based on observations for a species across space and time. Models can be tailored to specific ecological systems, and competing hypotheses can be tested for range shift mechanisms. By explicitly modeling demographic processes and their environmental drivers, drmr provides a powerful and accessible tool for ecologists to understand and predict changes in species distributions, thereby contributing to improved conservation planning and management in the face of global change.\n\n\nSlides"
  }
]